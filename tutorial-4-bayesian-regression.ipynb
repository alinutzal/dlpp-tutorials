{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian amplitude regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lectures you should've now covered, or at least discussed Bayesian networks.  Here we'll show you how to build these networks and use them in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by constructing a Bayesian layer in pytorch, and then building the Bayesian loss function.  We will then construct a Bayesian network from these layers, and use it to perform the same amplitude regression from the previous tutorial.  We will discuss how to analyse the outputs of the Bayesian network, and how this gives us the ability to estimate the error on our analysis.  This last step is crucial to the application of any numerical technique in physics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outline / tasks:\n",
    " - Imports \\& plotting set-up\n",
    " - Loading the data\n",
    " - Visualising the data\n",
    "     - visualise some of the kinematics of the process (transverse momentum of photons/gluons, MET)\n",
    "     - histogram the amplitudes\n",
    " - Preprocessing the data\n",
    "     - neural networks like $\\mathcal{O}(1)$ numbers\n",
    "     - how should we preprocess the data?\n",
    " - Datasets and dataloaders\n",
    "     - details are in the pytorch docs\n",
    " - Building a Bayesian layer\n",
    " - Constructing the Bayesian loss function\n",
    " - Building the Bayesian neural network\n",
    " - Optimising the neural network\n",
    " - Plot the train and validation losses as a function of the epochs\n",
    " - Study the results\n",
    "\n",
    "     \n",
    "Most practical pytorch skills you need for this work is covered in the basics tutorial at https://pytorch.org/tutorials/beginner/basics/intro.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import init\n",
    "from torch.nn import Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.colors as mcolors\n",
    "import colorsys\n",
    "\n",
    "labelfont = FontProperties()\n",
    "labelfont.set_family('serif')\n",
    "labelfont.set_name('Times New Roman')\n",
    "labelfont.set_size(14)\n",
    "\n",
    "axislabelfont = FontProperties()\n",
    "axislabelfont.set_family('serif')\n",
    "axislabelfont.set_name('Times New Roman')\n",
    "axislabelfont.set_size(22)\n",
    "\n",
    "tickfont = FontProperties()\n",
    "tickfont.set_family('serif')\n",
    "tickfont.set_name('Times New Roman')\n",
    "tickfont.set_size(16)\n",
    "\n",
    "axisfontsize = 16\n",
    "labelfontsize = 16\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"mathtext.default\"] = \"rm\"\n",
    "plt.rcParams['text.usetex'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dat = np.load( \"tutorial-2-data/trn_dat.npy\" )\n",
    "trn_amp = np.load( \"tutorial-2-data/trn_amp.npy\" )\n",
    "\n",
    "val_dat = np.load( \"tutorial-2-data/val_dat.npy\" )\n",
    "val_amp = np.load( \"tutorial-2-data/val_amp.npy\" )\n",
    "\n",
    "tst_dat = np.load( \"tutorial-2-data/tst_dat.npy\" )\n",
    "tst_amp = np.load( \"tutorial-2-data/tst_amp.npy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape: (30000, 5, 4)\n",
      "train amp  shape: (30000,)\n",
      "test  data shape: (30000, 5, 4)\n",
      "test  amp  shape: (30000,)\n",
      "val   data shape: (30000, 5, 4)\n",
      "val   amp  shape: (30000,)\n"
     ]
    }
   ],
   "source": [
    "print( f\"train data shape: {trn_dat.shape}\" )\n",
    "print( f\"train amp  shape: {trn_amp.shape}\" )\n",
    "print( f\"test  data shape: {tst_dat.shape}\" )\n",
    "print( f\"test  amp  shape: {tst_amp.shape}\" )\n",
    "print( f\"val   data shape: {val_dat.shape}\" )\n",
    "print( f\"val   amp  shape: {val_amp.shape}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not repeat the visualisation of the data, see the previous tutorial for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pt( fv ):\n",
    "    ptsq = np.round( fv[1]**2 + fv[2]**2 , 5 )\n",
    "    if ptsq>0:\n",
    "        return np.sqrt( ptsq )\n",
    "    elif ptsq<0:\n",
    "        raise Exception( \"$p_T$ squared is less than zero\" ) \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dat_gluon_pt = []\n",
    "for ev in trn_dat:\n",
    "    trn_dat_gluon_pt.append( get_pt( ev[2] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nev = trn_dat.shape[0]\n",
    "trn_datf = np.reshape( trn_dat, (nev,-1) )\n",
    "val_datf = np.reshape( val_dat, (nev,-1) )\n",
    "tst_datf = np.reshape( tst_dat, (nev,-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_datf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = np.mean( trn_dat_gluon_pt )\n",
    "trn_datf = trn_datf / gpt\n",
    "val_datf = val_datf / gpt\n",
    "tst_datf = tst_datf / gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_datfp = torch.Tensor( trn_datf )\n",
    "val_datfp = torch.Tensor( val_datf )\n",
    "tst_datfp = torch.Tensor( tst_datf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ampl = np.log( trn_amp )\n",
    "val_ampl = np.log( val_amp )\n",
    "tst_ampl = np.log( tst_amp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_amplp = torch.Tensor( trn_ampl )\n",
    "val_amplp = torch.Tensor( val_ampl )\n",
    "tst_amplp = torch.Tensor( tst_ampl )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class amp_dataset( Dataset ):\n",
    "    \n",
    "    def __init__( self, data, amp ):\n",
    "        self.data = data\n",
    "        self.amp = amp\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.amp)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.amp[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataset = amp_dataset( trn_datfp, trn_amplp.unsqueeze(-1) )\n",
    "val_dataset = amp_dataset( val_datfp, val_amplp.unsqueeze(-1) )\n",
    "tst_dataset = amp_dataset( tst_datfp, tst_amplp.unsqueeze(-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dataloader = DataLoader( trn_dataset, batch_size=64, shuffle=True )\n",
    "val_dataloader = DataLoader( val_dataset, batch_size=64, shuffle=True )\n",
    "tst_dataloader = DataLoader( tst_dataset, batch_size=64, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 20])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next( iter( trn_dataloader ) )[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next( iter( trn_dataloader ) )[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Bayesian layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's look at the source code for a **basic linear layer** in pytorch:\n",
    "\n",
    "(https://pytorch.org/docs/stable/_modules/torch/nn/modules/linear.html#Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n",
    "                 device=None, dtype=None) -> None:\n",
    "        factory_kwargs = {'device': device, 'dtype': dtype}\n",
    "        super(Linear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n",
    "            init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return F.linear(input, self.weight, self.bias)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects of this class apply a linear transformation to the incoming data: $y = xA^T + b$.\n",
    "\n",
    "The input arguments are required to initialise the layer, so, in the \\_\\_init()\\_\\_ function.  We have:\n",
    "- in_features: size of each input sample\n",
    "- out_features: size of each output sample\n",
    "- bias: If set to ``False``, the layer will not learn an additive bias.  Default: ``True``\n",
    "\n",
    "The shapes are:\n",
    "- Input: $(*, H_{in})$ where $*$ means any number of dimensions including none and $H_{in} = \\text{in_features}$.\n",
    "- Output: $(*, H_{out})$ where all but the last dimension are the same shape as the input and $H_{out} = \\text{out_features}$.\n",
    "\n",
    "The layer has attributes:\n",
    "- weight: the learnable weights of the module of shape $(\\text{out_features}, \\text{in_features})$. The values are initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$, where $k = \\frac{1}{\\text{in_features}}$\n",
    "- bias:   the learnable bias of the module of shape $(\\text{out_features})$.  If `bias` is ``True``, the values are initialized from $\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})$ where $k = \\frac{1}{\\text{in_features}}$.\n",
    "\n",
    "Examples::\n",
    "\n",
    "    >>> m = nn.Linear(20, 30)\n",
    "    \n",
    "    >>> input = torch.randn(128, 20)\n",
    "    \n",
    "    >>> output = m(input)\n",
    "    \n",
    "    >>> print(output.size())\n",
    "    \n",
    "    torch.Size([128, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lecture, we know that in a Bayesian network the weights are replaced by Gaussian distributions, and on a forward pass we get the output by sampling from that distribution.\n",
    "\n",
    "So the biases are the same as in the linear layer.  But not each weight is a Gaussian distibution and so needs a mean and a variance.  The bias and the mean and variance of the weight distribution will be learnable.  In practice it's easier to work with the log of the variance as it is more stable when optimising the network.\n",
    "\n",
    "We need to be able to sample from the Gaussian weight distributions, and compute derivatives of the output in order to update the network parameters.  To do this we use something called the 're-parameterisation trick'.  It involves sampling random noise from a unit normal distribution, and then transforming that number using the mean and variance of the weight distribution in this way:\n",
    "\\begin{equation}\n",
    "w = \\mu + \\sigma\\times r\n",
    "\\end{equation}\n",
    "where $r$ is a random number sampled from a unit normal distribution (Gaussian with mean and variance equal to one), $\\mu$ is the mean of the weight distribution, and $\\sigma$ is the standard deviation.  In this way we separate the stochastic part of the function from the parameters defining the distribution.  And so if we take any differentiable function of $x$ (e.g. an activation function), we can compute derivatives of that function with respect to the mean and variance of the weight distribution.\n",
    "\n",
    "In the `forward` method we then need to implement this reparameterisation trick for the weights, and then apply the same linear transformation as in the standard linear layer.\n",
    "\n",
    "On each forward pass we need to generate a set of random numbers with the same shape as our means and variances.  Choosing a set of random numbers for the sampling is equivalent to 'sampling' a new neural network from the Bayesian neural network.  And sometimes at the end of the analysis, we will want to keep the same network for testing.  So we don't always want to re-sample the random numbers on each forward pass.  To control this we define a flag called `self.resample`, with default set to ``True``.\n",
    "\n",
    "We also need a `reset_parameters` function to reset the parameters in the network.  This is standard for layers in pytorch.  We use a slightly different function to do this than is used in the pytorch linear layer, as can be seen below.\n",
    "\n",
    "From the lecture, you know that the weight distributions require a prior.  The simplest choice for this prior is just a Gaussian distribution with a mean and variance of one.  Results are typically not too sensitive to this prior, as long as the values are within reasonable limits.  For example, $\\mathcal{O}(1)$ means and standard deviations.  Going beyond $\\mathcal{O}(1)$ numbers just leads to numerical instabilities in the training.  The Bayesian loss function contains a term coming from the KL divergence between the weight distributions in the network and their priors.  So the layers should have some funcitonality to return these values.  The KL divergence for the layer is:\n",
    "\\begin{equation}\n",
    "\\text{KL} = \\sum_{\\text{weights}} 0.5 \\times (  \\mu^2 + \\sigma^2 - \\log\\sigma^2 - 1 )\n",
    "\\end{equation}\n",
    "\n",
    "So let's build the **simplest Bayesian layer** we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VBLinear( Module ):\n",
    "    # VB -> Variational Bayes\n",
    "    \n",
    "    __constants__ = ['in_features', 'out_features']\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "    \n",
    "    def __init__( self, in_features, out_features ):\n",
    "        super(VBLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.resample = True\n",
    "        self.bias = Parameter( Tensor( out_features ) )\n",
    "        self.mu_w = Parameter( Tensor( out_features, in_features ) )\n",
    "        self.logsig2_w = Parameter( Tensor( out_features, in_features ) )\n",
    "        self.random = torch.randn_like( self.logsig2_w )\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def forward( self, input ):\n",
    "        if self.resample:\n",
    "            self.random = torch.randn_like( self.logsig2_w )\n",
    "        s2_w = self.logsig2_w.exp()\n",
    "        weight = self.mu_w + s2_w.sqrt() * self.random\n",
    "        return nn.functional.linear( input, weight, self.bias ) #+ 1e-8\n",
    "    \n",
    "    def reset_parameters( self ):\n",
    "        stdv = 1. / np.sqrt( self.mu_w.size(1) )\n",
    "        self.mu_w.data.normal_( 0, stdv )\n",
    "        self.logsig2_w.data.zero_().normal_( -9, 0.001 )\n",
    "        self.bias.data.zero_()\n",
    "        \n",
    "    def KL( self, loguniform=False ):\n",
    "        kl = 0.5 * ( self.mu_w.pow(2) + self.logsig2_w.exp() - self.logsig2_w - 1 ).sum()\n",
    "        return kl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the layers, define:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tlr0 = VBLinear( 10, 5 )\n",
    "tlr1 = VBLinear( 5, 2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some test data, a batch of 20 vectors with 10 elements each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand( 20, 10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pass the data first through layer0 then through layer1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1523,  0.1869],\n",
       "        [ 0.1706,  0.3295],\n",
       "        [ 0.0875,  0.3682],\n",
       "        [-0.1234,  0.3718],\n",
       "        [ 0.6967,  0.7880],\n",
       "        [ 0.1683,  0.2134],\n",
       "        [ 0.0435,  0.5645],\n",
       "        [ 0.0617,  0.4357],\n",
       "        [ 0.1835,  0.8228],\n",
       "        [-0.0303,  0.1618],\n",
       "        [ 0.5201,  0.7970],\n",
       "        [ 0.1258,  0.4622],\n",
       "        [ 0.2583,  0.5258],\n",
       "        [ 0.1353,  0.4262],\n",
       "        [ 0.3772,  0.2814],\n",
       "        [ 0.0777,  0.5676],\n",
       "        [ 0.3921,  0.4807],\n",
       "        [-0.1868, -0.1350],\n",
       "        [-0.0236,  0.0432],\n",
       "        [ 0.3496,  0.1937]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlr1( tlr0( x ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this has the correct shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlr1( tlr0( x ) ).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also try running the same data through the layer multiple times, you get different results.  This is because of the sampling in the Bayesian layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5897, grad_fn=<SelectBackward0>)\n",
      "tensor(0.5777, grad_fn=<SelectBackward0>)\n",
      "tensor(0.5939, grad_fn=<SelectBackward0>)\n",
      "tensor(0.5936, grad_fn=<SelectBackward0>)\n",
      "tensor(0.6032, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(tlr0(x)[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Bayesian loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lectures we know that there are two parts to the Bayesian loss function:\n",
    "- The negative log Gaussian\n",
    "- the KL from the network weights\n",
    "\n",
    "The second comes from the layers, and the first is defined below.  This negative log Gaussian term acts on the two outputs from the Bayesian neural network:\n",
    "- the mean\n",
    "- the variance (which we parameterise as the log variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_gauss( outputs, targets ):\n",
    "\n",
    "    mu = outputs[:, 0]\n",
    "    logsigma2 = outputs[:, 1]\n",
    "    out = torch.pow( mu - targets, 2 ) / ( 2 * logsigma2.exp() ) + 1./2. * logsigma2\n",
    "    \n",
    "    return torch.mean(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Bayesian neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll build a simple network with one input and one output layer, and two hidden layers.  We define the dimensions of these layers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipt_dim = 20\n",
    "opt_dim = 1\n",
    "hdn_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build a very simple class for our neural network, which we call amp_net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bayes_amp_net( Module ):\n",
    "    \n",
    "    # default hdn_dim is 30, but can be changed upon initialisation\n",
    "    def __init__( self, training_size, hdn_dim=50 ):\n",
    "        \n",
    "        super( bayes_amp_net, self ).__init__()\n",
    "        \n",
    "        # the loss function depends on the amount of training data we have, so we need to store this\n",
    "        self.training_size = training_size\n",
    "        \n",
    "        # the activation layers of the network are not bayesian\n",
    "        # and we need to be able to access the bayesian layers separately\n",
    "        \n",
    "        self.vb_layers = []\n",
    "        self.all_layers = []\n",
    "        \n",
    "        # define the input layer\n",
    "        vb_layer = VBLinear( ipt_dim, hdn_dim )\n",
    "        self.vb_layers.append( vb_layer )\n",
    "        self.all_layers.append( vb_layer )\n",
    "        self.all_layers.append( nn.ReLU() )\n",
    "        \n",
    "        # loop over hidden layers\n",
    "        for i in range(2):\n",
    "            vb_layer = VBLinear( hdn_dim, hdn_dim )\n",
    "            self.vb_layers.append( vb_layer )\n",
    "            self.all_layers.append( vb_layer )\n",
    "            self.all_layers.append( nn.ReLU() )\n",
    "        \n",
    "        # define the output layer\n",
    "        vb_layer = VBLinear( hdn_dim, 2 )\n",
    "        self.vb_layers.append( vb_layer )\n",
    "        self.all_layers.append( vb_layer )\n",
    "        \n",
    "        # define the model as a Sequential net over all layers\n",
    "        self.model = nn.Sequential(*self.all_layers)\n",
    "\n",
    "    # and of course the forward function\n",
    "    def forward( self, x ):\n",
    "        out = self.model( x )\n",
    "        return out\n",
    "    \n",
    "    # we need the KL from the bayesian layers to compute the loss function\n",
    "    def KL( self ):\n",
    "        kl = 0\n",
    "        for vb_layer in self.vb_layers:\n",
    "            kl += vb_layer.KL()\n",
    "        return kl / self.training_size\n",
    "    \n",
    "    # let's put the neg_log_gauss in the network class aswell since it is key to bayesian networks\n",
    "    def neg_log_gauss( self, outputs, targets ):\n",
    "        mu = outputs[:, 0]\n",
    "        logsigma2 = outputs[:, 1]\n",
    "        out = torch.pow( mu - targets, 2 ) / ( 2 * logsigma2.exp() ) + 1./2. * logsigma2\n",
    "        return torch.mean(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we have a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the neural network and send to the GPU if we have one.  We can also print the model to see what layers it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bayes_amp_net(\n",
      "  (model): Sequential(\n",
      "    (0): VBLinear()\n",
      "    (1): ReLU()\n",
      "    (2): VBLinear()\n",
      "    (3): ReLU()\n",
      "    (4): VBLinear()\n",
      "    (5): ReLU()\n",
      "    (6): VBLinear()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trn_len = trn_amplp.shape[0]\n",
    "hdn_dim = 50\n",
    "model = bayes_amp_net( trn_len, hdn_dim=hdn_dim ).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test it briefly by throwing some random numbers into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(5, 20, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the numbers through the Bayesian network gives us different outputs each time we run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0588,  0.0313],\n",
       "        [-0.3057,  0.0786],\n",
       "        [-0.2172, -0.0391],\n",
       "        [-0.3509,  0.1364],\n",
       "        [-0.1802, -0.0766]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model( X )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note again that the output has the correct shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model( X ).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicitons of the full Bayesian network should vary with each forward pass because of the weight sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1066,  0.0385], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0911,  0.0146], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0795, -0.0063], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0723, -0.0150], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0640,  0.0576], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# print predictions for the same input data\n",
    "for i in range(5):\n",
    "    print(model( X )[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising (training) the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian loss function has two terms which we have already definedl; the negative los Gaussian, and the KL divergence between the network and the network prior.  The latter comes from the KL divergence over the weights in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can write a training loop for a single epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch( dataloader, model, optimizer ):\n",
    "\n",
    "    size = len( dataloader.dataset )\n",
    "    model.train()\n",
    "    loss_tot, kl_tot, neg_log_tot = 0.0, 0.0, 0.0\n",
    "    \n",
    "    for batch, (X, y) in enumerate( dataloader ):\n",
    "        \n",
    "        # pass data through network\n",
    "        pred = model(X)\n",
    "        \n",
    "        # compute loss\n",
    "        nl = model.neg_log_gauss( pred, y.reshape(-1) )\n",
    "        kl = model.KL()\n",
    "        loss = nl + kl\n",
    "        \n",
    "        # reset gradients in optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights with optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print the training loss every 100 updates\n",
    "        if batch % 100 == 0:\n",
    "            current = batch * len( X )\n",
    "            print(f\"current batch loss: {loss:>8f} KL: {kl:>8f} Neg-log {nl:>8f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor the performance of the network on the regression task we want to calculate the loss of both the training data and the validation data on the same network, so we have the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_pass( dataloader, model ):\n",
    "    \n",
    "    size = len( dataloader.dataset )\n",
    "    num_batches = len( dataloader )\n",
    "    nls = 0.0\n",
    "    kls = 0.0\n",
    "    vls = 0.0\n",
    "    mse = 0.0\n",
    "\n",
    "    # we don't need gradients here since we only use the forward pass\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model( X )\n",
    "            nl = model.neg_log_gauss( pred, y.reshape(-1) )\n",
    "            kl = model.KL()\n",
    "            vl = nl.item() + kl.item()\n",
    "            mse += torch.mean((pred[:, 0] - y.reshape(-1))**2)\n",
    "            nls += nl\n",
    "            kls += kl\n",
    "            vls += vl\n",
    "\n",
    "    nls /= num_batches\n",
    "    kls /= num_batches\n",
    "    vls /= num_batches\n",
    "    mse /= num_batches\n",
    "    print( f\"avg val loss per batch: {vls:>8f} KL: {kls:>8f} Neg-log {nls:>8f} MSE {mse:>8}\" )\n",
    "    \n",
    "    return nls, kls, vls, mse\n",
    "\n",
    "def trn_pass( dataloader, model ):\n",
    "    \n",
    "    size = len( dataloader.dataset )\n",
    "    num_batches = len( dataloader )\n",
    "    nls = 0.0\n",
    "    kls = 0.0\n",
    "    tls = 0.0\n",
    "    mse = 0.0\n",
    "\n",
    "    # we don't need gradients here since we only use the forward pass\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model( X )\n",
    "            nl = model.neg_log_gauss( pred, y.reshape(-1) )\n",
    "            kl = model.KL()\n",
    "            tl = nl.item() + kl.item()\n",
    "            mse += torch.mean((pred[:, 0] - y.reshape(-1))**2)\n",
    "            nls += nl\n",
    "            kls += kl\n",
    "            tls += tl\n",
    "\n",
    "    nls /= num_batches\n",
    "    kls /= num_batches\n",
    "    tls /= num_batches\n",
    "    mse /= num_batches\n",
    "    print( f\"avg trn loss per batch: {tls:>8f} KL: {kls:>8f} Neg-log {nls:>8f} MSE {mse:>8}\" )\n",
    "    \n",
    "    return nls, kls, tls, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset length: 30000\n",
      "-----------------------------------------------\n",
      "model architecture \n",
      "-----------------------------------------------\n",
      "bayes_amp_net(\n",
      "  (model): Sequential(\n",
      "    (0): VBLinear()\n",
      "    (1): ReLU()\n",
      "    (2): VBLinear()\n",
      "    (3): ReLU()\n",
      "    (4): VBLinear()\n",
      "    (5): ReLU()\n",
      "    (6): VBLinear()\n",
      "  )\n",
      ")\n",
      "-----------------------------------------------\n",
      "Epoch 1\n",
      "-----------------------------------------------\n",
      "current batch loss: 166.389908 KL: 0.815809 Neg-log 165.574097  [    0/30000]\n",
      "current batch loss: 6.421925 KL: 0.813876 Neg-log 5.608048  [12800/30000]\n",
      "current batch loss: 4.599923 KL: 0.812010 Neg-log 3.787913  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 4.630536 KL: 0.811385 Neg-log 3.819155 MSE 145.4280548095703\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 4.629337 KL: 0.811385 Neg-log 3.817955 MSE 145.0192108154297\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 2\n",
      "-----------------------------------------------\n",
      "current batch loss: 4.561648 KL: 0.811382 Neg-log 3.750266  [    0/30000]\n",
      "current batch loss: 4.367034 KL: 0.809637 Neg-log 3.557397  [12800/30000]\n",
      "current batch loss: 2.706464 KL: 0.807996 Neg-log 1.898468  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 2.752281 KL: 0.807408 Neg-log 1.944872 MSE 101.03401184082031\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 2.744174 KL: 0.807408 Neg-log 1.936766 MSE 102.29891204833984\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 3\n",
      "-----------------------------------------------\n",
      "current batch loss: 2.639491 KL: 0.807409 Neg-log 1.832082  [    0/30000]\n",
      "current batch loss: 2.767677 KL: 0.805732 Neg-log 1.961944  [12800/30000]\n",
      "current batch loss: 2.562927 KL: 0.804052 Neg-log 1.758876  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 2.640255 KL: 0.803463 Neg-log 1.836792 MSE 94.1214599609375\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 2.629693 KL: 0.803463 Neg-log 1.826231 MSE 96.01751708984375\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 4\n",
      "-----------------------------------------------\n",
      "current batch loss: 2.578897 KL: 0.803462 Neg-log 1.775435  [    0/30000]\n",
      "current batch loss: 2.442031 KL: 0.801783 Neg-log 1.640248  [12800/30000]\n",
      "current batch loss: 2.634353 KL: 0.800124 Neg-log 1.834229  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 2.438120 KL: 0.799549 Neg-log 1.638571 MSE 72.62515258789062\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 2.433926 KL: 0.799549 Neg-log 1.634377 MSE 74.32087707519531\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 5\n",
      "-----------------------------------------------\n",
      "current batch loss: 2.544817 KL: 0.799549 Neg-log 1.745268  [    0/30000]\n",
      "current batch loss: 2.308883 KL: 0.797948 Neg-log 1.510935  [12800/30000]\n",
      "current batch loss: 1.886966 KL: 0.796447 Neg-log 1.090519  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1.885878 KL: 0.795940 Neg-log 1.089939 MSE 14.672959327697754\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.887871 KL: 0.795940 Neg-log 1.091931 MSE 15.722001075744629\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 6\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.809393 KL: 0.795939 Neg-log 1.013453  [    0/30000]\n",
      "current batch loss: 1.457255 KL: 0.794511 Neg-log 0.662744  [12800/30000]\n",
      "current batch loss: 1.545472 KL: 0.793127 Neg-log 0.752345  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1.373018 KL: 0.792652 Neg-log 0.580365 MSE 2.525155544281006\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.371579 KL: 0.792652 Neg-log 0.578926 MSE 2.681269884109497\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 7\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.217703 KL: 0.792653 Neg-log 0.425050  [    0/30000]\n",
      "current batch loss: 1.144048 KL: 0.791315 Neg-log 0.352733  [12800/30000]\n",
      "current batch loss: 1.050328 KL: 0.790009 Neg-log 0.260319  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1.170842 KL: 0.789552 Neg-log 0.381289 MSE 1.287898063659668\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.184150 KL: 0.789552 Neg-log 0.394597 MSE 1.3861349821090698\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 8\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.138865 KL: 0.789553 Neg-log 0.349312  [    0/30000]\n",
      "current batch loss: 1.006819 KL: 0.788267 Neg-log 0.218552  [12800/30000]\n",
      "current batch loss: 1.021510 KL: 0.786977 Neg-log 0.234533  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1.114574 KL: 0.786519 Neg-log 0.328052 MSE 1.1960958242416382\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.108818 KL: 0.786519 Neg-log 0.322297 MSE 1.2619736194610596\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 9\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.883249 KL: 0.786521 Neg-log 0.096728  [    0/30000]\n",
      "current batch loss: 1.104638 KL: 0.785226 Neg-log 0.319412  [12800/30000]\n",
      "current batch loss: 0.970166 KL: 0.783945 Neg-log 0.186222  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1.033014 KL: 0.783507 Neg-log 0.249509 MSE 1.0552457571029663\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.100129 KL: 0.783507 Neg-log 0.316624 MSE 1.1598680019378662\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 10\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.279397 KL: 0.783505 Neg-log 0.495892  [    0/30000]\n",
      "current batch loss: 1.106601 KL: 0.782253 Neg-log 0.324348  [12800/30000]\n",
      "current batch loss: 0.944208 KL: 0.780998 Neg-log 0.163210  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.980678 KL: 0.780558 Neg-log 0.200121 MSE 0.9452440738677979\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.019164 KL: 0.780558 Neg-log 0.238607 MSE 1.081207275390625\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 11\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.796219 KL: 0.780556 Neg-log 0.015663  [    0/30000]\n",
      "current batch loss: 1.037411 KL: 0.779301 Neg-log 0.258110  [12800/30000]\n",
      "current batch loss: 1.870342 KL: 0.778048 Neg-log 1.092294  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.975987 KL: 0.777602 Neg-log 0.198387 MSE 0.8662856221199036\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.974407 KL: 0.777602 Neg-log 0.196807 MSE 0.8853015899658203\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 12\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.033247 KL: 0.777600 Neg-log 0.255647  [    0/30000]\n",
      "current batch loss: 0.891747 KL: 0.776337 Neg-log 0.115409  [12800/30000]\n",
      "current batch loss: 0.928453 KL: 0.775072 Neg-log 0.153381  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.964013 KL: 0.774627 Neg-log 0.189387 MSE 0.9846920371055603\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.932960 KL: 0.774627 Neg-log 0.158335 MSE 0.9756649732589722\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 13\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.789956 KL: 0.774625 Neg-log 0.015331  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: 0.781292 KL: 0.773356 Neg-log 0.007936  [12800/30000]\n",
      "current batch loss: 1.124421 KL: 0.772077 Neg-log 0.352344  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.910159 KL: 0.771632 Neg-log 0.138529 MSE 0.8536414504051208\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.932575 KL: 0.771632 Neg-log 0.160944 MSE 0.93007892370224\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 14\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.767457 KL: 0.771630 Neg-log -0.004173  [    0/30000]\n",
      "current batch loss: 0.746486 KL: 0.770360 Neg-log -0.023873  [12800/30000]\n",
      "current batch loss: 0.901205 KL: 0.769096 Neg-log 0.132108  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.852264 KL: 0.768647 Neg-log 0.083616 MSE 0.7513139843940735\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.861117 KL: 0.768647 Neg-log 0.092468 MSE 0.8105694055557251\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 15\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.615449 KL: 0.768649 Neg-log -0.153200  [    0/30000]\n",
      "current batch loss: 0.881277 KL: 0.767387 Neg-log 0.113890  [12800/30000]\n",
      "current batch loss: 0.924887 KL: 0.766138 Neg-log 0.158749  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1.042456 KL: 0.765690 Neg-log 0.276765 MSE 0.8563578724861145\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.026332 KL: 0.765690 Neg-log 0.260641 MSE 0.8437634110450745\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 16\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.040340 KL: 0.765691 Neg-log 0.274649  [    0/30000]\n",
      "current batch loss: 0.740591 KL: 0.764430 Neg-log -0.023838  [12800/30000]\n",
      "current batch loss: 1.305076 KL: 0.763170 Neg-log 0.541906  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.869117 KL: 0.762726 Neg-log 0.106390 MSE 0.8390602469444275\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.888099 KL: 0.762726 Neg-log 0.125373 MSE 0.8856173157691956\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 17\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.601013 KL: 0.762727 Neg-log -0.161714  [    0/30000]\n",
      "current batch loss: 0.964989 KL: 0.761478 Neg-log 0.203511  [12800/30000]\n",
      "current batch loss: 0.810935 KL: 0.760239 Neg-log 0.050696  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.868128 KL: 0.759796 Neg-log 0.108333 MSE 0.7128222584724426\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.885055 KL: 0.759796 Neg-log 0.125259 MSE 0.7281873822212219\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 18\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.006237 KL: 0.759795 Neg-log 0.246441  [    0/30000]\n",
      "current batch loss: 0.667293 KL: 0.758541 Neg-log -0.091248  [12800/30000]\n",
      "current batch loss: 0.713522 KL: 0.757275 Neg-log -0.043753  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1.152596 KL: 0.756826 Neg-log 0.395768 MSE 0.960232138633728\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.153030 KL: 0.756826 Neg-log 0.396202 MSE 0.9528219103813171\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 19\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.138012 KL: 0.756828 Neg-log 0.381184  [    0/30000]\n",
      "current batch loss: 0.651415 KL: 0.755553 Neg-log -0.104138  [12800/30000]\n",
      "current batch loss: 0.554326 KL: 0.754281 Neg-log -0.199955  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1.093891 KL: 0.753835 Neg-log 0.340054 MSE 1.0955853462219238\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.065894 KL: 0.753835 Neg-log 0.312056 MSE 1.1105024814605713\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 20\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.411895 KL: 0.753837 Neg-log -0.341943  [    0/30000]\n",
      "current batch loss: 0.542363 KL: 0.752578 Neg-log -0.210215  [12800/30000]\n",
      "current batch loss: 0.803493 KL: 0.751303 Neg-log 0.052189  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.782912 KL: 0.750859 Neg-log 0.032053 MSE 0.7008046507835388\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.786461 KL: 0.750859 Neg-log 0.035602 MSE 0.7156529426574707\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 21\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.634021 KL: 0.750859 Neg-log -0.116838  [    0/30000]\n",
      "current batch loss: 0.778922 KL: 0.749578 Neg-log 0.029344  [12800/30000]\n",
      "current batch loss: 1.330681 KL: 0.748311 Neg-log 0.582369  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.681560 KL: 0.747869 Neg-log -0.066310 MSE 0.5714227557182312\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.683508 KL: 0.747869 Neg-log -0.064362 MSE 0.5999447703361511\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 22\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.664317 KL: 0.747870 Neg-log -0.083553  [    0/30000]\n",
      "current batch loss: 0.510173 KL: 0.746612 Neg-log -0.236438  [12800/30000]\n",
      "current batch loss: 1.037459 KL: 0.745353 Neg-log 0.292106  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.896361 KL: 0.744914 Neg-log 0.151447 MSE 0.6340301036834717\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.859132 KL: 0.744914 Neg-log 0.114218 MSE 0.6213845014572144\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 23\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.820904 KL: 0.744914 Neg-log 0.075990  [    0/30000]\n",
      "current batch loss: 0.636575 KL: 0.743693 Neg-log -0.107118  [12800/30000]\n",
      "current batch loss: 0.409978 KL: 0.742511 Neg-log -0.332533  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.739706 KL: 0.742107 Neg-log -0.002400 MSE 0.623998761177063\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.775249 KL: 0.742107 Neg-log 0.033142 MSE 0.6637283563613892\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 24\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.563174 KL: 0.742107 Neg-log -0.178932  [    0/30000]\n",
      "current batch loss: 0.442734 KL: 0.740953 Neg-log -0.298218  [12800/30000]\n",
      "current batch loss: 0.558515 KL: 0.739819 Neg-log -0.181303  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.663296 KL: 0.739430 Neg-log -0.076133 MSE 0.5007181763648987\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.600296 KL: 0.739430 Neg-log -0.139133 MSE 0.47096937894821167\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 25\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.471000 KL: 0.739430 Neg-log -0.268430  [    0/30000]\n",
      "current batch loss: 0.670373 KL: 0.738322 Neg-log -0.067948  [12800/30000]\n",
      "current batch loss: 0.679151 KL: 0.737234 Neg-log -0.058082  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.665811 KL: 0.736851 Neg-log -0.071040 MSE 0.4587724208831787\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.674520 KL: 0.736851 Neg-log -0.062331 MSE 0.4668773114681244\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 26\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.701519 KL: 0.736851 Neg-log -0.035332  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: 0.251690 KL: 0.735757 Neg-log -0.484068  [12800/30000]\n",
      "current batch loss: 0.560733 KL: 0.734662 Neg-log -0.173929  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1.047139 KL: 0.734274 Neg-log 0.312863 MSE 0.7343472242355347\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 1.053655 KL: 0.734274 Neg-log 0.319379 MSE 0.7715469002723694\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 27\n",
      "-----------------------------------------------\n",
      "current batch loss: 2.059685 KL: 0.734275 Neg-log 1.325410  [    0/30000]\n",
      "current batch loss: 0.939454 KL: 0.733174 Neg-log 0.206280  [12800/30000]\n",
      "current batch loss: 0.984314 KL: 0.732076 Neg-log 0.252238  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.582473 KL: 0.731685 Neg-log -0.149212 MSE 0.3732471466064453\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.579502 KL: 0.731685 Neg-log -0.152183 MSE 0.39073750376701355\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 28\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.427569 KL: 0.731685 Neg-log -0.304116  [    0/30000]\n",
      "current batch loss: 0.543541 KL: 0.730581 Neg-log -0.187040  [12800/30000]\n",
      "current batch loss: 0.912025 KL: 0.729472 Neg-log 0.182553  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.540466 KL: 0.729081 Neg-log -0.188616 MSE 0.34406721591949463\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.565323 KL: 0.729081 Neg-log -0.163760 MSE 0.37254589796066284\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 29\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.437310 KL: 0.729082 Neg-log -0.291772  [    0/30000]\n",
      "current batch loss: 0.424663 KL: 0.727996 Neg-log -0.303333  [12800/30000]\n",
      "current batch loss: 0.764225 KL: 0.726921 Neg-log 0.037304  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.511942 KL: 0.726542 Neg-log -0.214598 MSE 0.33826547861099243\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.572174 KL: 0.726542 Neg-log -0.154367 MSE 0.3747340440750122\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 30\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.486840 KL: 0.726541 Neg-log -0.239701  [    0/30000]\n",
      "current batch loss: 0.945203 KL: 0.725478 Neg-log 0.219725  [12800/30000]\n",
      "current batch loss: 0.412425 KL: 0.724402 Neg-log -0.311977  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.575517 KL: 0.724028 Neg-log -0.148509 MSE 0.357729434967041\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.603704 KL: 0.724028 Neg-log -0.120323 MSE 0.3844504952430725\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 31\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.619109 KL: 0.724027 Neg-log -0.104918  [    0/30000]\n",
      "current batch loss: 0.461421 KL: 0.722947 Neg-log -0.261527  [12800/30000]\n",
      "current batch loss: 0.491209 KL: 0.721890 Neg-log -0.230681  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.551899 KL: 0.721543 Neg-log -0.169645 MSE 0.3466489315032959\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.566461 KL: 0.721543 Neg-log -0.155084 MSE 0.3562380075454712\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 32\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.490329 KL: 0.721544 Neg-log -0.231215  [    0/30000]\n",
      "current batch loss: 0.612365 KL: 0.720529 Neg-log -0.108164  [12800/30000]\n",
      "current batch loss: 0.197054 KL: 0.719553 Neg-log -0.522499  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.743694 KL: 0.719207 Neg-log 0.024488 MSE 0.501334547996521\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.772871 KL: 0.719207 Neg-log 0.053664 MSE 0.5103932023048401\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 33\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.872084 KL: 0.719207 Neg-log 0.152877  [    0/30000]\n",
      "current batch loss: 1.396167 KL: 0.718219 Neg-log 0.677949  [12800/30000]\n",
      "current batch loss: 0.279945 KL: 0.717230 Neg-log -0.437285  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.748826 KL: 0.716884 Neg-log 0.031943 MSE 0.49973636865615845\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.738845 KL: 0.716884 Neg-log 0.021962 MSE 0.48321500420570374\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 34\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.311382 KL: 0.716883 Neg-log -0.405501  [    0/30000]\n",
      "current batch loss: 0.475130 KL: 0.715884 Neg-log -0.240754  [12800/30000]\n",
      "current batch loss: 0.290966 KL: 0.714878 Neg-log -0.423913  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.486052 KL: 0.714525 Neg-log -0.228474 MSE 0.2826566994190216\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.486251 KL: 0.714525 Neg-log -0.228275 MSE 0.2736341655254364\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 35\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.473951 KL: 0.714526 Neg-log -0.240575  [    0/30000]\n",
      "current batch loss: 0.940732 KL: 0.713500 Neg-log 0.227232  [12800/30000]\n",
      "current batch loss: 0.191925 KL: 0.712487 Neg-log -0.520563  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.464288 KL: 0.712132 Neg-log -0.247845 MSE 0.28221389651298523\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.429077 KL: 0.712132 Neg-log -0.283056 MSE 0.2646777927875519\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 36\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.705163 KL: 0.712133 Neg-log -0.006970  [    0/30000]\n",
      "current batch loss: 0.235941 KL: 0.711098 Neg-log -0.475157  [12800/30000]\n",
      "current batch loss: 0.188741 KL: 0.710078 Neg-log -0.521336  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.688152 KL: 0.709727 Neg-log -0.021574 MSE 0.4505011737346649\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.643975 KL: 0.709727 Neg-log -0.065751 MSE 0.4297463297843933\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 37\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.477292 KL: 0.709726 Neg-log -0.232435  [    0/30000]\n",
      "current batch loss: 0.067273 KL: 0.708704 Neg-log -0.641431  [12800/30000]\n",
      "current batch loss: 0.119089 KL: 0.707692 Neg-log -0.588603  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.373872 KL: 0.707337 Neg-log -0.333465 MSE 0.27280014753341675\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.386945 KL: 0.707337 Neg-log -0.320392 MSE 0.28434088826179504\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 38\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.662375 KL: 0.707337 Neg-log -0.044962  [    0/30000]\n",
      "current batch loss: 0.298298 KL: 0.706335 Neg-log -0.408037  [12800/30000]\n",
      "current batch loss: 0.237036 KL: 0.705346 Neg-log -0.468310  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.435633 KL: 0.705013 Neg-log -0.269380 MSE 0.2981981337070465\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.425207 KL: 0.705013 Neg-log -0.279806 MSE 0.29489070177078247\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 39\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.628906 KL: 0.705013 Neg-log -0.076107  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: 0.265572 KL: 0.704050 Neg-log -0.438479  [12800/30000]\n",
      "current batch loss: 0.185980 KL: 0.703102 Neg-log -0.517122  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.780762 KL: 0.702769 Neg-log 0.077993 MSE 0.5381796956062317\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.875189 KL: 0.702769 Neg-log 0.172420 MSE 0.5998108983039856\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 40\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.133373 KL: 0.702769 Neg-log 0.430605  [    0/30000]\n",
      "current batch loss: 0.403564 KL: 0.701810 Neg-log -0.298246  [12800/30000]\n",
      "current batch loss: 0.238435 KL: 0.700819 Neg-log -0.462385  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.335500 KL: 0.700479 Neg-log -0.364979 MSE 0.2798926532268524\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.320206 KL: 0.700479 Neg-log -0.380273 MSE 0.2745649218559265\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 41\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.238475 KL: 0.700478 Neg-log -0.462004  [    0/30000]\n",
      "current batch loss: 0.292708 KL: 0.699486 Neg-log -0.406777  [12800/30000]\n",
      "current batch loss: 0.043121 KL: 0.698494 Neg-log -0.655373  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.557095 KL: 0.698166 Neg-log -0.141071 MSE 0.3521559238433838\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.572070 KL: 0.698166 Neg-log -0.126096 MSE 0.3582283556461334\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 42\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.812399 KL: 0.698166 Neg-log 0.114234  [    0/30000]\n",
      "current batch loss: 0.190609 KL: 0.697202 Neg-log -0.506593  [12800/30000]\n",
      "current batch loss: 0.414970 KL: 0.696234 Neg-log -0.281264  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.327255 KL: 0.695891 Neg-log -0.368634 MSE 0.2520986497402191\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.299526 KL: 0.695891 Neg-log -0.396363 MSE 0.24653702974319458\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 43\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.119418 KL: 0.695889 Neg-log -0.576471  [    0/30000]\n",
      "current batch loss: 0.187082 KL: 0.694909 Neg-log -0.507827  [12800/30000]\n",
      "current batch loss: 0.102140 KL: 0.693940 Neg-log -0.591800  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.602421 KL: 0.693602 Neg-log -0.091179 MSE 0.4155269265174866\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.570304 KL: 0.693602 Neg-log -0.123297 MSE 0.38854098320007324\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 44\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.624267 KL: 0.693600 Neg-log -0.069333  [    0/30000]\n",
      "current batch loss: 0.750015 KL: 0.692626 Neg-log 0.057389  [12800/30000]\n",
      "current batch loss: 0.131235 KL: 0.691646 Neg-log -0.560412  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.247163 KL: 0.691313 Neg-log -0.444149 MSE 0.2316247969865799\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.177819 KL: 0.691313 Neg-log -0.513493 MSE 0.21516942977905273\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 45\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.001508 KL: 0.691312 Neg-log -0.692820  [    0/30000]\n",
      "current batch loss: 0.713297 KL: 0.690360 Neg-log 0.022937  [12800/30000]\n",
      "current batch loss: 0.096214 KL: 0.689396 Neg-log -0.593182  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.290818 KL: 0.689067 Neg-log -0.398249 MSE 0.23063910007476807\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.244939 KL: 0.689067 Neg-log -0.444128 MSE 0.20942720770835876\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 46\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.210924 KL: 0.689067 Neg-log -0.478143  [    0/30000]\n",
      "current batch loss: 0.271960 KL: 0.688097 Neg-log -0.416137  [12800/30000]\n",
      "current batch loss: -0.011635 KL: 0.687142 Neg-log -0.698777  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.888762 KL: 0.686804 Neg-log 0.201958 MSE 0.592301070690155\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.941542 KL: 0.686804 Neg-log 0.254738 MSE 0.6480714678764343\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 47\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.148611 KL: 0.686804 Neg-log -0.538193  [    0/30000]\n",
      "current batch loss: 0.431110 KL: 0.685826 Neg-log -0.254716  [12800/30000]\n",
      "current batch loss: 0.553585 KL: 0.684875 Neg-log -0.131290  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.515428 KL: 0.684541 Neg-log -0.169116 MSE 0.3501565456390381\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.529727 KL: 0.684541 Neg-log -0.154816 MSE 0.3659597933292389\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 48\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.645570 KL: 0.684543 Neg-log -0.038974  [    0/30000]\n",
      "current batch loss: 0.369509 KL: 0.683580 Neg-log -0.314071  [12800/30000]\n",
      "current batch loss: 0.226500 KL: 0.682627 Neg-log -0.456127  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.211547 KL: 0.682295 Neg-log -0.470746 MSE 0.21249039471149445\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.195278 KL: 0.682295 Neg-log -0.487016 MSE 0.20849567651748657\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 49\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.182090 KL: 0.682294 Neg-log -0.500204  [    0/30000]\n",
      "current batch loss: -0.088822 KL: 0.681324 Neg-log -0.770146  [12800/30000]\n",
      "current batch loss: 0.354958 KL: 0.680353 Neg-log -0.325396  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.281771 KL: 0.680023 Neg-log -0.398253 MSE 0.2164534330368042\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.274434 KL: 0.680023 Neg-log -0.405590 MSE 0.21422813832759857\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 50\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.202679 KL: 0.680024 Neg-log -0.477345  [    0/30000]\n",
      "current batch loss: 0.075587 KL: 0.679080 Neg-log -0.603493  [12800/30000]\n",
      "current batch loss: 0.692295 KL: 0.678134 Neg-log 0.014161  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.392075 KL: 0.677812 Neg-log -0.285738 MSE 0.2832936644554138\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.345314 KL: 0.677812 Neg-log -0.332499 MSE 0.28300905227661133\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 51\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.101826 KL: 0.677813 Neg-log -0.779640  [    0/30000]\n",
      "current batch loss: -0.065226 KL: 0.676886 Neg-log -0.742112  [12800/30000]\n",
      "current batch loss: 0.534294 KL: 0.675965 Neg-log -0.141671  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.282566 KL: 0.675649 Neg-log -0.393083 MSE 0.251750111579895\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.302778 KL: 0.675649 Neg-log -0.372870 MSE 0.256779283285141\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 52\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.232054 KL: 0.675649 Neg-log -0.443594  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: 0.076022 KL: 0.674734 Neg-log -0.598712  [12800/30000]\n",
      "current batch loss: 0.203019 KL: 0.673826 Neg-log -0.470807  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.139043 KL: 0.673508 Neg-log -0.534464 MSE 0.19339749217033386\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.155752 KL: 0.673508 Neg-log -0.517755 MSE 0.19455569982528687\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 53\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.046482 KL: 0.673507 Neg-log -0.627025  [    0/30000]\n",
      "current batch loss: 0.820847 KL: 0.672617 Neg-log 0.148230  [12800/30000]\n",
      "current batch loss: -0.024227 KL: 0.671716 Neg-log -0.695943  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.189099 KL: 0.671412 Neg-log -0.482313 MSE 0.20372642576694489\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.184357 KL: 0.671412 Neg-log -0.487055 MSE 0.20680947601795197\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 54\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.019908 KL: 0.671412 Neg-log -0.691320  [    0/30000]\n",
      "current batch loss: 0.004513 KL: 0.670548 Neg-log -0.666035  [12800/30000]\n",
      "current batch loss: 0.941729 KL: 0.669687 Neg-log 0.272042  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.195516 KL: 0.669378 Neg-log -0.473861 MSE 0.20456591248512268\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.181280 KL: 0.669378 Neg-log -0.488098 MSE 0.1950627714395523\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 55\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.042411 KL: 0.669378 Neg-log -0.626966  [    0/30000]\n",
      "current batch loss: 0.970984 KL: 0.668492 Neg-log 0.302492  [12800/30000]\n",
      "current batch loss: -0.020899 KL: 0.667607 Neg-log -0.688506  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.582735 KL: 0.667297 Neg-log -0.084562 MSE 0.36163538694381714\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.526060 KL: 0.667297 Neg-log -0.141237 MSE 0.35944151878356934\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 56\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.257070 KL: 0.667297 Neg-log -0.410227  [    0/30000]\n",
      "current batch loss: 0.308415 KL: 0.666401 Neg-log -0.357986  [12800/30000]\n",
      "current batch loss: 0.021536 KL: 0.665524 Neg-log -0.643989  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.279273 KL: 0.665213 Neg-log -0.385940 MSE 0.2161547690629959\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.326203 KL: 0.665213 Neg-log -0.339010 MSE 0.24544191360473633\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 57\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.176458 KL: 0.665213 Neg-log -0.841671  [    0/30000]\n",
      "current batch loss: 0.056465 KL: 0.664335 Neg-log -0.607870  [12800/30000]\n",
      "current batch loss: 0.085178 KL: 0.663453 Neg-log -0.578275  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.586626 KL: 0.663141 Neg-log -0.076514 MSE 0.36562010645866394\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.522382 KL: 0.663141 Neg-log -0.140758 MSE 0.3434934914112091\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 58\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.132331 KL: 0.663139 Neg-log -0.530809  [    0/30000]\n",
      "current batch loss: -0.025261 KL: 0.662243 Neg-log -0.687504  [12800/30000]\n",
      "current batch loss: 0.012179 KL: 0.661362 Neg-log -0.649183  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.182567 KL: 0.661062 Neg-log -0.478495 MSE 0.18753363192081451\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.204671 KL: 0.661062 Neg-log -0.456391 MSE 0.20489762723445892\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 59\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.007792 KL: 0.661062 Neg-log -0.653270  [    0/30000]\n",
      "current batch loss: -0.102663 KL: 0.660181 Neg-log -0.762844  [12800/30000]\n",
      "current batch loss: 0.541879 KL: 0.659289 Neg-log -0.117410  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.508809 KL: 0.658996 Neg-log -0.150186 MSE 0.36590176820755005\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.515445 KL: 0.658996 Neg-log -0.143549 MSE 0.37590497732162476\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 60\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.167515 KL: 0.658995 Neg-log -0.491480  [    0/30000]\n",
      "current batch loss: -0.179935 KL: 0.658122 Neg-log -0.838057  [12800/30000]\n",
      "current batch loss: 0.428290 KL: 0.657272 Neg-log -0.228982  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.094582 KL: 0.656973 Neg-log -0.562391 MSE 0.16938002407550812\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.128932 KL: 0.656973 Neg-log -0.528041 MSE 0.1858755201101303\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 61\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.265258 KL: 0.656974 Neg-log -0.391716  [    0/30000]\n",
      "current batch loss: -0.015385 KL: 0.656134 Neg-log -0.671519  [12800/30000]\n",
      "current batch loss: -0.114089 KL: 0.655303 Neg-log -0.769392  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.482571 KL: 0.655008 Neg-log -0.172436 MSE 0.34192201495170593\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.509556 KL: 0.655008 Neg-log -0.145451 MSE 0.3506982624530792\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 62\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.375780 KL: 0.655007 Neg-log -0.279227  [    0/30000]\n",
      "current batch loss: 0.118771 KL: 0.654172 Neg-log -0.535401  [12800/30000]\n",
      "current batch loss: -0.240626 KL: 0.653350 Neg-log -0.893976  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.056260 KL: 0.653070 Neg-log -0.596808 MSE 0.162968710064888\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.054300 KL: 0.653070 Neg-log -0.598768 MSE 0.16476328670978546\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 63\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.218686 KL: 0.653069 Neg-log -0.871755  [    0/30000]\n",
      "current batch loss: -0.151697 KL: 0.652254 Neg-log -0.803951  [12800/30000]\n",
      "current batch loss: -0.190888 KL: 0.651421 Neg-log -0.842309  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.010348 KL: 0.651138 Neg-log -0.640790 MSE 0.15144047141075134\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.021480 KL: 0.651138 Neg-log -0.629658 MSE 0.15683874487876892\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 64\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.037104 KL: 0.651138 Neg-log -0.614034  [    0/30000]\n",
      "current batch loss: -0.122530 KL: 0.650317 Neg-log -0.772847  [12800/30000]\n",
      "current batch loss: 0.047056 KL: 0.649511 Neg-log -0.602456  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.134161 KL: 0.649246 Neg-log -0.515084 MSE 0.18381793797016144\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.119531 KL: 0.649246 Neg-log -0.529715 MSE 0.1792251467704773\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 65\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.147783 KL: 0.649245 Neg-log -0.501462  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: 0.710941 KL: 0.648446 Neg-log 0.062496  [12800/30000]\n",
      "current batch loss: -0.097433 KL: 0.647644 Neg-log -0.745077  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.041178 KL: 0.647374 Neg-log -0.606196 MSE 0.15268108248710632\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.026863 KL: 0.647374 Neg-log -0.620511 MSE 0.14528286457061768\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 66\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.097052 KL: 0.647374 Neg-log -0.550322  [    0/30000]\n",
      "current batch loss: -0.099691 KL: 0.646583 Neg-log -0.746275  [12800/30000]\n",
      "current batch loss: -0.176513 KL: 0.645794 Neg-log -0.822307  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.141098 KL: 0.645524 Neg-log -0.504427 MSE 0.20757700502872467\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.189338 KL: 0.645524 Neg-log -0.456188 MSE 0.22464950382709503\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 67\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.117210 KL: 0.645525 Neg-log -0.762735  [    0/30000]\n",
      "current batch loss: 0.093280 KL: 0.644748 Neg-log -0.551468  [12800/30000]\n",
      "current batch loss: 0.347728 KL: 0.643972 Neg-log -0.296244  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.015268 KL: 0.643692 Neg-log -0.658962 MSE 0.14612708985805511\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.006513 KL: 0.643692 Neg-log -0.650207 MSE 0.1514252871274948\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 68\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.191314 KL: 0.643693 Neg-log -0.835008  [    0/30000]\n",
      "current batch loss: 0.038617 KL: 0.642925 Neg-log -0.604308  [12800/30000]\n",
      "current batch loss: -0.086712 KL: 0.642163 Neg-log -0.728876  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.015915 KL: 0.641896 Neg-log -0.657811 MSE 0.15188997983932495\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.018440 KL: 0.641896 Neg-log -0.660336 MSE 0.14991985261440277\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 69\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.186717 KL: 0.641896 Neg-log -0.828613  [    0/30000]\n",
      "current batch loss: -0.222325 KL: 0.641134 Neg-log -0.863458  [12800/30000]\n",
      "current batch loss: -0.198657 KL: 0.640381 Neg-log -0.839038  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.076106 KL: 0.640131 Neg-log -0.564025 MSE 0.15307490527629852\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.076658 KL: 0.640131 Neg-log -0.563473 MSE 0.159284308552742\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 70\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.041465 KL: 0.640131 Neg-log -0.681596  [    0/30000]\n",
      "current batch loss: -0.096140 KL: 0.639375 Neg-log -0.735515  [12800/30000]\n",
      "current batch loss: 0.162620 KL: 0.638639 Neg-log -0.476019  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.146507 KL: 0.638375 Neg-log -0.491868 MSE 0.2000514417886734\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.172167 KL: 0.638375 Neg-log -0.466208 MSE 0.2139420509338379\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 71\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.041242 KL: 0.638375 Neg-log -0.597133  [    0/30000]\n",
      "current batch loss: 0.399971 KL: 0.637647 Neg-log -0.237676  [12800/30000]\n",
      "current batch loss: 1.268533 KL: 0.636971 Neg-log 0.631563  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.062684 KL: 0.636743 Neg-log -0.574059 MSE 0.16819828748703003\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.140158 KL: 0.636743 Neg-log -0.496584 MSE 0.18899407982826233\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 72\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.108975 KL: 0.636742 Neg-log -0.745717  [    0/30000]\n",
      "current batch loss: -0.180362 KL: 0.636075 Neg-log -0.816437  [12800/30000]\n",
      "current batch loss: 0.981004 KL: 0.635427 Neg-log 0.345576  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.138747 KL: 0.635199 Neg-log -0.496453 MSE 0.1888524740934372\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.096620 KL: 0.635199 Neg-log -0.538580 MSE 0.17194807529449463\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 73\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.666375 KL: 0.635200 Neg-log 0.031175  [    0/30000]\n",
      "current batch loss: -0.166526 KL: 0.634536 Neg-log -0.801062  [12800/30000]\n",
      "current batch loss: -0.023863 KL: 0.633880 Neg-log -0.657743  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.003961 KL: 0.633652 Neg-log -0.637614 MSE 0.14856769144535065\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.013534 KL: 0.633652 Neg-log -0.647187 MSE 0.13961386680603027\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 74\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.105419 KL: 0.633653 Neg-log -0.739072  [    0/30000]\n",
      "current batch loss: -0.012539 KL: 0.632987 Neg-log -0.645527  [12800/30000]\n",
      "current batch loss: -0.360435 KL: 0.632329 Neg-log -0.992764  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.049339 KL: 0.632111 Neg-log -0.681449 MSE 0.13207122683525085\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.037926 KL: 0.632111 Neg-log -0.670037 MSE 0.13925766944885254\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 75\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.268663 KL: 0.632111 Neg-log -0.900773  [    0/30000]\n",
      "current batch loss: -0.215080 KL: 0.631466 Neg-log -0.846546  [12800/30000]\n",
      "current batch loss: -0.138282 KL: 0.630818 Neg-log -0.769100  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.225376 KL: 0.630590 Neg-log -0.405214 MSE 0.2279483675956726\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.228749 KL: 0.630590 Neg-log -0.401841 MSE 0.23203183710575104\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 76\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.094131 KL: 0.630590 Neg-log -0.724721  [    0/30000]\n",
      "current batch loss: 0.056734 KL: 0.629923 Neg-log -0.573190  [12800/30000]\n",
      "current batch loss: -0.144120 KL: 0.629300 Neg-log -0.773420  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.062576 KL: 0.629079 Neg-log -0.566503 MSE 0.16257429122924805\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.079773 KL: 0.629079 Neg-log -0.549306 MSE 0.17113681137561798\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 77\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.222938 KL: 0.629079 Neg-log -0.852017  [    0/30000]\n",
      "current batch loss: 0.559865 KL: 0.628462 Neg-log -0.068597  [12800/30000]\n",
      "current batch loss: 0.188830 KL: 0.627824 Neg-log -0.438994  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.108938 KL: 0.627600 Neg-log -0.518663 MSE 0.20453524589538574\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.074314 KL: 0.627600 Neg-log -0.553286 MSE 0.19512656331062317\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 78\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.129671 KL: 0.627601 Neg-log -0.757272  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: 0.169085 KL: 0.626964 Neg-log -0.457879  [12800/30000]\n",
      "current batch loss: -0.247504 KL: 0.626356 Neg-log -0.873860  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.045749 KL: 0.626146 Neg-log -0.671896 MSE 0.14252755045890808\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.061862 KL: 0.626146 Neg-log -0.688010 MSE 0.1390758603811264\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 79\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.184863 KL: 0.626147 Neg-log -0.811010  [    0/30000]\n",
      "current batch loss: -0.124812 KL: 0.625565 Neg-log -0.750378  [12800/30000]\n",
      "current batch loss: -0.222846 KL: 0.624971 Neg-log -0.847817  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.092414 KL: 0.624762 Neg-log -0.717177 MSE 0.1284596472978592\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.118478 KL: 0.624762 Neg-log -0.743241 MSE 0.12500549852848053\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 80\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.177050 KL: 0.624763 Neg-log -0.447713  [    0/30000]\n",
      "current batch loss: 0.173932 KL: 0.624189 Neg-log -0.450257  [12800/30000]\n",
      "current batch loss: -0.357744 KL: 0.623603 Neg-log -0.981347  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.096800 KL: 0.623403 Neg-log -0.720203 MSE 0.13322392106056213\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.088585 KL: 0.623403 Neg-log -0.711987 MSE 0.13507820665836334\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 81\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.027794 KL: 0.623402 Neg-log -0.651197  [    0/30000]\n",
      "current batch loss: 0.091832 KL: 0.622850 Neg-log -0.531018  [12800/30000]\n",
      "current batch loss: 0.167218 KL: 0.622288 Neg-log -0.455070  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.093884 KL: 0.622087 Neg-log -0.715972 MSE 0.12489529699087143\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.057017 KL: 0.622087 Neg-log -0.679105 MSE 0.13285690546035767\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 82\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.266815 KL: 0.622088 Neg-log -0.888903  [    0/30000]\n",
      "current batch loss: -0.308752 KL: 0.621535 Neg-log -0.930288  [12800/30000]\n",
      "current batch loss: -0.003180 KL: 0.620980 Neg-log -0.624160  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.173650 KL: 0.620795 Neg-log -0.794445 MSE 0.11327426880598068\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.154603 KL: 0.620795 Neg-log -0.775399 MSE 0.109507717192173\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 83\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.418850 KL: 0.620795 Neg-log -1.039645  [    0/30000]\n",
      "current batch loss: -0.146901 KL: 0.620274 Neg-log -0.767175  [12800/30000]\n",
      "current batch loss: 0.279316 KL: 0.619748 Neg-log -0.340432  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.109368 KL: 0.619561 Neg-log -0.728928 MSE 0.12244226783514023\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.075771 KL: 0.619561 Neg-log -0.695332 MSE 0.13032162189483643\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 84\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.007643 KL: 0.619561 Neg-log -0.611917  [    0/30000]\n",
      "current batch loss: -0.353415 KL: 0.619021 Neg-log -0.972436  [12800/30000]\n",
      "current batch loss: -0.360609 KL: 0.618492 Neg-log -0.979101  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.137637 KL: 0.618315 Neg-log -0.755951 MSE 0.10973910242319107\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.151750 KL: 0.618315 Neg-log -0.770064 MSE 0.10801941156387329\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 85\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.290198 KL: 0.618314 Neg-log -0.908512  [    0/30000]\n",
      "current batch loss: -0.306743 KL: 0.617795 Neg-log -0.924538  [12800/30000]\n",
      "current batch loss: -0.027061 KL: 0.617271 Neg-log -0.644332  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.181412 KL: 0.617087 Neg-log -0.798498 MSE 0.10804609209299088\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.154868 KL: 0.617087 Neg-log -0.771954 MSE 0.11742077767848969\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 86\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.040278 KL: 0.617086 Neg-log -0.576808  [    0/30000]\n",
      "current batch loss: 0.390812 KL: 0.616576 Neg-log -0.225764  [12800/30000]\n",
      "current batch loss: -0.161452 KL: 0.616065 Neg-log -0.777517  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.112480 KL: 0.615891 Neg-log -0.728372 MSE 0.10616029053926468\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.117894 KL: 0.615891 Neg-log -0.733786 MSE 0.11086074262857437\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 87\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.111603 KL: 0.615892 Neg-log -0.727496  [    0/30000]\n",
      "current batch loss: -0.261010 KL: 0.615403 Neg-log -0.876413  [12800/30000]\n",
      "current batch loss: -0.166090 KL: 0.614913 Neg-log -0.781003  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.135896 KL: 0.614739 Neg-log -0.750635 MSE 0.10812479257583618\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.132332 KL: 0.614739 Neg-log -0.747070 MSE 0.11289376020431519\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 88\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.002463 KL: 0.614739 Neg-log -0.617202  [    0/30000]\n",
      "current batch loss: 0.130732 KL: 0.614231 Neg-log -0.483499  [12800/30000]\n",
      "current batch loss: -0.444526 KL: 0.613722 Neg-log -1.058248  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.229175 KL: 0.613555 Neg-log -0.842729 MSE 0.09478835761547089\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.180922 KL: 0.613555 Neg-log -0.794476 MSE 0.10799645632505417\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 89\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.243379 KL: 0.613554 Neg-log -0.856933  [    0/30000]\n",
      "current batch loss: -0.306136 KL: 0.613051 Neg-log -0.919187  [12800/30000]\n",
      "current batch loss: -0.352241 KL: 0.612539 Neg-log -0.964781  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.047022 KL: 0.612351 Neg-log -0.659373 MSE 0.12932950258255005\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.001458 KL: 0.612351 Neg-log -0.613810 MSE 0.14657051861286163\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 90\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.269897 KL: 0.612351 Neg-log -0.342454  [    0/30000]\n",
      "current batch loss: 0.292542 KL: 0.611827 Neg-log -0.319285  [12800/30000]\n",
      "current batch loss: 2.000650 KL: 0.611322 Neg-log 1.389328  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.155812 KL: 0.611136 Neg-log -0.766948 MSE 0.10022766143083572\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -0.137102 KL: 0.611136 Neg-log -0.748238 MSE 0.10665684938430786\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 91\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.275370 KL: 0.611136 Neg-log -0.335766  [    0/30000]\n",
      "current batch loss: -0.304921 KL: 0.610637 Neg-log -0.915559  [12800/30000]\n",
      "current batch loss: 0.969881 KL: 0.610129 Neg-log 0.359752  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.151352 KL: 0.609948 Neg-log -0.761300 MSE 0.13101966679096222\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.140905 KL: 0.609948 Neg-log -0.750853 MSE 0.1360824555158615\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 92\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.023175 KL: 0.609948 Neg-log -0.633123  [    0/30000]\n",
      "current batch loss: -0.287845 KL: 0.609472 Neg-log -0.897317  [12800/30000]\n",
      "current batch loss: 0.028375 KL: 0.609010 Neg-log -0.580635  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.028819 KL: 0.608842 Neg-log -0.637662 MSE 0.15160338580608368\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.047906 KL: 0.608842 Neg-log -0.560937 MSE 0.16396543383598328\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 93\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.336415 KL: 0.608843 Neg-log -0.272428  [    0/30000]\n",
      "current batch loss: -0.121991 KL: 0.608361 Neg-log -0.730353  [12800/30000]\n",
      "current batch loss: -0.053164 KL: 0.607876 Neg-log -0.661040  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.222147 KL: 0.607711 Neg-log -0.829857 MSE 0.10118783265352249\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.150057 KL: 0.607711 Neg-log -0.757767 MSE 0.1162993460893631\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 94\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.641057 KL: 0.607710 Neg-log 0.033346  [    0/30000]\n",
      "current batch loss: -0.407218 KL: 0.607248 Neg-log -1.014466  [12800/30000]\n",
      "current batch loss: 0.288532 KL: 0.606782 Neg-log -0.318249  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.134138 KL: 0.606620 Neg-log -0.740758 MSE 0.11836405098438263\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.164099 KL: 0.606620 Neg-log -0.770718 MSE 0.11288068443536758\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 95\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.478403 KL: 0.606619 Neg-log -0.128216  [    0/30000]\n",
      "current batch loss: -0.398583 KL: 0.606168 Neg-log -1.004751  [12800/30000]\n",
      "current batch loss: -0.086288 KL: 0.605734 Neg-log -0.692022  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.132386 KL: 0.605582 Neg-log -0.737968 MSE 0.11903872340917587\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.117410 KL: 0.605582 Neg-log -0.722991 MSE 0.12438274174928665\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 96\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.161026 KL: 0.605581 Neg-log -0.444556  [    0/30000]\n",
      "current batch loss: 2.788197 KL: 0.605164 Neg-log 2.183033  [12800/30000]\n",
      "current batch loss: -0.385922 KL: 0.604766 Neg-log -0.990688  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.179204 KL: 0.604620 Neg-log -0.783823 MSE 0.10498631745576859\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.179150 KL: 0.604620 Neg-log -0.783769 MSE 0.1036452054977417\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 97\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.281427 KL: 0.604619 Neg-log -0.886046  [    0/30000]\n",
      "current batch loss: -0.312344 KL: 0.604257 Neg-log -0.916601  [12800/30000]\n",
      "current batch loss: -0.304564 KL: 0.603942 Neg-log -0.908506  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.025252 KL: 0.603829 Neg-log -0.629081 MSE 0.13957498967647552\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.034893 KL: 0.603829 Neg-log -0.638723 MSE 0.13824333250522614\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 98\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.207540 KL: 0.603829 Neg-log -0.811369  [    0/30000]\n",
      "current batch loss: 0.076280 KL: 0.603506 Neg-log -0.527226  [12800/30000]\n",
      "current batch loss: -0.264455 KL: 0.603176 Neg-log -0.867631  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.233198 KL: 0.603059 Neg-log -0.836258 MSE 0.09519549459218979\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.237494 KL: 0.603059 Neg-log -0.840555 MSE 0.1001540794968605\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 99\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.318956 KL: 0.603061 Neg-log -0.922017  [    0/30000]\n",
      "current batch loss: -0.273581 KL: 0.602725 Neg-log -0.876306  [12800/30000]\n",
      "current batch loss: -0.348403 KL: 0.602387 Neg-log -0.950791  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.240633 KL: 0.602271 Neg-log -0.842905 MSE 0.09665607661008835\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.260570 KL: 0.602271 Neg-log -0.862841 MSE 0.09421755373477936\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 100\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.388424 KL: 0.602272 Neg-log -0.990696  [    0/30000]\n",
      "current batch loss: -0.347055 KL: 0.601951 Neg-log -0.949006  [12800/30000]\n",
      "current batch loss: -0.442760 KL: 0.601614 Neg-log -1.044374  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.193938 KL: 0.601500 Neg-log -0.795437 MSE 0.10347377508878708\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.173291 KL: 0.601500 Neg-log -0.774790 MSE 0.11058415472507477\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 101\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.370038 KL: 0.601499 Neg-log -0.971537  [    0/30000]\n",
      "current batch loss: -0.247407 KL: 0.601161 Neg-log -0.848568  [12800/30000]\n",
      "current batch loss: 0.686234 KL: 0.600844 Neg-log 0.085390  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.183806 KL: 0.600754 Neg-log -0.784561 MSE 0.13627953827381134\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.177669 KL: 0.600754 Neg-log -0.778424 MSE 0.14024072885513306\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 102\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.075707 KL: 0.600755 Neg-log -0.525048  [    0/30000]\n",
      "current batch loss: 0.302812 KL: 0.600480 Neg-log -0.297668  [12800/30000]\n",
      "current batch loss: -0.220118 KL: 0.600203 Neg-log -0.820321  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.111009 KL: 0.600106 Neg-log -0.711115 MSE 0.11968870460987091\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.131643 KL: 0.600106 Neg-log -0.731749 MSE 0.1185903325676918\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 103\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.501356 KL: 0.600106 Neg-log -1.101462  [    0/30000]\n",
      "current batch loss: 0.105451 KL: 0.599841 Neg-log -0.494389  [12800/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -0.167525 KL: 0.599571 Neg-log -0.767096  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.295774 KL: 0.599472 Neg-log -0.895247 MSE 0.09382954239845276\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.304690 KL: 0.599472 Neg-log -0.904163 MSE 0.09316863119602203\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 104\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.327907 KL: 0.599473 Neg-log -0.927380  [    0/30000]\n",
      "current batch loss: -0.389447 KL: 0.599193 Neg-log -0.988640  [12800/30000]\n",
      "current batch loss: -0.354919 KL: 0.598923 Neg-log -0.953843  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.351561 KL: 0.598825 Neg-log -0.950387 MSE 0.08391109853982925\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.315897 KL: 0.598825 Neg-log -0.914722 MSE 0.09205316752195358\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 105\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.305581 KL: 0.598825 Neg-log -0.904406  [    0/30000]\n",
      "current batch loss: -0.525514 KL: 0.598570 Neg-log -1.124084  [12800/30000]\n",
      "current batch loss: -0.373440 KL: 0.598302 Neg-log -0.971742  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.561920 KL: 0.598215 Neg-log -0.036295 MSE 0.33200645446777344\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.602484 KL: 0.598215 Neg-log 0.004269 MSE 0.3321020305156708\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 106\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.250623 KL: 0.598215 Neg-log 0.652408  [    0/30000]\n",
      "current batch loss: -0.530711 KL: 0.597944 Neg-log -1.128655  [12800/30000]\n",
      "current batch loss: -0.136135 KL: 0.597675 Neg-log -0.733810  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.169101 KL: 0.597587 Neg-log -0.766686 MSE 0.10504366457462311\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.148093 KL: 0.597587 Neg-log -0.745678 MSE 0.11310875415802002\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 107\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.098269 KL: 0.597586 Neg-log -0.499317  [    0/30000]\n",
      "current batch loss: -0.279007 KL: 0.597333 Neg-log -0.876340  [12800/30000]\n",
      "current batch loss: -0.145706 KL: 0.597090 Neg-log -0.742797  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.348436 KL: 0.597002 Neg-log -0.945439 MSE 0.08745963126420975\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.325614 KL: 0.597002 Neg-log -0.922617 MSE 0.08790470659732819\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 108\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.409801 KL: 0.597003 Neg-log -1.006803  [    0/30000]\n",
      "current batch loss: -0.397332 KL: 0.596752 Neg-log -0.994084  [12800/30000]\n",
      "current batch loss: -0.364364 KL: 0.596493 Neg-log -0.960857  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.333915 KL: 0.596405 Neg-log -0.930320 MSE 0.08407812565565109\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.345468 KL: 0.596405 Neg-log -0.941874 MSE 0.08412184566259384\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 109\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.533838 KL: 0.596405 Neg-log -1.130243  [    0/30000]\n",
      "current batch loss: -0.449136 KL: 0.596160 Neg-log -1.045296  [12800/30000]\n",
      "current batch loss: -0.473224 KL: 0.595919 Neg-log -1.069143  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.279877 KL: 0.595831 Neg-log -0.875707 MSE 0.09318365901708603\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.264411 KL: 0.595831 Neg-log -0.860240 MSE 0.09752814471721649\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 110\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.304911 KL: 0.595830 Neg-log -0.900741  [    0/30000]\n",
      "current batch loss: -0.534066 KL: 0.595581 Neg-log -1.129647  [12800/30000]\n",
      "current batch loss: -0.474459 KL: 0.595343 Neg-log -1.069801  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.293504 KL: 0.595260 Neg-log -0.888764 MSE 0.08848275244235992\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.261535 KL: 0.595260 Neg-log -0.856795 MSE 0.09481468796730042\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 111\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.507962 KL: 0.595259 Neg-log -1.103222  [    0/30000]\n",
      "current batch loss: 1.239144 KL: 0.595012 Neg-log 0.644132  [12800/30000]\n",
      "current batch loss: -0.589122 KL: 0.594787 Neg-log -1.183909  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.243052 KL: 0.594710 Neg-log -0.837760 MSE 0.09828813374042511\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.282120 KL: 0.594710 Neg-log -0.876828 MSE 0.08964600414037704\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 112\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.328715 KL: 0.594708 Neg-log -0.923423  [    0/30000]\n",
      "current batch loss: -0.216370 KL: 0.594476 Neg-log -0.810846  [12800/30000]\n",
      "current batch loss: -0.559438 KL: 0.594236 Neg-log -1.153674  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.100497 KL: 0.594152 Neg-log -0.493655 MSE 0.16370174288749695\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.131588 KL: 0.594152 Neg-log -0.462563 MSE 0.1694447249174118\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 113\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.070325 KL: 0.594151 Neg-log -0.523827  [    0/30000]\n",
      "current batch loss: 1.152029 KL: 0.593907 Neg-log 0.558122  [12800/30000]\n",
      "current batch loss: -0.397114 KL: 0.593669 Neg-log -0.990783  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.188750 KL: 0.593582 Neg-log -0.782331 MSE 0.1067553237080574\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.127389 KL: 0.593582 Neg-log -0.720970 MSE 0.12050148099660873\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 114\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.358280 KL: 0.593581 Neg-log -0.951861  [    0/30000]\n",
      "current batch loss: -0.393898 KL: 0.593342 Neg-log -0.987240  [12800/30000]\n",
      "current batch loss: -0.292107 KL: 0.593113 Neg-log -0.885220  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.300840 KL: 0.593032 Neg-log -0.893871 MSE 0.0959358811378479\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.305785 KL: 0.593032 Neg-log -0.898816 MSE 0.094256192445755\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 115\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.130049 KL: 0.593031 Neg-log -0.462982  [    0/30000]\n",
      "current batch loss: -0.467405 KL: 0.592806 Neg-log -1.060210  [12800/30000]\n",
      "current batch loss: 0.211494 KL: 0.592565 Neg-log -0.381070  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.359197 KL: 0.592477 Neg-log -0.951674 MSE 0.07983189821243286\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.315458 KL: 0.592477 Neg-log -0.907935 MSE 0.08409944176673889\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 116\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.310588 KL: 0.592476 Neg-log -0.903064  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: 0.403128 KL: 0.592239 Neg-log -0.189111  [12800/30000]\n",
      "current batch loss: -0.502284 KL: 0.592003 Neg-log -1.094287  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.191485 KL: 0.591913 Neg-log -0.783399 MSE 0.10734901577234268\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.278742 KL: 0.591913 Neg-log -0.870656 MSE 0.09175027161836624\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 117\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.625952 KL: 0.591914 Neg-log -1.217866  [    0/30000]\n",
      "current batch loss: -0.469277 KL: 0.591692 Neg-log -1.060969  [12800/30000]\n",
      "current batch loss: -0.224245 KL: 0.591445 Neg-log -0.815690  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.297141 KL: 0.591368 Neg-log -0.888508 MSE 0.08756408095359802\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.278758 KL: 0.591368 Neg-log -0.870125 MSE 0.09324220567941666\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 118\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.483666 KL: 0.591367 Neg-log -1.075033  [    0/30000]\n",
      "current batch loss: -0.482306 KL: 0.591121 Neg-log -1.073427  [12800/30000]\n",
      "current batch loss: -0.520967 KL: 0.590883 Neg-log -1.111850  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.344503 KL: 0.590806 Neg-log -0.935310 MSE 0.08368123322725296\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.285850 KL: 0.590806 Neg-log -0.876657 MSE 0.09463927149772644\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 119\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.600471 KL: 0.590807 Neg-log -1.191278  [    0/30000]\n",
      "current batch loss: -0.370072 KL: 0.590584 Neg-log -0.960655  [12800/30000]\n",
      "current batch loss: -0.263007 KL: 0.590352 Neg-log -0.853359  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.304222 KL: 0.590271 Neg-log -0.286047 MSE 0.09251493215560913\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.371192 KL: 0.590271 Neg-log -0.961461 MSE 0.0806853249669075\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 120\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.628784 KL: 0.590269 Neg-log -1.219054  [    0/30000]\n",
      "current batch loss: -0.085965 KL: 0.590029 Neg-log -0.675995  [12800/30000]\n",
      "current batch loss: -0.608941 KL: 0.589783 Neg-log -1.198724  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.346945 KL: 0.589700 Neg-log -0.936646 MSE 0.08012905716896057\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.328277 KL: 0.589700 Neg-log -0.917978 MSE 0.084042489528656\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 121\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.563470 KL: 0.589700 Neg-log -1.153171  [    0/30000]\n",
      "current batch loss: -0.329494 KL: 0.589455 Neg-log -0.918948  [12800/30000]\n",
      "current batch loss: -0.537263 KL: 0.589206 Neg-log -1.126469  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.445405 KL: 0.589126 Neg-log -1.034531 MSE 0.0726625844836235\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.425010 KL: 0.589126 Neg-log -1.014136 MSE 0.0717516764998436\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 122\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.507254 KL: 0.589126 Neg-log -1.096380  [    0/30000]\n",
      "current batch loss: -0.590565 KL: 0.588902 Neg-log -1.179468  [12800/30000]\n",
      "current batch loss: -0.614594 KL: 0.588663 Neg-log -1.203257  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.244131 KL: 0.588577 Neg-log -0.832708 MSE 0.10456858575344086\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.223960 KL: 0.588577 Neg-log -0.812537 MSE 0.11007871478796005\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 123\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.545358 KL: 0.588577 Neg-log -1.133936  [    0/30000]\n",
      "current batch loss: -0.260214 KL: 0.588349 Neg-log -0.848564  [12800/30000]\n",
      "current batch loss: 0.321390 KL: 0.588132 Neg-log -0.266742  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.269381 KL: 0.588065 Neg-log -0.857446 MSE 0.1009884774684906\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.258007 KL: 0.588065 Neg-log -0.846072 MSE 0.10955001413822174\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 124\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.164507 KL: 0.588064 Neg-log -0.752571  [    0/30000]\n",
      "current batch loss: -0.406018 KL: 0.587830 Neg-log -0.993848  [12800/30000]\n",
      "current batch loss: -0.575052 KL: 0.587595 Neg-log -1.162646  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.005474 KL: 0.587509 Neg-log -0.592982 MSE 0.1357475370168686\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.016492 KL: 0.587509 Neg-log -0.571016 MSE 0.14184367656707764\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 125\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.325773 KL: 0.587508 Neg-log -0.913281  [    0/30000]\n",
      "current batch loss: -0.550943 KL: 0.587265 Neg-log -1.138207  [12800/30000]\n",
      "current batch loss: -0.535646 KL: 0.587046 Neg-log -1.122691  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.407245 KL: 0.586960 Neg-log -0.994206 MSE 0.07300877571105957\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.376470 KL: 0.586960 Neg-log -0.963431 MSE 0.07484040409326553\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 126\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.343661 KL: 0.586961 Neg-log -0.930622  [    0/30000]\n",
      "current batch loss: -0.566304 KL: 0.586720 Neg-log -1.153025  [12800/30000]\n",
      "current batch loss: 0.088125 KL: 0.586492 Neg-log -0.498367  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.437129 KL: 0.586401 Neg-log -1.023530 MSE 0.07004339247941971\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.433809 KL: 0.586401 Neg-log -1.020210 MSE 0.06948751956224442\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 127\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.223144 KL: 0.586401 Neg-log -0.809545  [    0/30000]\n",
      "current batch loss: -0.513902 KL: 0.586182 Neg-log -1.100084  [12800/30000]\n",
      "current batch loss: -0.381498 KL: 0.585947 Neg-log -0.967444  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.168496 KL: 0.585875 Neg-log -0.754370 MSE 0.10686943680047989\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.106684 KL: 0.585875 Neg-log -0.692557 MSE 0.11549489200115204\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 128\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.932982 KL: 0.585873 Neg-log 0.347108  [    0/30000]\n",
      "current batch loss: 0.045581 KL: 0.585650 Neg-log -0.540069  [12800/30000]\n",
      "current batch loss: -0.594940 KL: 0.585421 Neg-log -1.180361  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.307358 KL: 0.585341 Neg-log -0.892697 MSE 0.08418813347816467\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -0.313408 KL: 0.585341 Neg-log -0.898747 MSE 0.081090047955513\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 129\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.604582 KL: 0.585340 Neg-log -1.189922  [    0/30000]\n",
      "current batch loss: -0.181807 KL: 0.585115 Neg-log -0.766923  [12800/30000]\n",
      "current batch loss: -0.046402 KL: 0.584877 Neg-log -0.631279  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.457179 KL: 0.584793 Neg-log -1.041972 MSE 0.06575176864862442\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.408460 KL: 0.584793 Neg-log -0.993253 MSE 0.07334408909082413\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 130\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.616121 KL: 0.584793 Neg-log -1.200914  [    0/30000]\n",
      "current batch loss: -0.557290 KL: 0.584558 Neg-log -1.141847  [12800/30000]\n",
      "current batch loss: -0.394201 KL: 0.584323 Neg-log -0.978524  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.443053 KL: 0.584250 Neg-log -1.027302 MSE 0.06948842853307724\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.443386 KL: 0.584250 Neg-log -1.027635 MSE 0.06623274832963943\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 131\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.591831 KL: 0.584249 Neg-log -1.176081  [    0/30000]\n",
      "current batch loss: -0.596287 KL: 0.584024 Neg-log -1.180311  [12800/30000]\n",
      "current batch loss: 0.068308 KL: 0.583792 Neg-log -0.515484  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.427605 KL: 0.583719 Neg-log -1.011325 MSE 0.06681105494499207\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.398129 KL: 0.583719 Neg-log -0.981849 MSE 0.0731060653924942\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 132\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.414426 KL: 0.583720 Neg-log -0.998146  [    0/30000]\n",
      "current batch loss: -0.636159 KL: 0.583505 Neg-log -1.219665  [12800/30000]\n",
      "current batch loss: -0.195522 KL: 0.583277 Neg-log -0.778799  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.305304 KL: 0.583197 Neg-log -0.888500 MSE 0.08108875155448914\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.342401 KL: 0.583197 Neg-log -0.925597 MSE 0.0785919576883316\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 133\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.259030 KL: 0.583196 Neg-log -0.842226  [    0/30000]\n",
      "current batch loss: -0.558167 KL: 0.582972 Neg-log -1.141140  [12800/30000]\n",
      "current batch loss: -0.630469 KL: 0.582739 Neg-log -1.213208  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.471627 KL: 0.582671 Neg-log -1.054296 MSE 0.06574475020170212\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.480243 KL: 0.582671 Neg-log -1.062913 MSE 0.06290428340435028\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 134\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.700586 KL: 0.582669 Neg-log -1.283255  [    0/30000]\n",
      "current batch loss: -0.673279 KL: 0.582456 Neg-log -1.255735  [12800/30000]\n",
      "current batch loss: -0.578057 KL: 0.582229 Neg-log -1.160287  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.428271 KL: 0.582147 Neg-log -1.010419 MSE 0.0703669935464859\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.464975 KL: 0.582147 Neg-log -1.047123 MSE 0.06534393876791\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 135\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.599857 KL: 0.582148 Neg-log -1.182005  [    0/30000]\n",
      "current batch loss: -0.558410 KL: 0.581932 Neg-log -1.140342  [12800/30000]\n",
      "current batch loss: -0.545279 KL: 0.581711 Neg-log -1.126989  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.415764 KL: 0.581629 Neg-log -0.997394 MSE 0.07388024777173996\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.380525 KL: 0.581629 Neg-log -0.962155 MSE 0.076559878885746\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 136\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.378671 KL: 0.581629 Neg-log -0.960301  [    0/30000]\n",
      "current batch loss: -0.313444 KL: 0.581397 Neg-log -0.894841  [12800/30000]\n",
      "current batch loss: -0.629455 KL: 0.581182 Neg-log -1.210637  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.491803 KL: 0.581100 Neg-log -1.072903 MSE 0.06358326226472855\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.493402 KL: 0.581100 Neg-log -1.074502 MSE 0.06467494368553162\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 137\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.620505 KL: 0.581100 Neg-log -1.201604  [    0/30000]\n",
      "current batch loss: -0.648061 KL: 0.580871 Neg-log -1.228931  [12800/30000]\n",
      "current batch loss: 0.112915 KL: 0.580656 Neg-log -0.467740  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.446001 KL: 0.580575 Neg-log -1.026576 MSE 0.06760646402835846\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.442702 KL: 0.580575 Neg-log -1.023277 MSE 0.06964577734470367\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 138\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.556882 KL: 0.580575 Neg-log -1.137457  [    0/30000]\n",
      "current batch loss: -0.607989 KL: 0.580346 Neg-log -1.188335  [12800/30000]\n",
      "current batch loss: -0.630862 KL: 0.580101 Neg-log -1.210963  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.492835 KL: 0.580025 Neg-log -1.072860 MSE 0.06395266205072403\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.475103 KL: 0.580025 Neg-log -1.055128 MSE 0.06379403918981552\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 139\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.647266 KL: 0.580025 Neg-log -1.227291  [    0/30000]\n",
      "current batch loss: -0.459083 KL: 0.579804 Neg-log -1.038887  [12800/30000]\n",
      "current batch loss: -0.155206 KL: 0.579569 Neg-log -0.734775  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.356300 KL: 0.579489 Neg-log -0.935788 MSE 0.07528458535671234\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.359467 KL: 0.579489 Neg-log -0.938955 MSE 0.07404721528291702\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 140\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.597901 KL: 0.579488 Neg-log -1.177389  [    0/30000]\n",
      "current batch loss: -0.765864 KL: 0.579245 Neg-log -1.345109  [12800/30000]\n",
      "current batch loss: -0.694375 KL: 0.578993 Neg-log -1.273368  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.452953 KL: 0.578917 Neg-log -1.031868 MSE 0.07012509554624557\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.423752 KL: 0.578917 Neg-log -1.002668 MSE 0.07257801294326782\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 141\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.778990 KL: 0.578916 Neg-log -1.357905  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -0.698338 KL: 0.578681 Neg-log -1.277019  [12800/30000]\n",
      "current batch loss: -0.575861 KL: 0.578453 Neg-log -1.154314  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.456821 KL: 0.578379 Neg-log -1.035201 MSE 0.06400676816701889\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.421882 KL: 0.578379 Neg-log -1.000262 MSE 0.06660477817058563\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 142\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.436729 KL: 0.578380 Neg-log -1.015109  [    0/30000]\n",
      "current batch loss: -0.516815 KL: 0.578146 Neg-log -1.094961  [12800/30000]\n",
      "current batch loss: -0.530620 KL: 0.577894 Neg-log -1.108514  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.510108 KL: 0.577805 Neg-log -1.087913 MSE 0.05772379785776138\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.491734 KL: 0.577805 Neg-log -1.069539 MSE 0.06139764189720154\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 143\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.315687 KL: 0.577805 Neg-log -0.893492  [    0/30000]\n",
      "current batch loss: -0.600772 KL: 0.577583 Neg-log -1.178355  [12800/30000]\n",
      "current batch loss: -0.736088 KL: 0.577354 Neg-log -1.313441  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.337155 KL: 0.577277 Neg-log -0.914432 MSE 0.08431671559810638\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.388416 KL: 0.577277 Neg-log -0.965693 MSE 0.07347650080919266\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 144\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.352747 KL: 0.577277 Neg-log -0.930024  [    0/30000]\n",
      "current batch loss: -0.591315 KL: 0.577040 Neg-log -1.168355  [12800/30000]\n",
      "current batch loss: -0.694261 KL: 0.576793 Neg-log -1.271055  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.543023 KL: 0.576708 Neg-log -1.119732 MSE 0.05923207476735115\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.533085 KL: 0.576708 Neg-log -1.109794 MSE 0.060398928821086884\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 145\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.789803 KL: 0.576709 Neg-log -1.366512  [    0/30000]\n",
      "current batch loss: -0.668396 KL: 0.576500 Neg-log -1.244897  [12800/30000]\n",
      "current batch loss: -0.174546 KL: 0.576299 Neg-log -0.750845  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.379175 KL: 0.576240 Neg-log -0.955415 MSE 0.07380340993404388\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.443887 KL: 0.576240 Neg-log -1.020127 MSE 0.07011827826499939\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 146\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.250359 KL: 0.576240 Neg-log -0.826599  [    0/30000]\n",
      "current batch loss: -0.375964 KL: 0.576036 Neg-log -0.952000  [12800/30000]\n",
      "current batch loss: -0.661975 KL: 0.575822 Neg-log -1.237796  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.443532 KL: 0.575745 Neg-log -1.019278 MSE 0.06809744238853455\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.453878 KL: 0.575745 Neg-log -1.029623 MSE 0.067302405834198\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 147\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.631344 KL: 0.575746 Neg-log -1.207090  [    0/30000]\n",
      "current batch loss: -0.420856 KL: 0.575551 Neg-log -0.996406  [12800/30000]\n",
      "current batch loss: 0.364114 KL: 0.575332 Neg-log -0.211219  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.567021 KL: 0.575258 Neg-log -1.142279 MSE 0.05629274621605873\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.549072 KL: 0.575258 Neg-log -1.124331 MSE 0.05780620500445366\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 148\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.545967 KL: 0.575259 Neg-log -1.121226  [    0/30000]\n",
      "current batch loss: -0.272968 KL: 0.575048 Neg-log -0.848016  [12800/30000]\n",
      "current batch loss: -0.661290 KL: 0.574833 Neg-log -1.236123  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.395227 KL: 0.574760 Neg-log -0.969986 MSE 0.0735912024974823\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.413177 KL: 0.574760 Neg-log -0.987936 MSE 0.0714229941368103\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 149\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.480923 KL: 0.574759 Neg-log -1.055681  [    0/30000]\n",
      "current batch loss: -0.651686 KL: 0.574541 Neg-log -1.226228  [12800/30000]\n",
      "current batch loss: -0.704718 KL: 0.574338 Neg-log -1.279056  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.231884 KL: 0.574263 Neg-log -0.806146 MSE 0.08570487797260284\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.306965 KL: 0.574263 Neg-log -0.881226 MSE 0.07729190587997437\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 150\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.513769 KL: 0.574261 Neg-log -1.088030  [    0/30000]\n",
      "current batch loss: -0.656658 KL: 0.574052 Neg-log -1.230710  [12800/30000]\n",
      "current batch loss: -0.815497 KL: 0.573837 Neg-log -1.389334  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.490604 KL: 0.573762 Neg-log -1.064368 MSE 0.07045599818229675\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.476009 KL: 0.573762 Neg-log -1.049773 MSE 0.07543148845434189\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 151\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.617867 KL: 0.573764 Neg-log -1.191631  [    0/30000]\n",
      "current batch loss: -0.589983 KL: 0.573537 Neg-log -1.163520  [12800/30000]\n",
      "current batch loss: -0.203888 KL: 0.573316 Neg-log -0.777204  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.204068 KL: 0.573237 Neg-log -0.777305 MSE 0.09688528627157211\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.177077 KL: 0.573237 Neg-log -0.750315 MSE 0.1033293679356575\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 152\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.496406 KL: 0.573238 Neg-log -1.069645  [    0/30000]\n",
      "current batch loss: -0.347075 KL: 0.573012 Neg-log -0.920087  [12800/30000]\n",
      "current batch loss: -0.704224 KL: 0.572778 Neg-log -1.277002  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.051766 KL: 0.572695 Neg-log -0.520930 MSE 0.13515542447566986\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.042717 KL: 0.572695 Neg-log -0.529979 MSE 0.13193725049495697\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 153\n",
      "-----------------------------------------------\n",
      "current batch loss: 1.429507 KL: 0.572696 Neg-log 0.856811  [    0/30000]\n",
      "current batch loss: -0.071201 KL: 0.572452 Neg-log -0.643653  [12800/30000]\n",
      "current batch loss: 0.085617 KL: 0.572222 Neg-log -0.486605  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.301184 KL: 0.572144 Neg-log -0.873328 MSE 0.07226426899433136\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -0.279788 KL: 0.572144 Neg-log -0.851932 MSE 0.07564432919025421\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 154\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.025764 KL: 0.572144 Neg-log -0.546380  [    0/30000]\n",
      "current batch loss: -0.733255 KL: 0.571900 Neg-log -1.305155  [12800/30000]\n",
      "current batch loss: -0.081127 KL: 0.571668 Neg-log -0.652795  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.582139 KL: 0.571586 Neg-log -1.153724 MSE 0.052275143563747406\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.501373 KL: 0.571586 Neg-log -1.072957 MSE 0.06086325645446777\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 155\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.589299 KL: 0.571585 Neg-log -1.160884  [    0/30000]\n",
      "current batch loss: -0.794623 KL: 0.571343 Neg-log -1.365966  [12800/30000]\n",
      "current batch loss: -0.701246 KL: 0.571122 Neg-log -1.272368  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.585028 KL: 0.571043 Neg-log -1.156071 MSE 0.052412908524274826\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.545159 KL: 0.571043 Neg-log -1.116201 MSE 0.056284934282302856\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 156\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.721530 KL: 0.571042 Neg-log -1.292572  [    0/30000]\n",
      "current batch loss: -0.298537 KL: 0.570812 Neg-log -0.869349  [12800/30000]\n",
      "current batch loss: -0.767324 KL: 0.570577 Neg-log -1.337902  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.540238 KL: 0.570497 Neg-log -1.110737 MSE 0.052584439516067505\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.523028 KL: 0.570497 Neg-log -1.093527 MSE 0.05547488480806351\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 157\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.594355 KL: 0.570499 Neg-log -1.164854  [    0/30000]\n",
      "current batch loss: -0.833950 KL: 0.570267 Neg-log -1.404216  [12800/30000]\n",
      "current batch loss: -0.704550 KL: 0.570039 Neg-log -1.274590  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.578536 KL: 0.569963 Neg-log -1.148501 MSE 0.05163303762674332\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.560812 KL: 0.569963 Neg-log -1.130777 MSE 0.05222264304757118\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 158\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.594883 KL: 0.569965 Neg-log -1.164847  [    0/30000]\n",
      "current batch loss: -0.793913 KL: 0.569737 Neg-log -1.363650  [12800/30000]\n",
      "current batch loss: -0.313317 KL: 0.569507 Neg-log -0.882823  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.549125 KL: 0.569426 Neg-log -1.118550 MSE 0.05980374664068222\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.523266 KL: 0.569426 Neg-log -1.092691 MSE 0.06404739618301392\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 159\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.586966 KL: 0.569425 Neg-log -1.156391  [    0/30000]\n",
      "current batch loss: 1.000703 KL: 0.569203 Neg-log 0.431499  [12800/30000]\n",
      "current batch loss: -0.508353 KL: 0.568992 Neg-log -1.077345  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.625137 KL: 0.568914 Neg-log -1.194050 MSE 0.048904165625572205\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.620970 KL: 0.568914 Neg-log -1.189882 MSE 0.0509248748421669\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 160\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.662650 KL: 0.568913 Neg-log -1.231562  [    0/30000]\n",
      "current batch loss: -0.764989 KL: 0.568691 Neg-log -1.333680  [12800/30000]\n",
      "current batch loss: -0.199075 KL: 0.568474 Neg-log -0.767548  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.598097 KL: 0.568407 Neg-log -1.166504 MSE 0.05388733372092247\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.604162 KL: 0.568407 Neg-log -1.172569 MSE 0.05332133173942566\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 161\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.069626 KL: 0.568407 Neg-log -0.498782  [    0/30000]\n",
      "current batch loss: -0.625846 KL: 0.568196 Neg-log -1.194041  [12800/30000]\n",
      "current batch loss: -0.678497 KL: 0.567981 Neg-log -1.246478  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.590173 KL: 0.567909 Neg-log -1.158081 MSE 0.04796503856778145\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.566089 KL: 0.567909 Neg-log -1.133997 MSE 0.05233406275510788\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 162\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.699090 KL: 0.567908 Neg-log -1.266998  [    0/30000]\n",
      "current batch loss: -0.617079 KL: 0.567689 Neg-log -1.184768  [12800/30000]\n",
      "current batch loss: -0.224455 KL: 0.567479 Neg-log -0.791934  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.538944 KL: 0.567398 Neg-log -1.106342 MSE 0.05424567312002182\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.591441 KL: 0.567398 Neg-log -1.158839 MSE 0.05112529918551445\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 163\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.804917 KL: 0.567398 Neg-log -1.372316  [    0/30000]\n",
      "current batch loss: -0.843828 KL: 0.567176 Neg-log -1.411004  [12800/30000]\n",
      "current batch loss: -0.771336 KL: 0.566952 Neg-log -1.338288  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.355124 KL: 0.566872 Neg-log -0.211748 MSE 0.12216746062040329\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: 0.307611 KL: 0.566872 Neg-log -0.259261 MSE 0.11906518042087555\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 164\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.182408 KL: 0.566872 Neg-log -0.384464  [    0/30000]\n",
      "current batch loss: -0.781416 KL: 0.566654 Neg-log -1.348070  [12800/30000]\n",
      "current batch loss: -0.783477 KL: 0.566449 Neg-log -1.349926  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.664606 KL: 0.566368 Neg-log -1.230973 MSE 0.04970972612500191\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.641931 KL: 0.566368 Neg-log -1.208298 MSE 0.05041665583848953\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 165\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.833360 KL: 0.566368 Neg-log -1.399727  [    0/30000]\n",
      "current batch loss: -0.492284 KL: 0.566155 Neg-log -1.058439  [12800/30000]\n",
      "current batch loss: -0.691353 KL: 0.565935 Neg-log -1.257288  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.416455 KL: 0.565858 Neg-log -0.982314 MSE 0.06555991619825363\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.454147 KL: 0.565858 Neg-log -1.020006 MSE 0.06442335247993469\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 166\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.719623 KL: 0.565859 Neg-log -1.285482  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -0.524571 KL: 0.565666 Neg-log -1.090237  [12800/30000]\n",
      "current batch loss: -0.643184 KL: 0.565442 Neg-log -1.208627  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.619869 KL: 0.565369 Neg-log -1.185237 MSE 0.053565822541713715\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.629112 KL: 0.565369 Neg-log -1.194481 MSE 0.052445027977228165\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 167\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.014778 KL: 0.565368 Neg-log -1.580146  [    0/30000]\n",
      "current batch loss: -0.856363 KL: 0.565151 Neg-log -1.421514  [12800/30000]\n",
      "current batch loss: -0.715484 KL: 0.564957 Neg-log -1.280441  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.640108 KL: 0.564873 Neg-log -1.204981 MSE 0.050747115164995193\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.613405 KL: 0.564873 Neg-log -1.178278 MSE 0.050887979567050934\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 168\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.961538 KL: 0.564874 Neg-log -1.526411  [    0/30000]\n",
      "current batch loss: -0.803340 KL: 0.564660 Neg-log -1.368000  [12800/30000]\n",
      "current batch loss: -0.675326 KL: 0.564426 Neg-log -1.239752  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.607637 KL: 0.564356 Neg-log -1.171993 MSE 0.05073852464556694\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.608670 KL: 0.564356 Neg-log -1.173026 MSE 0.052530378103256226\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 169\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.802846 KL: 0.564357 Neg-log -1.367203  [    0/30000]\n",
      "current batch loss: -0.652067 KL: 0.564150 Neg-log -1.216218  [12800/30000]\n",
      "current batch loss: -0.824898 KL: 0.563935 Neg-log -1.388833  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 0.024949 KL: 0.563866 Neg-log -0.538918 MSE 0.1422758847475052\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.033124 KL: 0.563866 Neg-log -0.596991 MSE 0.1342010647058487\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 170\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.354457 KL: 0.563867 Neg-log -0.918324  [    0/30000]\n",
      "current batch loss: -0.087479 KL: 0.563640 Neg-log -0.651119  [12800/30000]\n",
      "current batch loss: -0.884043 KL: 0.563423 Neg-log -1.447466  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.562144 KL: 0.563341 Neg-log -1.125486 MSE 0.055849216878414154\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.561881 KL: 0.563341 Neg-log -1.125223 MSE 0.058781854808330536\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 171\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.354045 KL: 0.563342 Neg-log -0.917386  [    0/30000]\n",
      "current batch loss: -0.398838 KL: 0.563132 Neg-log -0.961969  [12800/30000]\n",
      "current batch loss: -0.713929 KL: 0.562904 Neg-log -1.276833  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.657483 KL: 0.562819 Neg-log -1.220300 MSE 0.04570629447698593\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.635344 KL: 0.562819 Neg-log -1.198161 MSE 0.046607956290245056\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 172\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.474949 KL: 0.562817 Neg-log -1.037766  [    0/30000]\n",
      "current batch loss: -0.779396 KL: 0.562610 Neg-log -1.342006  [12800/30000]\n",
      "current batch loss: -0.627404 KL: 0.562402 Neg-log -1.189806  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.667277 KL: 0.562331 Neg-log -1.229607 MSE 0.050449274480342865\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.660364 KL: 0.562331 Neg-log -1.222694 MSE 0.05028300732374191\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 173\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.653746 KL: 0.562330 Neg-log -1.216076  [    0/30000]\n",
      "current batch loss: -0.813498 KL: 0.562108 Neg-log -1.375607  [12800/30000]\n",
      "current batch loss: -0.552804 KL: 0.561893 Neg-log -1.114697  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.644482 KL: 0.561806 Neg-log -1.206288 MSE 0.044200364500284195\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.587359 KL: 0.561806 Neg-log -1.149166 MSE 0.05019669979810715\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 174\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.706472 KL: 0.561807 Neg-log -1.268279  [    0/30000]\n",
      "current batch loss: -0.699235 KL: 0.561586 Neg-log -1.260821  [12800/30000]\n",
      "current batch loss: -0.658990 KL: 0.561369 Neg-log -1.220359  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.673190 KL: 0.561289 Neg-log -1.234479 MSE 0.0496370829641819\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.636447 KL: 0.561289 Neg-log -1.197737 MSE 0.05092966556549072\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 175\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.545346 KL: 0.561290 Neg-log -1.106636  [    0/30000]\n",
      "current batch loss: -0.841646 KL: 0.561085 Neg-log -1.402730  [12800/30000]\n",
      "current batch loss: 0.091882 KL: 0.560883 Neg-log -0.469001  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.650522 KL: 0.560812 Neg-log -1.211333 MSE 0.0464697889983654\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.615759 KL: 0.560812 Neg-log -1.176570 MSE 0.049321841448545456\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 176\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.839848 KL: 0.560811 Neg-log -1.400659  [    0/30000]\n",
      "current batch loss: -0.572757 KL: 0.560604 Neg-log -1.133361  [12800/30000]\n",
      "current batch loss: -0.370565 KL: 0.560390 Neg-log -0.930955  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.665726 KL: 0.560312 Neg-log -1.226039 MSE 0.051845330744981766\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.637785 KL: 0.560312 Neg-log -1.198098 MSE 0.05421246960759163\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 177\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.775216 KL: 0.560313 Neg-log -1.335528  [    0/30000]\n",
      "current batch loss: -0.789462 KL: 0.560104 Neg-log -1.349566  [12800/30000]\n",
      "current batch loss: -0.328997 KL: 0.559902 Neg-log -0.888900  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.671116 KL: 0.559830 Neg-log -1.230945 MSE 0.05195779353380203\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.694831 KL: 0.559830 Neg-log -1.254659 MSE 0.04555446282029152\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 178\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.742684 KL: 0.559829 Neg-log -1.302513  [    0/30000]\n",
      "current batch loss: 0.167423 KL: 0.559618 Neg-log -0.392195  [12800/30000]\n",
      "current batch loss: -0.508495 KL: 0.559405 Neg-log -1.067900  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.630069 KL: 0.559326 Neg-log -1.189395 MSE 0.052291546016931534\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -0.626381 KL: 0.559326 Neg-log -1.185707 MSE 0.05517309159040451\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 179\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.703757 KL: 0.559326 Neg-log -1.263083  [    0/30000]\n",
      "current batch loss: -0.301691 KL: 0.559130 Neg-log -0.860821  [12800/30000]\n",
      "current batch loss: -0.894426 KL: 0.558913 Neg-log -1.453339  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.720841 KL: 0.558839 Neg-log -1.279681 MSE 0.04311714321374893\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.727236 KL: 0.558839 Neg-log -1.286076 MSE 0.041266705840826035\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 180\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.606131 KL: 0.558840 Neg-log -1.164971  [    0/30000]\n",
      "current batch loss: -0.666626 KL: 0.558623 Neg-log -1.225250  [12800/30000]\n",
      "current batch loss: -0.568207 KL: 0.558409 Neg-log -1.126616  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.491543 KL: 0.558334 Neg-log -1.049875 MSE 0.06487798690795898\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.526608 KL: 0.558334 Neg-log -1.084941 MSE 0.06306137889623642\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 181\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.561427 KL: 0.558333 Neg-log -1.119761  [    0/30000]\n",
      "current batch loss: -0.770355 KL: 0.558113 Neg-log -1.328468  [12800/30000]\n",
      "current batch loss: 0.024479 KL: 0.557894 Neg-log -0.533415  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.516956 KL: 0.557817 Neg-log -1.074774 MSE 0.05279272049665451\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.550315 KL: 0.557817 Neg-log -1.108133 MSE 0.0509454682469368\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 182\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.686731 KL: 0.557818 Neg-log -1.244549  [    0/30000]\n",
      "current batch loss: -0.786538 KL: 0.557585 Neg-log -1.344122  [12800/30000]\n",
      "current batch loss: -0.789558 KL: 0.557348 Neg-log -1.346906  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.686831 KL: 0.557274 Neg-log -1.244105 MSE 0.04451813921332359\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.685042 KL: 0.557274 Neg-log -1.242317 MSE 0.04669981449842453\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 183\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.136604 KL: 0.557274 Neg-log -0.693879  [    0/30000]\n",
      "current batch loss: -0.582794 KL: 0.557051 Neg-log -1.139845  [12800/30000]\n",
      "current batch loss: -0.800547 KL: 0.556832 Neg-log -1.357378  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.258626 KL: 0.556753 Neg-log -0.815379 MSE 0.08141055703163147\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.347315 KL: 0.556753 Neg-log -0.904067 MSE 0.07420917600393295\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 184\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.523965 KL: 0.556753 Neg-log -1.080718  [    0/30000]\n",
      "current batch loss: -0.720081 KL: 0.556536 Neg-log -1.276618  [12800/30000]\n",
      "current batch loss: 0.138631 KL: 0.556310 Neg-log -0.417680  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.624211 KL: 0.556228 Neg-log -1.180438 MSE 0.04840128496289253\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.631136 KL: 0.556228 Neg-log -1.187363 MSE 0.04761185497045517\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 185\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.293643 KL: 0.556227 Neg-log -0.849870  [    0/30000]\n",
      "current batch loss: -0.870833 KL: 0.556015 Neg-log -1.426848  [12800/30000]\n",
      "current batch loss: -0.788062 KL: 0.555783 Neg-log -1.343845  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.687689 KL: 0.555702 Neg-log -1.243391 MSE 0.04458048567175865\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.722332 KL: 0.555702 Neg-log -1.278034 MSE 0.04283466562628746\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 186\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.728814 KL: 0.555702 Neg-log -1.284516  [    0/30000]\n",
      "current batch loss: -0.043037 KL: 0.555484 Neg-log -0.598522  [12800/30000]\n",
      "current batch loss: -0.757916 KL: 0.555253 Neg-log -1.313169  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.502444 KL: 0.555174 Neg-log -1.057617 MSE 0.05863964930176735\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.513053 KL: 0.555174 Neg-log -1.068225 MSE 0.057666633278131485\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 187\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.650938 KL: 0.555173 Neg-log -1.206110  [    0/30000]\n",
      "current batch loss: -0.767334 KL: 0.554944 Neg-log -1.322278  [12800/30000]\n",
      "current batch loss: -0.843070 KL: 0.554720 Neg-log -1.397790  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.382394 KL: 0.554648 Neg-log -0.937041 MSE 0.06812776625156403\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.419565 KL: 0.554648 Neg-log -0.974212 MSE 0.06467638909816742\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 188\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.543355 KL: 0.554647 Neg-log -1.098003  [    0/30000]\n",
      "current batch loss: -0.434568 KL: 0.554438 Neg-log -0.989006  [12800/30000]\n",
      "current batch loss: -0.748729 KL: 0.554194 Neg-log -1.302923  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.736336 KL: 0.554110 Neg-log -1.290448 MSE 0.03798606991767883\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.701819 KL: 0.554110 Neg-log -1.255931 MSE 0.04117267578840256\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 189\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.753101 KL: 0.554111 Neg-log -1.307213  [    0/30000]\n",
      "current batch loss: -0.909408 KL: 0.553884 Neg-log -1.463292  [12800/30000]\n",
      "current batch loss: -0.866045 KL: 0.553675 Neg-log -1.419720  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.640095 KL: 0.553598 Neg-log -1.193694 MSE 0.04680224135518074\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.603676 KL: 0.553598 Neg-log -1.157276 MSE 0.05120927095413208\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 190\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.582207 KL: 0.553599 Neg-log -1.135806  [    0/30000]\n",
      "current batch loss: -0.616347 KL: 0.553388 Neg-log -1.169735  [12800/30000]\n",
      "current batch loss: 0.788373 KL: 0.553196 Neg-log 0.235177  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.755291 KL: 0.553122 Neg-log -1.308411 MSE 0.03761603310704231\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.743250 KL: 0.553122 Neg-log -1.296371 MSE 0.03937873989343643\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 191\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.787155 KL: 0.553120 Neg-log -1.340275  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -0.848912 KL: 0.552917 Neg-log -1.401830  [12800/30000]\n",
      "current batch loss: -0.935997 KL: 0.552704 Neg-log -1.488701  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.779000 KL: 0.552635 Neg-log -1.331635 MSE 0.03969622403383255\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.751361 KL: 0.552635 Neg-log -1.303995 MSE 0.040338192135095596\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 192\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.469608 KL: 0.552634 Neg-log -1.022242  [    0/30000]\n",
      "current batch loss: -0.873560 KL: 0.552430 Neg-log -1.425990  [12800/30000]\n",
      "current batch loss: -0.767995 KL: 0.552231 Neg-log -1.320226  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.690726 KL: 0.552163 Neg-log -1.242890 MSE 0.041199907660484314\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.669642 KL: 0.552163 Neg-log -1.221806 MSE 0.043161436915397644\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 193\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.984099 KL: 0.552163 Neg-log -1.536262  [    0/30000]\n",
      "current batch loss: -0.911619 KL: 0.551975 Neg-log -1.463594  [12800/30000]\n",
      "current batch loss: -0.627095 KL: 0.551786 Neg-log -1.178881  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.682104 KL: 0.551704 Neg-log -1.233808 MSE 0.04511437192559242\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.653844 KL: 0.551704 Neg-log -1.205550 MSE 0.04717819020152092\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 194\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.894588 KL: 0.551704 Neg-log -1.446292  [    0/30000]\n",
      "current batch loss: -0.655003 KL: 0.551515 Neg-log -1.206518  [12800/30000]\n",
      "current batch loss: -0.599833 KL: 0.551320 Neg-log -1.151154  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.751719 KL: 0.551247 Neg-log -1.302968 MSE 0.03574018552899361\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.712711 KL: 0.551247 Neg-log -1.263959 MSE 0.03834065794944763\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 195\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.793389 KL: 0.551248 Neg-log -1.344637  [    0/30000]\n",
      "current batch loss: -0.632345 KL: 0.551039 Neg-log -1.183385  [12800/30000]\n",
      "current batch loss: -0.839125 KL: 0.550835 Neg-log -1.389960  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.780649 KL: 0.550767 Neg-log -1.331418 MSE 0.038780681788921356\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.757509 KL: 0.550767 Neg-log -1.308278 MSE 0.040910664945840836\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 196\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.672489 KL: 0.550768 Neg-log -1.223257  [    0/30000]\n",
      "current batch loss: 0.699649 KL: 0.550576 Neg-log 0.149073  [12800/30000]\n",
      "current batch loss: -0.999627 KL: 0.550362 Neg-log -1.549989  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.468066 KL: 0.550295 Neg-log -1.018363 MSE 0.05684642493724823\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.440378 KL: 0.550295 Neg-log -0.990674 MSE 0.06080266088247299\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 197\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.351294 KL: 0.550297 Neg-log -0.901590  [    0/30000]\n",
      "current batch loss: -0.906898 KL: 0.550101 Neg-log -1.456999  [12800/30000]\n",
      "current batch loss: -0.921726 KL: 0.549903 Neg-log -1.471629  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.678987 KL: 0.549834 Neg-log -1.228820 MSE 0.04486333206295967\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.693383 KL: 0.549834 Neg-log -1.243217 MSE 0.04408728703856468\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 198\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.889377 KL: 0.549833 Neg-log -1.439210  [    0/30000]\n",
      "current batch loss: -0.028433 KL: 0.549630 Neg-log -0.578062  [12800/30000]\n",
      "current batch loss: -0.842437 KL: 0.549437 Neg-log -1.391874  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.767251 KL: 0.549362 Neg-log -1.316612 MSE 0.03850127384066582\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.731309 KL: 0.549362 Neg-log -1.280669 MSE 0.04019469395279884\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 199\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.837145 KL: 0.549361 Neg-log -1.386505  [    0/30000]\n",
      "current batch loss: -0.751642 KL: 0.549166 Neg-log -1.300808  [12800/30000]\n",
      "current batch loss: -0.942736 KL: 0.548956 Neg-log -1.491692  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.150372 KL: 0.548891 Neg-log -0.699263 MSE 0.08707273751497269\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.217279 KL: 0.548891 Neg-log -0.766171 MSE 0.08202555030584335\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 200\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.736302 KL: 0.548891 Neg-log -1.285193  [    0/30000]\n",
      "current batch loss: -0.934434 KL: 0.548686 Neg-log -1.483120  [12800/30000]\n",
      "current batch loss: -1.075724 KL: 0.548478 Neg-log -1.624202  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.750622 KL: 0.548407 Neg-log -1.299028 MSE 0.038448818027973175\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.788105 KL: 0.548407 Neg-log -1.336511 MSE 0.03740590438246727\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 201\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.810595 KL: 0.548406 Neg-log -1.359001  [    0/30000]\n",
      "current batch loss: -0.686716 KL: 0.548204 Neg-log -1.234920  [12800/30000]\n",
      "current batch loss: -0.773946 KL: 0.548014 Neg-log -1.321960  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.842155 KL: 0.547949 Neg-log -1.390104 MSE 0.03441985696554184\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.827545 KL: 0.547949 Neg-log -1.375493 MSE 0.034265872091054916\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 202\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.920382 KL: 0.547948 Neg-log -1.468330  [    0/30000]\n",
      "current batch loss: -0.979891 KL: 0.547735 Neg-log -1.527625  [12800/30000]\n",
      "current batch loss: -0.445632 KL: 0.547541 Neg-log -0.993173  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.797707 KL: 0.547464 Neg-log -1.345173 MSE 0.036688994616270065\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.797548 KL: 0.547464 Neg-log -1.345014 MSE 0.037173230201005936\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 203\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.727829 KL: 0.547466 Neg-log -1.275295  [    0/30000]\n",
      "current batch loss: 0.028569 KL: 0.547270 Neg-log -0.518701  [12800/30000]\n",
      "current batch loss: -0.912516 KL: 0.547074 Neg-log -1.459590  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.622398 KL: 0.547014 Neg-log -1.169414 MSE 0.04892495274543762\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -0.573546 KL: 0.547014 Neg-log -1.120562 MSE 0.05485197529196739\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 204\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.157390 KL: 0.547016 Neg-log -0.704406  [    0/30000]\n",
      "current batch loss: -0.891449 KL: 0.546809 Neg-log -1.438257  [12800/30000]\n",
      "current batch loss: -0.838437 KL: 0.546622 Neg-log -1.385059  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.822608 KL: 0.546555 Neg-log -1.369162 MSE 0.03801640123128891\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.786627 KL: 0.546555 Neg-log -1.333182 MSE 0.04207395762205124\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 205\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.812088 KL: 0.546555 Neg-log -1.358643  [    0/30000]\n",
      "current batch loss: -0.479444 KL: 0.546370 Neg-log -1.025814  [12800/30000]\n",
      "current batch loss: -0.483022 KL: 0.546196 Neg-log -1.029218  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.789553 KL: 0.546135 Neg-log -1.335690 MSE 0.036979760974645615\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.765816 KL: 0.546135 Neg-log -1.311952 MSE 0.039014555513858795\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 206\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.053639 KL: 0.546137 Neg-log -1.599776  [    0/30000]\n",
      "current batch loss: -0.936145 KL: 0.545967 Neg-log -1.482113  [12800/30000]\n",
      "current batch loss: -0.975293 KL: 0.545786 Neg-log -1.521079  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.289680 KL: 0.545721 Neg-log -0.835400 MSE 0.06429905444383621\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.170805 KL: 0.545721 Neg-log -0.716524 MSE 0.07100089639425278\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 207\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.258559 KL: 0.545719 Neg-log -0.287161  [    0/30000]\n",
      "current batch loss: -0.478131 KL: 0.545549 Neg-log -1.023681  [12800/30000]\n",
      "current batch loss: -0.803660 KL: 0.545366 Neg-log -1.349026  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.810685 KL: 0.545296 Neg-log -1.355982 MSE 0.03504898399114609\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.795962 KL: 0.545296 Neg-log -1.341259 MSE 0.03561021015048027\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 208\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.939679 KL: 0.545297 Neg-log -1.484976  [    0/30000]\n",
      "current batch loss: -0.518753 KL: 0.545105 Neg-log -1.063858  [12800/30000]\n",
      "current batch loss: -0.758066 KL: 0.544906 Neg-log -1.302973  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.824134 KL: 0.544844 Neg-log -1.368977 MSE 0.036179035902023315\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.886044 KL: 0.544844 Neg-log -1.430887 MSE 0.032941438257694244\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 209\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.262914 KL: 0.544843 Neg-log -0.807757  [    0/30000]\n",
      "current batch loss: -0.918620 KL: 0.544661 Neg-log -1.463280  [12800/30000]\n",
      "current batch loss: 0.378776 KL: 0.544477 Neg-log -0.165701  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.852314 KL: 0.544411 Neg-log -1.396726 MSE 0.032843269407749176\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.846758 KL: 0.544411 Neg-log -1.391170 MSE 0.03420199826359749\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 210\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.942313 KL: 0.544412 Neg-log -1.486725  [    0/30000]\n",
      "current batch loss: -0.590489 KL: 0.544222 Neg-log -1.134710  [12800/30000]\n",
      "current batch loss: -0.748605 KL: 0.544044 Neg-log -1.292649  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.484551 KL: 0.543993 Neg-log -1.028545 MSE 0.0592658594250679\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.474857 KL: 0.543993 Neg-log -1.018850 MSE 0.06156855821609497\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 211\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.718489 KL: 0.543993 Neg-log -1.262482  [    0/30000]\n",
      "current batch loss: -1.024437 KL: 0.543818 Neg-log -1.568255  [12800/30000]\n",
      "current batch loss: -0.759207 KL: 0.543659 Neg-log -1.302866  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.770688 KL: 0.543587 Neg-log -1.314276 MSE 0.04006480053067207\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.658943 KL: 0.543587 Neg-log -1.202530 MSE 0.04644470661878586\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 212\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.865331 KL: 0.543587 Neg-log -1.408918  [    0/30000]\n",
      "current batch loss: -1.039911 KL: 0.543431 Neg-log -1.583343  [12800/30000]\n",
      "current batch loss: -0.882796 KL: 0.543265 Neg-log -1.426061  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.852277 KL: 0.543205 Neg-log -1.395481 MSE 0.03114348277449608\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.840367 KL: 0.543205 Neg-log -1.383571 MSE 0.033528976142406464\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 213\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.111670 KL: 0.543205 Neg-log -1.654875  [    0/30000]\n",
      "current batch loss: -0.462322 KL: 0.543059 Neg-log -1.005381  [12800/30000]\n",
      "current batch loss: -0.782634 KL: 0.542887 Neg-log -1.325521  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.897035 KL: 0.542830 Neg-log -1.439863 MSE 0.031244074925780296\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.876151 KL: 0.542830 Neg-log -1.418980 MSE 0.034036509692668915\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 214\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.884993 KL: 0.542829 Neg-log -1.427821  [    0/30000]\n",
      "current batch loss: -0.999911 KL: 0.542696 Neg-log -1.542606  [12800/30000]\n",
      "current batch loss: -0.480149 KL: 0.542531 Neg-log -1.022680  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.873578 KL: 0.542466 Neg-log -1.416045 MSE 0.03159520402550697\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.862239 KL: 0.542466 Neg-log -1.404706 MSE 0.035905659198760986\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 215\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.727450 KL: 0.542467 Neg-log -1.269917  [    0/30000]\n",
      "current batch loss: -0.901385 KL: 0.542308 Neg-log -1.443692  [12800/30000]\n",
      "current batch loss: -0.953301 KL: 0.542157 Neg-log -1.495458  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.754387 KL: 0.542105 Neg-log -1.296491 MSE 0.03881816938519478\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.717449 KL: 0.542105 Neg-log -1.259553 MSE 0.041461504995822906\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 216\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.055016 KL: 0.542105 Neg-log -1.597120  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -0.973982 KL: 0.541955 Neg-log -1.515937  [12800/30000]\n",
      "current batch loss: -0.948433 KL: 0.541795 Neg-log -1.490229  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.849643 KL: 0.541749 Neg-log -1.391392 MSE 0.03412996977567673\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.801430 KL: 0.541749 Neg-log -1.343180 MSE 0.03694286569952965\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 217\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.066455 KL: 0.541750 Neg-log -1.608204  [    0/30000]\n",
      "current batch loss: -1.032425 KL: 0.541582 Neg-log -1.574007  [12800/30000]\n",
      "current batch loss: -0.841316 KL: 0.541441 Neg-log -1.382757  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.859302 KL: 0.541382 Neg-log -1.400685 MSE 0.034155841916799545\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.818206 KL: 0.541382 Neg-log -1.359589 MSE 0.0387839637696743\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 218\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.753341 KL: 0.541383 Neg-log -1.294724  [    0/30000]\n",
      "current batch loss: -0.952230 KL: 0.541219 Neg-log -1.493448  [12800/30000]\n",
      "current batch loss: -0.444962 KL: 0.541045 Neg-log -0.986007  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.759892 KL: 0.540985 Neg-log -1.300877 MSE 0.03862314671278\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.749924 KL: 0.540985 Neg-log -1.290908 MSE 0.039063211530447006\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 219\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.714411 KL: 0.540985 Neg-log -1.255396  [    0/30000]\n",
      "current batch loss: -0.822703 KL: 0.540818 Neg-log -1.363521  [12800/30000]\n",
      "current batch loss: -0.850669 KL: 0.540640 Neg-log -1.391309  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.642997 KL: 0.540581 Neg-log -1.183580 MSE 0.04367685690522194\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.629333 KL: 0.540581 Neg-log -1.169915 MSE 0.04505643621087074\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 220\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.492921 KL: 0.540582 Neg-log -1.033503  [    0/30000]\n",
      "current batch loss: -1.036899 KL: 0.540410 Neg-log -1.577309  [12800/30000]\n",
      "current batch loss: -0.372468 KL: 0.540256 Neg-log -0.912724  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.906406 KL: 0.540207 Neg-log -1.446612 MSE 0.032254595309495926\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.883494 KL: 0.540207 Neg-log -1.423700 MSE 0.03166311979293823\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 221\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.077416 KL: 0.540206 Neg-log -1.617623  [    0/30000]\n",
      "current batch loss: -1.093196 KL: 0.540062 Neg-log -1.633258  [12800/30000]\n",
      "current batch loss: -1.047495 KL: 0.539899 Neg-log -1.587394  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.834482 KL: 0.539849 Neg-log -1.374333 MSE 0.03219087794423103\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.824681 KL: 0.539849 Neg-log -1.364531 MSE 0.033489253371953964\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 222\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.016779 KL: 0.539850 Neg-log -1.556628  [    0/30000]\n",
      "current batch loss: -0.556760 KL: 0.539704 Neg-log -1.096464  [12800/30000]\n",
      "current batch loss: -0.660741 KL: 0.539530 Neg-log -1.200271  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.928308 KL: 0.539461 Neg-log -1.467770 MSE 0.029659073799848557\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.409918 KL: 0.539461 Neg-log -0.949381 MSE 0.03369389846920967\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 223\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.572460 KL: 0.539463 Neg-log -1.111922  [    0/30000]\n",
      "current batch loss: -0.771247 KL: 0.539293 Neg-log -1.310541  [12800/30000]\n",
      "current batch loss: -1.009369 KL: 0.539131 Neg-log -1.548501  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.390626 KL: 0.539076 Neg-log -0.929700 MSE 0.060604508966207504\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.352168 KL: 0.539076 Neg-log -0.891242 MSE 0.06344013661146164\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 224\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.987919 KL: 0.539074 Neg-log -1.526993  [    0/30000]\n",
      "current batch loss: -0.638846 KL: 0.538926 Neg-log -1.177771  [12800/30000]\n",
      "current batch loss: -1.029787 KL: 0.538780 Neg-log -1.568567  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.755566 KL: 0.538725 Neg-log -1.294289 MSE 0.039949219673871994\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.768740 KL: 0.538725 Neg-log -1.307464 MSE 0.038432665169239044\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 225\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.060205 KL: 0.538724 Neg-log -1.598928  [    0/30000]\n",
      "current batch loss: -0.921553 KL: 0.538552 Neg-log -1.460106  [12800/30000]\n",
      "current batch loss: -0.818083 KL: 0.538386 Neg-log -1.356469  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.853173 KL: 0.538321 Neg-log -1.391494 MSE 0.031856659799814224\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.799977 KL: 0.538321 Neg-log -1.338298 MSE 0.035871706902980804\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 226\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.571027 KL: 0.538320 Neg-log -1.109347  [    0/30000]\n",
      "current batch loss: -1.074278 KL: 0.538163 Neg-log -1.612441  [12800/30000]\n",
      "current batch loss: -0.793390 KL: 0.537989 Neg-log -1.331379  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.913864 KL: 0.537933 Neg-log -1.451797 MSE 0.029268942773342133\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.898854 KL: 0.537933 Neg-log -1.436787 MSE 0.030628111213445663\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 227\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.114310 KL: 0.537933 Neg-log -1.652244  [    0/30000]\n",
      "current batch loss: -0.821197 KL: 0.537762 Neg-log -1.358959  [12800/30000]\n",
      "current batch loss: -1.073472 KL: 0.537610 Neg-log -1.611082  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.934636 KL: 0.537552 Neg-log -1.472188 MSE 0.02953576110303402\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.886953 KL: 0.537552 Neg-log -1.424506 MSE 0.03322451189160347\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 228\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.701714 KL: 0.537553 Neg-log -1.239267  [    0/30000]\n",
      "current batch loss: -0.884160 KL: 0.537395 Neg-log -1.421555  [12800/30000]\n",
      "current batch loss: -1.098451 KL: 0.537239 Neg-log -1.635690  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.920961 KL: 0.537187 Neg-log -1.458148 MSE 0.030532648786902428\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -0.896963 KL: 0.537187 Neg-log -1.434150 MSE 0.030943728983402252\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 229\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.340561 KL: 0.537188 Neg-log -0.877749  [    0/30000]\n",
      "current batch loss: -0.631570 KL: 0.537017 Neg-log -1.168586  [12800/30000]\n",
      "current batch loss: -0.701468 KL: 0.536864 Neg-log -1.238332  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.888582 KL: 0.536811 Neg-log -1.425392 MSE 0.03302214667201042\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.853987 KL: 0.536811 Neg-log -1.390797 MSE 0.035906143486499786\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 230\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.014513 KL: 0.536810 Neg-log -1.551323  [    0/30000]\n",
      "current batch loss: -1.145681 KL: 0.536642 Neg-log -1.682323  [12800/30000]\n",
      "current batch loss: -0.408355 KL: 0.536474 Neg-log -0.944830  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.648866 KL: 0.536421 Neg-log -1.185286 MSE 0.04191473126411438\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.641159 KL: 0.536421 Neg-log -1.177579 MSE 0.04288250952959061\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 231\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.848500 KL: 0.536420 Neg-log -1.384920  [    0/30000]\n",
      "current batch loss: -1.058137 KL: 0.536249 Neg-log -1.594386  [12800/30000]\n",
      "current batch loss: 0.022800 KL: 0.536077 Neg-log -0.513277  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.744359 KL: 0.536025 Neg-log -1.280383 MSE 0.03823382779955864\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.721103 KL: 0.536025 Neg-log -1.257128 MSE 0.04080486670136452\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 232\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.761279 KL: 0.536024 Neg-log -1.297303  [    0/30000]\n",
      "current batch loss: -0.508215 KL: 0.535859 Neg-log -1.044074  [12800/30000]\n",
      "current batch loss: -0.623563 KL: 0.535711 Neg-log -1.159274  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.806375 KL: 0.535654 Neg-log -1.342030 MSE 0.0359477698802948\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.788680 KL: 0.535654 Neg-log -1.324336 MSE 0.03843153268098831\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 233\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.754852 KL: 0.535655 Neg-log -1.290508  [    0/30000]\n",
      "current batch loss: -0.237860 KL: 0.535494 Neg-log -0.773354  [12800/30000]\n",
      "current batch loss: -0.578612 KL: 0.535351 Neg-log -1.113963  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.952135 KL: 0.535288 Neg-log -1.487424 MSE 0.03458277881145477\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.924525 KL: 0.535288 Neg-log -1.459814 MSE 0.029648737981915474\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 234\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.033661 KL: 0.535289 Neg-log -1.568949  [    0/30000]\n",
      "current batch loss: -1.016917 KL: 0.535127 Neg-log -1.552044  [12800/30000]\n",
      "current batch loss: -1.142224 KL: 0.534968 Neg-log -1.677192  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.949678 KL: 0.534906 Neg-log -1.484586 MSE 0.029037073254585266\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.959546 KL: 0.534906 Neg-log -1.494454 MSE 0.029286647215485573\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 235\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.108064 KL: 0.534907 Neg-log -1.642971  [    0/30000]\n",
      "current batch loss: -0.972616 KL: 0.534764 Neg-log -1.507379  [12800/30000]\n",
      "current batch loss: -1.032621 KL: 0.534609 Neg-log -1.567230  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.879123 KL: 0.534546 Neg-log -1.413671 MSE 0.03164409473538399\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.828272 KL: 0.534546 Neg-log -1.362820 MSE 0.03455878794193268\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 236\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.558822 KL: 0.534548 Neg-log -1.093369  [    0/30000]\n",
      "current batch loss: -0.527598 KL: 0.534377 Neg-log -1.061975  [12800/30000]\n",
      "current batch loss: -1.214974 KL: 0.534211 Neg-log -1.749186  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.851527 KL: 0.534165 Neg-log -1.385693 MSE 0.03135521709918976\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.812635 KL: 0.534165 Neg-log -1.346801 MSE 0.03287932276725769\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 237\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.641960 KL: 0.534166 Neg-log -1.176126  [    0/30000]\n",
      "current batch loss: -0.918014 KL: 0.534035 Neg-log -1.452049  [12800/30000]\n",
      "current batch loss: -1.022890 KL: 0.533888 Neg-log -1.556777  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.926177 KL: 0.533836 Neg-log -1.460013 MSE 0.028858507052063942\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.918215 KL: 0.533836 Neg-log -1.452050 MSE 0.028170380741357803\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 238\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.983204 KL: 0.533836 Neg-log -1.517040  [    0/30000]\n",
      "current batch loss: -0.935779 KL: 0.533684 Neg-log -1.469463  [12800/30000]\n",
      "current batch loss: -0.987110 KL: 0.533500 Neg-log -1.520611  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.867461 KL: 0.533447 Neg-log -1.400907 MSE 0.03266560658812523\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.854629 KL: 0.533447 Neg-log -1.388075 MSE 0.034371230751276016\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 239\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.975214 KL: 0.533446 Neg-log -1.508660  [    0/30000]\n",
      "current batch loss: -0.436584 KL: 0.533290 Neg-log -0.969874  [12800/30000]\n",
      "current batch loss: -1.088268 KL: 0.533118 Neg-log -1.621386  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.861148 KL: 0.533072 Neg-log -1.394218 MSE 0.034617651253938675\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.848348 KL: 0.533072 Neg-log -1.381419 MSE 0.036007605493068695\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 240\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.963926 KL: 0.533071 Neg-log -1.496997  [    0/30000]\n",
      "current batch loss: -1.203940 KL: 0.532912 Neg-log -1.736852  [12800/30000]\n",
      "current batch loss: -1.011787 KL: 0.532756 Neg-log -1.544542  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.677280 KL: 0.532702 Neg-log -1.209984 MSE 0.039561737328767776\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.725472 KL: 0.532702 Neg-log -1.258176 MSE 0.03741233050823212\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 241\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.998748 KL: 0.532703 Neg-log -1.531451  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.182626 KL: 0.532537 Neg-log -1.715164  [12800/30000]\n",
      "current batch loss: -0.150493 KL: 0.532387 Neg-log -0.682880  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.920784 KL: 0.532335 Neg-log -1.453121 MSE 0.029092492535710335\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.900584 KL: 0.532335 Neg-log -1.432920 MSE 0.031164037063717842\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 242\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.827192 KL: 0.532337 Neg-log -1.359529  [    0/30000]\n",
      "current batch loss: -1.028061 KL: 0.532176 Neg-log -1.560237  [12800/30000]\n",
      "current batch loss: -1.033387 KL: 0.532038 Neg-log -1.565425  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.992586 KL: 0.531982 Neg-log -1.524569 MSE 0.02683008834719658\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.968559 KL: 0.531982 Neg-log -1.500542 MSE 0.02828885056078434\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 243\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.030789 KL: 0.531982 Neg-log -1.562771  [    0/30000]\n",
      "current batch loss: -1.097540 KL: 0.531816 Neg-log -1.629355  [12800/30000]\n",
      "current batch loss: -1.079211 KL: 0.531660 Neg-log -1.610871  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.985338 KL: 0.531625 Neg-log -1.516963 MSE 0.026486076414585114\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.983319 KL: 0.531625 Neg-log -1.514945 MSE 0.028589757159352303\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 244\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.003359 KL: 0.531626 Neg-log -1.534985  [    0/30000]\n",
      "current batch loss: -0.516563 KL: 0.531477 Neg-log -1.048041  [12800/30000]\n",
      "current batch loss: -1.106413 KL: 0.531314 Neg-log -1.637726  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.992698 KL: 0.531258 Neg-log -1.523955 MSE 0.02552325651049614\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.004132 KL: 0.531258 Neg-log -1.535388 MSE 0.027329260483384132\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 245\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.271715 KL: 0.531257 Neg-log -1.802972  [    0/30000]\n",
      "current batch loss: -0.983134 KL: 0.531085 Neg-log -1.514219  [12800/30000]\n",
      "current batch loss: -1.136965 KL: 0.530916 Neg-log -1.667881  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.642559 KL: 0.530869 Neg-log -1.173429 MSE 0.04693097621202469\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.541949 KL: 0.530869 Neg-log -1.072818 MSE 0.05338520184159279\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 246\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.565508 KL: 0.530870 Neg-log -1.096378  [    0/30000]\n",
      "current batch loss: -0.996788 KL: 0.530690 Neg-log -1.527478  [12800/30000]\n",
      "current batch loss: 1.571792 KL: 0.530520 Neg-log 1.041272  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.872663 KL: 0.530456 Neg-log -1.403119 MSE 0.03607536852359772\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.846901 KL: 0.530456 Neg-log -1.377357 MSE 0.037280354648828506\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 247\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.653341 KL: 0.530456 Neg-log -1.183797  [    0/30000]\n",
      "current batch loss: -1.060923 KL: 0.530301 Neg-log -1.591224  [12800/30000]\n",
      "current batch loss: -0.340394 KL: 0.530131 Neg-log -0.870524  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.894832 KL: 0.530069 Neg-log -1.424904 MSE 0.0316256545484066\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.884074 KL: 0.530069 Neg-log -1.414145 MSE 0.03365457430481911\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 248\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.383649 KL: 0.530071 Neg-log -0.913720  [    0/30000]\n",
      "current batch loss: 0.440764 KL: 0.529902 Neg-log -0.089139  [12800/30000]\n",
      "current batch loss: 0.170780 KL: 0.529735 Neg-log -0.358955  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.910759 KL: 0.529672 Neg-log -1.440432 MSE 0.029042227193713188\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.890810 KL: 0.529672 Neg-log -1.420483 MSE 0.03163880109786987\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 249\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.947135 KL: 0.529673 Neg-log -1.476808  [    0/30000]\n",
      "current batch loss: -0.603133 KL: 0.529508 Neg-log -1.132641  [12800/30000]\n",
      "current batch loss: -1.053721 KL: 0.529327 Neg-log -1.583048  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.998744 KL: 0.529265 Neg-log -1.528009 MSE 0.026400471106171608\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.006642 KL: 0.529265 Neg-log -1.535906 MSE 0.025706827640533447\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 250\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.137006 KL: 0.529264 Neg-log -1.666270  [    0/30000]\n",
      "current batch loss: -0.981106 KL: 0.529124 Neg-log -1.510230  [12800/30000]\n",
      "current batch loss: -1.008028 KL: 0.528986 Neg-log -1.537015  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.007252 KL: 0.528933 Neg-log -1.536187 MSE 0.028645355254411697\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.977192 KL: 0.528933 Neg-log -1.506125 MSE 0.02699347585439682\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 251\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.146282 KL: 0.528934 Neg-log -1.675216  [    0/30000]\n",
      "current batch loss: -1.114541 KL: 0.528797 Neg-log -1.643338  [12800/30000]\n",
      "current batch loss: -0.886019 KL: 0.528637 Neg-log -1.414656  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.991738 KL: 0.528589 Neg-log -1.520328 MSE 0.02792331762611866\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.965848 KL: 0.528589 Neg-log -1.494438 MSE 0.02781532146036625\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 252\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.067578 KL: 0.528589 Neg-log -1.596167  [    0/30000]\n",
      "current batch loss: -0.842018 KL: 0.528445 Neg-log -1.370462  [12800/30000]\n",
      "current batch loss: -1.038440 KL: 0.528313 Neg-log -1.566752  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.827876 KL: 0.528261 Neg-log -1.356138 MSE 0.030813241377472878\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.803143 KL: 0.528261 Neg-log -1.331405 MSE 0.03178178146481514\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 253\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.904304 KL: 0.528262 Neg-log -1.432566  [    0/30000]\n",
      "current batch loss: -1.012578 KL: 0.528132 Neg-log -1.540710  [12800/30000]\n",
      "current batch loss: -1.126980 KL: 0.527993 Neg-log -1.654973  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.893282 KL: 0.527939 Neg-log -1.421223 MSE 0.03879028931260109\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -0.873172 KL: 0.527939 Neg-log -1.401113 MSE 0.03146633505821228\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 254\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.686828 KL: 0.527941 Neg-log -1.214769  [    0/30000]\n",
      "current batch loss: -0.007262 KL: 0.527790 Neg-log -0.535052  [12800/30000]\n",
      "current batch loss: -0.758634 KL: 0.527645 Neg-log -1.286279  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.028463 KL: 0.527603 Neg-log -1.556066 MSE 0.02505706436932087\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.020700 KL: 0.527603 Neg-log -1.548304 MSE 0.0251461174339056\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 255\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.730646 KL: 0.527604 Neg-log -1.258250  [    0/30000]\n",
      "current batch loss: -0.987356 KL: 0.527475 Neg-log -1.514830  [12800/30000]\n",
      "current batch loss: -0.829384 KL: 0.527337 Neg-log -1.356721  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.009748 KL: 0.527289 Neg-log -1.537036 MSE 0.028365587815642357\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.005948 KL: 0.527289 Neg-log -1.533236 MSE 0.026733528822660446\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 256\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.016642 KL: 0.527288 Neg-log -1.543930  [    0/30000]\n",
      "current batch loss: -0.928282 KL: 0.527157 Neg-log -1.455439  [12800/30000]\n",
      "current batch loss: -0.768319 KL: 0.527008 Neg-log -1.295327  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.886431 KL: 0.526962 Neg-log -1.413392 MSE 0.03222007304430008\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.841439 KL: 0.526962 Neg-log -1.368400 MSE 0.03615178167819977\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 257\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.027140 KL: 0.526961 Neg-log -1.554101  [    0/30000]\n",
      "current batch loss: -1.265092 KL: 0.526830 Neg-log -1.791922  [12800/30000]\n",
      "current batch loss: -1.042852 KL: 0.526708 Neg-log -1.569560  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.964576 KL: 0.526658 Neg-log -1.491234 MSE 0.025447912514209747\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.924212 KL: 0.526658 Neg-log -1.450870 MSE 0.02754570171236992\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 258\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.082984 KL: 0.526658 Neg-log -1.609643  [    0/30000]\n",
      "current batch loss: -0.521229 KL: 0.526520 Neg-log -1.047749  [12800/30000]\n",
      "current batch loss: -0.246179 KL: 0.526375 Neg-log -0.772554  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.027386 KL: 0.526321 Neg-log -1.553706 MSE 0.02432691678404808\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.028395 KL: 0.526321 Neg-log -1.554715 MSE 0.024311749264597893\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 259\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.557152 KL: 0.526320 Neg-log -1.083472  [    0/30000]\n",
      "current batch loss: -1.256255 KL: 0.526179 Neg-log -1.782434  [12800/30000]\n",
      "current batch loss: -0.830247 KL: 0.526039 Neg-log -1.356286  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.103560 KL: 0.525991 Neg-log -0.629551 MSE 0.059105273336172104\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.107240 KL: 0.525991 Neg-log -0.633231 MSE 0.06018831953406334\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 260\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.572196 KL: 0.525990 Neg-log -1.098186  [    0/30000]\n",
      "current batch loss: -1.155416 KL: 0.525838 Neg-log -1.681253  [12800/30000]\n",
      "current batch loss: -0.926038 KL: 0.525692 Neg-log -1.451730  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.032804 KL: 0.525642 Neg-log -1.558444 MSE 0.02406863123178482\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.997222 KL: 0.525642 Neg-log -1.522864 MSE 0.025400569662451744\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 261\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.189250 KL: 0.525641 Neg-log -1.714891  [    0/30000]\n",
      "current batch loss: -1.076428 KL: 0.525505 Neg-log -1.601933  [12800/30000]\n",
      "current batch loss: 0.462702 KL: 0.525370 Neg-log -0.062668  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.023893 KL: 0.525314 Neg-log -1.549208 MSE 0.025039786472916603\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.971326 KL: 0.525314 Neg-log -1.496641 MSE 0.026732176542282104\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 262\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.056398 KL: 0.525314 Neg-log -1.581712  [    0/30000]\n",
      "current batch loss: -1.182094 KL: 0.525169 Neg-log -1.707264  [12800/30000]\n",
      "current batch loss: -1.009780 KL: 0.525045 Neg-log -1.534824  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.940095 KL: 0.524987 Neg-log -1.465083 MSE 0.026976203545928\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.931430 KL: 0.524987 Neg-log -1.456418 MSE 0.02846185863018036\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 263\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.983714 KL: 0.524988 Neg-log -1.508701  [    0/30000]\n",
      "current batch loss: -0.981981 KL: 0.524854 Neg-log -1.506835  [12800/30000]\n",
      "current batch loss: -1.283780 KL: 0.524708 Neg-log -1.808488  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.051343 KL: 0.524668 Neg-log -1.576012 MSE 0.027929730713367462\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.022069 KL: 0.524668 Neg-log -1.546738 MSE 0.0282407458871603\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 264\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.134797 KL: 0.524669 Neg-log -1.659466  [    0/30000]\n",
      "current batch loss: -1.117128 KL: 0.524541 Neg-log -1.641669  [12800/30000]\n",
      "current batch loss: -1.222484 KL: 0.524426 Neg-log -1.746911  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.047783 KL: 0.524384 Neg-log -1.572167 MSE 0.024564655497670174\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.074120 KL: 0.524384 Neg-log -1.598504 MSE 0.025812674313783646\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 265\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.057345 KL: 0.524384 Neg-log -1.581729  [    0/30000]\n",
      "current batch loss: -0.991823 KL: 0.524275 Neg-log -1.516098  [12800/30000]\n",
      "current batch loss: -0.712554 KL: 0.524162 Neg-log -1.236717  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.041120 KL: 0.524125 Neg-log -1.565246 MSE 0.022698290646076202\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.014295 KL: 0.524125 Neg-log -1.538421 MSE 0.02600850723683834\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 266\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.179389 KL: 0.524125 Neg-log -1.703515  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.020424 KL: 0.524006 Neg-log -1.544430  [12800/30000]\n",
      "current batch loss: -0.883452 KL: 0.523894 Neg-log -1.407345  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.884600 KL: 0.523848 Neg-log -1.408446 MSE 0.031260278075933456\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.870626 KL: 0.523848 Neg-log -1.394472 MSE 0.03244753181934357\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 267\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.994206 KL: 0.523846 Neg-log -1.518052  [    0/30000]\n",
      "current batch loss: -1.258204 KL: 0.523699 Neg-log -1.781903  [12800/30000]\n",
      "current batch loss: -1.136277 KL: 0.523590 Neg-log -1.659867  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.648035 KL: 0.523544 Neg-log -1.171578 MSE 0.04096235707402229\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.656361 KL: 0.523544 Neg-log -1.179904 MSE 0.03958166390657425\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 268\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.120049 KL: 0.523543 Neg-log -1.643592  [    0/30000]\n",
      "current batch loss: -1.152632 KL: 0.523414 Neg-log -1.676046  [12800/30000]\n",
      "current batch loss: -0.735553 KL: 0.523297 Neg-log -1.258850  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.044840 KL: 0.523262 Neg-log -1.568103 MSE 0.025139568373560905\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.999717 KL: 0.523262 Neg-log -1.522980 MSE 0.026638705283403397\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 269\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.065492 KL: 0.523263 Neg-log -1.588755  [    0/30000]\n",
      "current batch loss: -1.056218 KL: 0.523148 Neg-log -1.579365  [12800/30000]\n",
      "current batch loss: -0.769865 KL: 0.523029 Neg-log -1.292894  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.064403 KL: 0.522980 Neg-log -1.587382 MSE 0.023451698943972588\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.044384 KL: 0.522980 Neg-log -1.567363 MSE 0.025793515145778656\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 270\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.144953 KL: 0.522979 Neg-log -0.378026  [    0/30000]\n",
      "current batch loss: -0.550807 KL: 0.522860 Neg-log -1.073668  [12800/30000]\n",
      "current batch loss: -1.124120 KL: 0.522752 Neg-log -1.646872  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.066465 KL: 0.522720 Neg-log -1.589185 MSE 0.02197973057627678\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.060515 KL: 0.522720 Neg-log -1.583235 MSE 0.02200179547071457\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 271\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.893158 KL: 0.522720 Neg-log -1.415879  [    0/30000]\n",
      "current batch loss: -1.113759 KL: 0.522607 Neg-log -1.636367  [12800/30000]\n",
      "current batch loss: -1.166793 KL: 0.522497 Neg-log -1.689290  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.078616 KL: 0.522461 Neg-log -1.601077 MSE 0.024191344156861305\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.076286 KL: 0.522461 Neg-log -1.598747 MSE 0.022749267518520355\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 272\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.930457 KL: 0.522462 Neg-log -1.452918  [    0/30000]\n",
      "current batch loss: -1.244728 KL: 0.522355 Neg-log -1.767083  [12800/30000]\n",
      "current batch loss: -0.863471 KL: 0.522255 Neg-log -1.385726  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.032368 KL: 0.522211 Neg-log -1.554579 MSE 0.025462795048952103\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.012683 KL: 0.522211 Neg-log -1.534894 MSE 0.026438575237989426\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 273\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.177997 KL: 0.522212 Neg-log -1.700209  [    0/30000]\n",
      "current batch loss: -1.011606 KL: 0.522083 Neg-log -1.533689  [12800/30000]\n",
      "current batch loss: -1.039098 KL: 0.521972 Neg-log -1.561070  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.072614 KL: 0.521942 Neg-log -1.594555 MSE 0.02551419846713543\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.045574 KL: 0.521942 Neg-log -1.567515 MSE 0.024684609845280647\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 274\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.955860 KL: 0.521941 Neg-log -1.477801  [    0/30000]\n",
      "current batch loss: -1.100014 KL: 0.521823 Neg-log -1.621837  [12800/30000]\n",
      "current batch loss: -0.651264 KL: 0.521709 Neg-log -1.172973  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.947208 KL: 0.521674 Neg-log -1.468881 MSE 0.029109224677085876\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.928102 KL: 0.521674 Neg-log -1.449774 MSE 0.02976270392537117\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 275\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.249270 KL: 0.521673 Neg-log -1.770943  [    0/30000]\n",
      "current batch loss: -1.011092 KL: 0.521571 Neg-log -1.532663  [12800/30000]\n",
      "current batch loss: -1.252663 KL: 0.521477 Neg-log -1.774140  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.071339 KL: 0.521448 Neg-log -1.592787 MSE 0.02400927245616913\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.050149 KL: 0.521448 Neg-log -1.571598 MSE 0.0244579054415226\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 276\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.112389 KL: 0.521448 Neg-log -1.633837  [    0/30000]\n",
      "current batch loss: -0.693487 KL: 0.521334 Neg-log -1.214821  [12800/30000]\n",
      "current batch loss: -1.201665 KL: 0.521215 Neg-log -1.722880  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.073809 KL: 0.521172 Neg-log -1.594981 MSE 0.02282198704779148\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.068553 KL: 0.521172 Neg-log -1.589725 MSE 0.023420672863721848\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 277\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.097392 KL: 0.521172 Neg-log -1.618564  [    0/30000]\n",
      "current batch loss: -1.110875 KL: 0.521068 Neg-log -1.631943  [12800/30000]\n",
      "current batch loss: -1.258643 KL: 0.520966 Neg-log -1.779609  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.108200 KL: 0.520922 Neg-log -1.629124 MSE 0.02077632024884224\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.095369 KL: 0.520922 Neg-log -1.616292 MSE 0.022906005382537842\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 278\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.407169 KL: 0.520923 Neg-log -0.928092  [    0/30000]\n",
      "current batch loss: -1.239920 KL: 0.520813 Neg-log -1.760733  [12800/30000]\n",
      "current batch loss: -1.250755 KL: 0.520728 Neg-log -1.771483  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.064234 KL: 0.520698 Neg-log -1.584932 MSE 0.022587331011891365\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -1.049359 KL: 0.520698 Neg-log -1.570056 MSE 0.023088615387678146\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 279\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.153434 KL: 0.520698 Neg-log -1.674131  [    0/30000]\n",
      "current batch loss: -1.274982 KL: 0.520581 Neg-log -1.795563  [12800/30000]\n",
      "current batch loss: -1.000885 KL: 0.520461 Neg-log -1.521346  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.122691 KL: 0.520424 Neg-log -1.643114 MSE 0.02204592153429985\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.079404 KL: 0.520424 Neg-log -1.599827 MSE 0.024539079517126083\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 280\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.807253 KL: 0.520424 Neg-log -1.327677  [    0/30000]\n",
      "current batch loss: -0.804599 KL: 0.520317 Neg-log -1.324917  [12800/30000]\n",
      "current batch loss: -0.969556 KL: 0.520207 Neg-log -1.489763  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.088351 KL: 0.520171 Neg-log -1.608521 MSE 0.021496696397662163\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.113789 KL: 0.520171 Neg-log -1.633958 MSE 0.022967243567109108\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 281\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.137378 KL: 0.520169 Neg-log -1.657547  [    0/30000]\n",
      "current batch loss: -0.796435 KL: 0.520049 Neg-log -1.316484  [12800/30000]\n",
      "current batch loss: -0.997792 KL: 0.519944 Neg-log -1.517735  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.885550 KL: 0.519904 Neg-log -1.405452 MSE 0.030743954703211784\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.849085 KL: 0.519904 Neg-log -1.368988 MSE 0.03236113488674164\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 282\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.970272 KL: 0.519903 Neg-log -1.490174  [    0/30000]\n",
      "current batch loss: -1.124460 KL: 0.519790 Neg-log -1.644250  [12800/30000]\n",
      "current batch loss: -1.136790 KL: 0.519674 Neg-log -1.656464  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.103032 KL: 0.519632 Neg-log -1.622664 MSE 0.021527932956814766\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.062791 KL: 0.519632 Neg-log -1.582423 MSE 0.02284516952931881\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 283\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.383034 KL: 0.519632 Neg-log -1.902666  [    0/30000]\n",
      "current batch loss: -1.225696 KL: 0.519528 Neg-log -1.745224  [12800/30000]\n",
      "current batch loss: -1.231893 KL: 0.519425 Neg-log -1.751319  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.092424 KL: 0.519386 Neg-log -1.611811 MSE 0.0239160917699337\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.079602 KL: 0.519386 Neg-log -1.598989 MSE 0.024120338261127472\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 284\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.199038 KL: 0.519387 Neg-log -1.718425  [    0/30000]\n",
      "current batch loss: -0.984254 KL: 0.519269 Neg-log -1.503523  [12800/30000]\n",
      "current batch loss: -1.121169 KL: 0.519172 Neg-log -1.640341  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.110122 KL: 0.519135 Neg-log -1.629258 MSE 0.020690347999334335\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.094753 KL: 0.519135 Neg-log -1.613889 MSE 0.021422427147626877\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 285\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.126863 KL: 0.519136 Neg-log -1.645999  [    0/30000]\n",
      "current batch loss: -0.941111 KL: 0.519028 Neg-log -1.460138  [12800/30000]\n",
      "current batch loss: -1.220656 KL: 0.518916 Neg-log -1.739571  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.163746 KL: 0.518877 Neg-log -1.682626 MSE 0.019661320373415947\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.131128 KL: 0.518877 Neg-log -1.650007 MSE 0.0221196711063385\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 286\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.105885 KL: 0.518879 Neg-log -1.624764  [    0/30000]\n",
      "current batch loss: -1.206987 KL: 0.518775 Neg-log -1.725762  [12800/30000]\n",
      "current batch loss: -1.282275 KL: 0.518683 Neg-log -1.800958  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.081999 KL: 0.518652 Neg-log -1.600650 MSE 0.03895488381385803\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.099016 KL: 0.518652 Neg-log -1.617666 MSE 0.02218490093946457\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 287\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.198758 KL: 0.518650 Neg-log -1.717408  [    0/30000]\n",
      "current batch loss: -0.764477 KL: 0.518549 Neg-log -1.283025  [12800/30000]\n",
      "current batch loss: -1.107481 KL: 0.518446 Neg-log -1.625926  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.090575 KL: 0.518393 Neg-log -1.608965 MSE 0.020009001716971397\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.070485 KL: 0.518393 Neg-log -1.588877 MSE 0.022214733064174652\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 288\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.161744 KL: 0.518392 Neg-log -1.680136  [    0/30000]\n",
      "current batch loss: -1.372904 KL: 0.518280 Neg-log -1.891184  [12800/30000]\n",
      "current batch loss: -1.261322 KL: 0.518182 Neg-log -1.779504  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.154016 KL: 0.518144 Neg-log -1.672161 MSE 0.022076543420553207\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.133400 KL: 0.518144 Neg-log -1.651546 MSE 0.023833464831113815\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 289\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.273542 KL: 0.518145 Neg-log -1.791688  [    0/30000]\n",
      "current batch loss: -0.367660 KL: 0.518053 Neg-log -0.885713  [12800/30000]\n",
      "current batch loss: -1.095142 KL: 0.517947 Neg-log -1.613089  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.148135 KL: 0.517906 Neg-log -1.666041 MSE 0.01990506239235401\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.153069 KL: 0.517906 Neg-log -1.670974 MSE 0.021644897758960724\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 290\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.705303 KL: 0.517905 Neg-log -1.223208  [    0/30000]\n",
      "current batch loss: -1.317345 KL: 0.517809 Neg-log -1.835155  [12800/30000]\n",
      "current batch loss: -1.261143 KL: 0.517722 Neg-log -1.778866  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.934583 KL: 0.517692 Neg-log -1.452275 MSE 0.030251003801822662\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.881091 KL: 0.517692 Neg-log -1.398783 MSE 0.03381955996155739\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 291\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.787642 KL: 0.517691 Neg-log -1.305333  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -0.378502 KL: 0.517593 Neg-log -0.896095  [12800/30000]\n",
      "current batch loss: -1.044809 KL: 0.517492 Neg-log -1.562301  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.154709 KL: 0.517463 Neg-log -1.672171 MSE 0.02105947583913803\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.132322 KL: 0.517463 Neg-log -1.649784 MSE 0.02172582782804966\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 292\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.170934 KL: 0.517463 Neg-log -1.688397  [    0/30000]\n",
      "current batch loss: -1.072779 KL: 0.517387 Neg-log -1.590166  [12800/30000]\n",
      "current batch loss: -1.114968 KL: 0.517298 Neg-log -1.632266  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.905206 KL: 0.517266 Neg-log -1.422474 MSE 0.02998431585729122\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.949172 KL: 0.517266 Neg-log -1.466439 MSE 0.02729182131588459\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 293\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.295360 KL: 0.517267 Neg-log -1.812627  [    0/30000]\n",
      "current batch loss: -1.121494 KL: 0.517177 Neg-log -1.638672  [12800/30000]\n",
      "current batch loss: -1.248894 KL: 0.517109 Neg-log -1.766003  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.955025 KL: 0.517089 Neg-log -1.472113 MSE 0.030224444344639778\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.979052 KL: 0.517089 Neg-log -1.496140 MSE 0.029635600745677948\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 294\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.177879 KL: 0.517088 Neg-log -1.694967  [    0/30000]\n",
      "current batch loss: -1.241368 KL: 0.516995 Neg-log -1.758362  [12800/30000]\n",
      "current batch loss: -1.107484 KL: 0.516909 Neg-log -1.624392  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.026934 KL: 0.516882 Neg-log -1.543816 MSE 0.024209387600421906\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.003978 KL: 0.516882 Neg-log -1.520860 MSE 0.025570904836058617\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 295\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.188287 KL: 0.516882 Neg-log -1.705169  [    0/30000]\n",
      "current batch loss: -0.618876 KL: 0.516804 Neg-log -1.135680  [12800/30000]\n",
      "current batch loss: -1.242378 KL: 0.516721 Neg-log -1.759099  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.157428 KL: 0.516684 Neg-log -1.674111 MSE 0.020311644300818443\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.149975 KL: 0.516684 Neg-log -1.666658 MSE 0.020299896597862244\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 296\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.319889 KL: 0.516683 Neg-log -1.836572  [    0/30000]\n",
      "current batch loss: -1.228601 KL: 0.516576 Neg-log -1.745177  [12800/30000]\n",
      "current batch loss: -1.131379 KL: 0.516485 Neg-log -1.647864  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.867090 KL: 0.516464 Neg-log -1.383552 MSE 0.0290483757853508\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.765339 KL: 0.516464 Neg-log -1.281801 MSE 0.036053404211997986\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 297\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.954940 KL: 0.516462 Neg-log -1.471402  [    0/30000]\n",
      "current batch loss: -0.987392 KL: 0.516371 Neg-log -1.503763  [12800/30000]\n",
      "current batch loss: -1.211253 KL: 0.516277 Neg-log -1.727530  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.165734 KL: 0.516249 Neg-log -1.681980 MSE 0.020890982821583748\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.166769 KL: 0.516249 Neg-log -1.683016 MSE 0.019374294206500053\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 298\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.104610 KL: 0.516247 Neg-log -1.620857  [    0/30000]\n",
      "current batch loss: -0.787233 KL: 0.516168 Neg-log -1.303401  [12800/30000]\n",
      "current batch loss: -1.393197 KL: 0.516097 Neg-log -1.909293  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.199300 KL: 0.516067 Neg-log -1.715366 MSE 0.017711913213133812\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.151322 KL: 0.516067 Neg-log -1.667388 MSE 0.021089818328619003\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 299\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.306296 KL: 0.516066 Neg-log -1.822361  [    0/30000]\n",
      "current batch loss: -0.668532 KL: 0.515973 Neg-log -1.184504  [12800/30000]\n",
      "current batch loss: -1.160294 KL: 0.515866 Neg-log -1.676160  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.119417 KL: 0.515833 Neg-log -1.635252 MSE 0.023765722289681435\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.135421 KL: 0.515833 Neg-log -1.651256 MSE 0.021547069773077965\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 300\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.237719 KL: 0.515835 Neg-log -1.753554  [    0/30000]\n",
      "current batch loss: -1.241016 KL: 0.515749 Neg-log -1.756765  [12800/30000]\n",
      "current batch loss: -0.577738 KL: 0.515669 Neg-log -1.093407  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.119121 KL: 0.515633 Neg-log -1.634754 MSE 0.02049470879137516\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.119870 KL: 0.515633 Neg-log -1.635503 MSE 0.0206765029579401\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 301\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.956259 KL: 0.515633 Neg-log -1.471892  [    0/30000]\n",
      "current batch loss: -1.334045 KL: 0.515526 Neg-log -1.849571  [12800/30000]\n",
      "current batch loss: -0.872490 KL: 0.515432 Neg-log -1.387923  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.930841 KL: 0.515396 Neg-log -1.446237 MSE 0.030642211437225342\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.923549 KL: 0.515396 Neg-log -1.438945 MSE 0.03183559700846672\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 302\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.280861 KL: 0.515396 Neg-log -1.796258  [    0/30000]\n",
      "current batch loss: -1.120727 KL: 0.515298 Neg-log -1.636025  [12800/30000]\n",
      "current batch loss: -1.347242 KL: 0.515199 Neg-log -1.862441  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.153184 KL: 0.515161 Neg-log -1.668345 MSE 0.019773468375205994\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.133297 KL: 0.515161 Neg-log -1.648459 MSE 0.02090037241578102\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 303\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.176358 KL: 0.515162 Neg-log -1.691520  [    0/30000]\n",
      "current batch loss: -1.283065 KL: 0.515069 Neg-log -1.798133  [12800/30000]\n",
      "current batch loss: -1.231986 KL: 0.514972 Neg-log -1.746958  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.034510 KL: 0.514946 Neg-log -1.549454 MSE 0.025460217148065567\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -1.030311 KL: 0.514946 Neg-log -1.545257 MSE 0.02527104876935482\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 304\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.216327 KL: 0.514945 Neg-log -1.731272  [    0/30000]\n",
      "current batch loss: -1.356821 KL: 0.514849 Neg-log -1.871670  [12800/30000]\n",
      "current batch loss: -0.888738 KL: 0.514758 Neg-log -1.403496  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.165074 KL: 0.514733 Neg-log -1.679807 MSE 0.02133217453956604\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.130663 KL: 0.514733 Neg-log -1.645397 MSE 0.01951785944402218\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 305\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.197440 KL: 0.514734 Neg-log -1.712173  [    0/30000]\n",
      "current batch loss: -0.942784 KL: 0.514636 Neg-log -1.457420  [12800/30000]\n",
      "current batch loss: -1.278161 KL: 0.514538 Neg-log -1.792699  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.984633 KL: 0.514503 Neg-log -1.499135 MSE 0.029178664088249207\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.978295 KL: 0.514503 Neg-log -1.492797 MSE 0.02684924565255642\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 306\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.836899 KL: 0.514502 Neg-log -1.351401  [    0/30000]\n",
      "current batch loss: -1.195100 KL: 0.514416 Neg-log -1.709517  [12800/30000]\n",
      "current batch loss: -1.260379 KL: 0.514330 Neg-log -1.774709  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.068900 KL: 0.514288 Neg-log -1.583188 MSE 0.021564187481999397\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.060937 KL: 0.514288 Neg-log -1.575224 MSE 0.022333022207021713\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 307\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.790165 KL: 0.514287 Neg-log -1.304453  [    0/30000]\n",
      "current batch loss: -1.047666 KL: 0.514185 Neg-log -1.561851  [12800/30000]\n",
      "current batch loss: -1.187575 KL: 0.514077 Neg-log -1.701652  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.944872 KL: 0.514039 Neg-log -1.458912 MSE 0.027946384623646736\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.944557 KL: 0.514039 Neg-log -1.458596 MSE 0.02404424548149109\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 308\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.269316 KL: 0.514039 Neg-log -1.783356  [    0/30000]\n",
      "current batch loss: -1.046618 KL: 0.513932 Neg-log -1.560550  [12800/30000]\n",
      "current batch loss: -1.195475 KL: 0.513841 Neg-log -1.709316  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.061648 KL: 0.513809 Neg-log -1.575457 MSE 0.023376094177365303\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.054817 KL: 0.513809 Neg-log -1.568626 MSE 0.02488006092607975\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 309\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.016267 KL: 0.513808 Neg-log -1.530075  [    0/30000]\n",
      "current batch loss: -1.138709 KL: 0.513729 Neg-log -1.652439  [12800/30000]\n",
      "current batch loss: -1.501202 KL: 0.513629 Neg-log -2.014831  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.128786 KL: 0.513602 Neg-log -1.642388 MSE 0.022701717913150787\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.101015 KL: 0.513602 Neg-log -1.614617 MSE 0.020867422223091125\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 310\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.195701 KL: 0.513601 Neg-log -1.709303  [    0/30000]\n",
      "current batch loss: -1.275254 KL: 0.513517 Neg-log -1.788771  [12800/30000]\n",
      "current batch loss: -1.069350 KL: 0.513417 Neg-log -1.582767  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.918740 KL: 0.513380 Neg-log -1.432118 MSE 0.025620603933930397\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.894053 KL: 0.513380 Neg-log -1.407432 MSE 0.025780245661735535\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 311\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.664386 KL: 0.513378 Neg-log -1.177764  [    0/30000]\n",
      "current batch loss: -0.826286 KL: 0.513276 Neg-log -1.339562  [12800/30000]\n",
      "current batch loss: -1.315842 KL: 0.513179 Neg-log -1.829021  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.229742 KL: 0.513159 Neg-log -1.742899 MSE 0.017056329175829887\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.223813 KL: 0.513159 Neg-log -1.736970 MSE 0.01809658296406269\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 312\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.334034 KL: 0.513157 Neg-log -1.847191  [    0/30000]\n",
      "current batch loss: -1.271772 KL: 0.513056 Neg-log -1.784828  [12800/30000]\n",
      "current batch loss: -1.066548 KL: 0.512969 Neg-log -1.579518  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.196105 KL: 0.512941 Neg-log -1.709048 MSE 0.018811848014593124\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.191391 KL: 0.512941 Neg-log -1.704334 MSE 0.019547712057828903\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 313\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.341469 KL: 0.512943 Neg-log -1.854412  [    0/30000]\n",
      "current batch loss: -1.231544 KL: 0.512835 Neg-log -1.744379  [12800/30000]\n",
      "current batch loss: -1.304465 KL: 0.512732 Neg-log -1.817197  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.117780 KL: 0.512695 Neg-log -1.630474 MSE 0.020575525239109993\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.071367 KL: 0.512695 Neg-log -1.584062 MSE 0.022038154304027557\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 314\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.446979 KL: 0.512694 Neg-log -0.959674  [    0/30000]\n",
      "current batch loss: -1.234740 KL: 0.512595 Neg-log -1.747335  [12800/30000]\n",
      "current batch loss: -0.911876 KL: 0.512507 Neg-log -1.424383  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.210102 KL: 0.512476 Neg-log -1.722580 MSE 0.018940698355436325\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.169937 KL: 0.512476 Neg-log -1.682415 MSE 0.019410844892263412\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 315\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.185044 KL: 0.512477 Neg-log -1.697521  [    0/30000]\n",
      "current batch loss: -0.273044 KL: 0.512374 Neg-log -0.785418  [12800/30000]\n",
      "current batch loss: -1.219115 KL: 0.512272 Neg-log -1.731387  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.146461 KL: 0.512237 Neg-log -1.658697 MSE 0.019550401717424393\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.144207 KL: 0.512237 Neg-log -1.656443 MSE 0.018582062795758247\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 316\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.130980 KL: 0.512237 Neg-log -1.643217  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.101455 KL: 0.512125 Neg-log -1.613580  [12800/30000]\n",
      "current batch loss: -1.169957 KL: 0.512024 Neg-log -1.681981  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.213411 KL: 0.511984 Neg-log -1.725394 MSE 0.01728089712560177\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.196215 KL: 0.511984 Neg-log -1.708199 MSE 0.018347885459661484\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 317\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.284379 KL: 0.511983 Neg-log -1.796362  [    0/30000]\n",
      "current batch loss: -0.856974 KL: 0.511901 Neg-log -1.368875  [12800/30000]\n",
      "current batch loss: -1.386476 KL: 0.511822 Neg-log -1.898298  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.271664 KL: 0.511787 Neg-log -1.783452 MSE 0.016596918925642967\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.234985 KL: 0.511787 Neg-log -1.746773 MSE 0.018485436215996742\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 318\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.785793 KL: 0.511787 Neg-log -1.297580  [    0/30000]\n",
      "current batch loss: -1.204226 KL: 0.511676 Neg-log -1.715901  [12800/30000]\n",
      "current batch loss: -1.243650 KL: 0.511581 Neg-log -1.755231  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.988543 KL: 0.511543 Neg-log -1.500086 MSE 0.02677992731332779\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.886975 KL: 0.511543 Neg-log -1.398519 MSE 0.03279741853475571\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 319\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.267833 KL: 0.511544 Neg-log -1.779377  [    0/30000]\n",
      "current batch loss: -1.167401 KL: 0.511455 Neg-log -1.678856  [12800/30000]\n",
      "current batch loss: -1.364001 KL: 0.511368 Neg-log -1.875369  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.125753 KL: 0.511335 Neg-log -1.637087 MSE 0.030996283516287804\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.091637 KL: 0.511335 Neg-log -1.602971 MSE 0.024473192170262337\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 320\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.449649 KL: 0.511334 Neg-log -1.960983  [    0/30000]\n",
      "current batch loss: -0.824111 KL: 0.511256 Neg-log -1.335367  [12800/30000]\n",
      "current batch loss: -1.504138 KL: 0.511149 Neg-log -2.015287  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.720835 KL: 0.511124 Neg-log -1.231959 MSE 0.031637489795684814\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.671583 KL: 0.511124 Neg-log -1.182707 MSE 0.032812658697366714\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 321\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.072023 KL: 0.511124 Neg-log -1.583147  [    0/30000]\n",
      "current batch loss: -1.404712 KL: 0.511048 Neg-log -1.915760  [12800/30000]\n",
      "current batch loss: -1.171443 KL: 0.510967 Neg-log -1.682410  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.255466 KL: 0.510918 Neg-log -1.766386 MSE 0.016707366332411766\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.227577 KL: 0.510918 Neg-log -1.738497 MSE 0.01802264340221882\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 322\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.324714 KL: 0.510919 Neg-log -1.835633  [    0/30000]\n",
      "current batch loss: -1.172382 KL: 0.510825 Neg-log -1.683206  [12800/30000]\n",
      "current batch loss: -0.744035 KL: 0.510742 Neg-log -1.254777  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.252532 KL: 0.510712 Neg-log -1.763245 MSE 0.017586208879947662\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.225973 KL: 0.510712 Neg-log -1.736685 MSE 0.020201094448566437\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 323\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.374896 KL: 0.510713 Neg-log -1.885609  [    0/30000]\n",
      "current batch loss: -0.590363 KL: 0.510613 Neg-log -1.100977  [12800/30000]\n",
      "current batch loss: -1.215691 KL: 0.510514 Neg-log -1.726205  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.135871 KL: 0.510484 Neg-log -1.646357 MSE 0.02150185965001583\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.112412 KL: 0.510484 Neg-log -1.622898 MSE 0.019734248518943787\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 324\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.297068 KL: 0.510485 Neg-log -1.807553  [    0/30000]\n",
      "current batch loss: -1.381189 KL: 0.510389 Neg-log -1.891578  [12800/30000]\n",
      "current batch loss: -1.300104 KL: 0.510306 Neg-log -1.810410  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.184907 KL: 0.510271 Neg-log -1.695179 MSE 0.09965439885854721\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.186597 KL: 0.510271 Neg-log -1.696869 MSE 0.01912209391593933\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 325\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.809789 KL: 0.510273 Neg-log -1.320061  [    0/30000]\n",
      "current batch loss: -0.561547 KL: 0.510169 Neg-log -1.071716  [12800/30000]\n",
      "current batch loss: -1.257033 KL: 0.510095 Neg-log -1.767127  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.194622 KL: 0.510069 Neg-log -1.704689 MSE 0.019078746438026428\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.180908 KL: 0.510069 Neg-log -1.690975 MSE 0.01890590786933899\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 326\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.334583 KL: 0.510067 Neg-log -1.844650  [    0/30000]\n",
      "current batch loss: -1.216065 KL: 0.509975 Neg-log -1.726039  [12800/30000]\n",
      "current batch loss: -1.297623 KL: 0.509907 Neg-log -1.807530  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.235139 KL: 0.509878 Neg-log -1.745016 MSE 0.01902422122657299\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.216480 KL: 0.509878 Neg-log -1.726357 MSE 0.018891865387558937\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 327\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.417385 KL: 0.509877 Neg-log -1.927262  [    0/30000]\n",
      "current batch loss: -1.375104 KL: 0.509793 Neg-log -1.884898  [12800/30000]\n",
      "current batch loss: -1.456785 KL: 0.509699 Neg-log -1.966484  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.262941 KL: 0.509674 Neg-log -1.772614 MSE 0.018528519198298454\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.266440 KL: 0.509674 Neg-log -1.776113 MSE 0.01802891492843628\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 328\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.194659 KL: 0.509673 Neg-log -1.704332  [    0/30000]\n",
      "current batch loss: -1.387195 KL: 0.509580 Neg-log -1.896775  [12800/30000]\n",
      "current batch loss: -1.463085 KL: 0.509485 Neg-log -1.972570  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.303547 KL: 0.509454 Neg-log -1.813002 MSE 0.018069103360176086\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -1.265667 KL: 0.509454 Neg-log -1.775122 MSE 0.01722918078303337\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 329\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.482617 KL: 0.509455 Neg-log -1.992072  [    0/30000]\n",
      "current batch loss: -1.058801 KL: 0.509347 Neg-log -1.568148  [12800/30000]\n",
      "current batch loss: -0.830173 KL: 0.509267 Neg-log -1.339440  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.183807 KL: 0.509239 Neg-log -1.693045 MSE 0.02303941175341606\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.156624 KL: 0.509239 Neg-log -1.665862 MSE 0.01949862577021122\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 330\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.316874 KL: 0.509238 Neg-log -1.826112  [    0/30000]\n",
      "current batch loss: -1.301960 KL: 0.509164 Neg-log -1.811124  [12800/30000]\n",
      "current batch loss: -1.313131 KL: 0.509070 Neg-log -1.822201  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.212739 KL: 0.509047 Neg-log -1.721785 MSE 0.017662856727838516\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.196596 KL: 0.509047 Neg-log -1.705642 MSE 0.018409326672554016\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 331\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.315990 KL: 0.509046 Neg-log -1.825036  [    0/30000]\n",
      "current batch loss: -1.257760 KL: 0.508957 Neg-log -1.766717  [12800/30000]\n",
      "current batch loss: -0.943354 KL: 0.508888 Neg-log -1.452242  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.286480 KL: 0.508860 Neg-log -1.795342 MSE 0.017079079523682594\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.262802 KL: 0.508860 Neg-log -1.771664 MSE 0.017087331041693687\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 332\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.306232 KL: 0.508861 Neg-log -1.815094  [    0/30000]\n",
      "current batch loss: -1.400527 KL: 0.508776 Neg-log -1.909302  [12800/30000]\n",
      "current batch loss: -1.285015 KL: 0.508675 Neg-log -1.793690  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.160892 KL: 0.508642 Neg-log -1.669534 MSE 0.018228184431791306\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.160767 KL: 0.508642 Neg-log -1.669408 MSE 0.019167544320225716\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 333\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.448209 KL: 0.508641 Neg-log -0.956851  [    0/30000]\n",
      "current batch loss: -1.210443 KL: 0.508536 Neg-log -1.718979  [12800/30000]\n",
      "current batch loss: -1.401935 KL: 0.508459 Neg-log -1.910394  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.812423 KL: 0.508438 Neg-log -1.320860 MSE 0.029145635664463043\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.786721 KL: 0.508438 Neg-log -1.295157 MSE 0.030481673777103424\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 334\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.261233 KL: 0.508437 Neg-log -1.769669  [    0/30000]\n",
      "current batch loss: -1.233532 KL: 0.508363 Neg-log -1.741894  [12800/30000]\n",
      "current batch loss: -1.352904 KL: 0.508282 Neg-log -1.861185  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.317803 KL: 0.508242 Neg-log -1.826046 MSE 0.015609754249453545\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.267707 KL: 0.508242 Neg-log -1.775950 MSE 0.017404789105057716\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 335\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.916902 KL: 0.508243 Neg-log -1.425145  [    0/30000]\n",
      "current batch loss: -1.316042 KL: 0.508175 Neg-log -1.824217  [12800/30000]\n",
      "current batch loss: -1.346237 KL: 0.508113 Neg-log -1.854350  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.284871 KL: 0.508088 Neg-log -1.792959 MSE 0.017322394996881485\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.227317 KL: 0.508088 Neg-log -1.735405 MSE 0.01926524005830288\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 336\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.317992 KL: 0.508089 Neg-log -1.826080  [    0/30000]\n",
      "current batch loss: -1.332137 KL: 0.507999 Neg-log -1.840136  [12800/30000]\n",
      "current batch loss: -1.210978 KL: 0.507924 Neg-log -1.718902  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.265140 KL: 0.507904 Neg-log -1.773042 MSE 0.017762988805770874\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.275585 KL: 0.507904 Neg-log -1.783488 MSE 0.017755022272467613\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 337\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.391951 KL: 0.507903 Neg-log -1.899854  [    0/30000]\n",
      "current batch loss: -1.230086 KL: 0.507814 Neg-log -1.737900  [12800/30000]\n",
      "current batch loss: -1.319561 KL: 0.507731 Neg-log -1.827291  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.047207 KL: 0.507700 Neg-log -1.554909 MSE 0.0220915749669075\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.024880 KL: 0.507700 Neg-log -1.532581 MSE 0.023168792948126793\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 338\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.241467 KL: 0.507701 Neg-log -1.749169  [    0/30000]\n",
      "current batch loss: -1.395648 KL: 0.507625 Neg-log -1.903274  [12800/30000]\n",
      "current batch loss: -1.254540 KL: 0.507528 Neg-log -1.762067  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.293630 KL: 0.507498 Neg-log -1.801127 MSE 0.016621291637420654\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.287849 KL: 0.507498 Neg-log -1.795346 MSE 0.017682062461972237\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 339\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.415673 KL: 0.507497 Neg-log -1.923170  [    0/30000]\n",
      "current batch loss: -1.198166 KL: 0.507421 Neg-log -1.705587  [12800/30000]\n",
      "current batch loss: -1.476723 KL: 0.507358 Neg-log -1.984082  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.606468 KL: 0.507347 Neg-log -1.113813 MSE 0.031668420881032944\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.655343 KL: 0.507347 Neg-log -1.162689 MSE 0.03154534101486206\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 340\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.696610 KL: 0.507345 Neg-log -1.203955  [    0/30000]\n",
      "current batch loss: -1.285866 KL: 0.507247 Neg-log -1.793114  [12800/30000]\n",
      "current batch loss: -1.326188 KL: 0.507170 Neg-log -1.833357  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.239006 KL: 0.507134 Neg-log -1.746140 MSE 0.016859302297234535\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.240930 KL: 0.507134 Neg-log -1.748065 MSE 0.017022687941789627\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 341\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.360334 KL: 0.507134 Neg-log -1.867468  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.279171 KL: 0.507047 Neg-log -1.786218  [12800/30000]\n",
      "current batch loss: -1.452896 KL: 0.506966 Neg-log -1.959862  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.310696 KL: 0.506941 Neg-log -1.817635 MSE 0.01660451851785183\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.283347 KL: 0.506941 Neg-log -1.790287 MSE 0.017177250236272812\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 342\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.458333 KL: 0.506939 Neg-log -1.965273  [    0/30000]\n",
      "current batch loss: -1.274472 KL: 0.506848 Neg-log -1.781320  [12800/30000]\n",
      "current batch loss: -0.908653 KL: 0.506760 Neg-log -1.415413  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.293065 KL: 0.506731 Neg-log -1.799797 MSE 0.02468849904835224\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.281238 KL: 0.506731 Neg-log -1.787969 MSE 0.016345037147402763\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 343\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.894184 KL: 0.506731 Neg-log -1.400916  [    0/30000]\n",
      "current batch loss: -1.377271 KL: 0.506637 Neg-log -1.883908  [12800/30000]\n",
      "current batch loss: -1.171726 KL: 0.506554 Neg-log -1.678279  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.257990 KL: 0.506517 Neg-log -1.764508 MSE 0.01721988059580326\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.165588 KL: 0.506517 Neg-log -1.672106 MSE 0.019667673856019974\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 344\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.498203 KL: 0.506518 Neg-log -2.004721  [    0/30000]\n",
      "current batch loss: -1.436408 KL: 0.506440 Neg-log -1.942848  [12800/30000]\n",
      "current batch loss: -1.075774 KL: 0.506355 Neg-log -1.582129  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.188835 KL: 0.506327 Neg-log -1.695164 MSE 0.021942196413874626\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.129592 KL: 0.506327 Neg-log -1.635920 MSE 0.023045005276799202\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 345\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.316379 KL: 0.506328 Neg-log -1.822707  [    0/30000]\n",
      "current batch loss: -0.626646 KL: 0.506260 Neg-log -1.132906  [12800/30000]\n",
      "current batch loss: -0.986143 KL: 0.506175 Neg-log -1.492318  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.783627 KL: 0.506140 Neg-log -1.289766 MSE 0.025133952498435974\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.750990 KL: 0.506140 Neg-log -1.257130 MSE 0.02638019621372223\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 346\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.545022 KL: 0.506140 Neg-log -1.051161  [    0/30000]\n",
      "current batch loss: -1.269645 KL: 0.506063 Neg-log -1.775708  [12800/30000]\n",
      "current batch loss: -1.316149 KL: 0.505994 Neg-log -1.822144  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.238728 KL: 0.505959 Neg-log -1.744686 MSE 0.019900543615221977\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.173357 KL: 0.505959 Neg-log -1.679316 MSE 0.020923299714922905\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 347\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.829028 KL: 0.505959 Neg-log -1.334986  [    0/30000]\n",
      "current batch loss: -1.115347 KL: 0.505899 Neg-log -1.621246  [12800/30000]\n",
      "current batch loss: -1.127365 KL: 0.505815 Neg-log -1.633180  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.316311 KL: 0.505785 Neg-log -1.822097 MSE 0.015519239939749241\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.783629 KL: 0.505785 Neg-log -1.289416 MSE 0.020125215873122215\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 348\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.417126 KL: 0.505787 Neg-log -1.922913  [    0/30000]\n",
      "current batch loss: -1.306837 KL: 0.505737 Neg-log -1.812575  [12800/30000]\n",
      "current batch loss: -1.263317 KL: 0.505640 Neg-log -1.768957  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.070876 KL: 0.505602 Neg-log -1.576478 MSE 0.025654420256614685\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.057705 KL: 0.505602 Neg-log -1.563307 MSE 0.02642679587006569\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 349\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.213693 KL: 0.505603 Neg-log -1.719296  [    0/30000]\n",
      "current batch loss: -1.093965 KL: 0.505529 Neg-log -1.599494  [12800/30000]\n",
      "current batch loss: -1.502864 KL: 0.505456 Neg-log -2.008320  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.318933 KL: 0.505440 Neg-log -1.824374 MSE 0.015712440013885498\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.304405 KL: 0.505440 Neg-log -1.809845 MSE 0.016191883012652397\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 350\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.336239 KL: 0.505441 Neg-log -1.841680  [    0/30000]\n",
      "current batch loss: -0.826284 KL: 0.505387 Neg-log -1.331671  [12800/30000]\n",
      "current batch loss: -1.514531 KL: 0.505326 Neg-log -2.019857  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.351787 KL: 0.505295 Neg-log -1.857083 MSE 0.016060061752796173\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.320791 KL: 0.505295 Neg-log -1.826087 MSE 0.016141755506396294\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 351\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.118099 KL: 0.505296 Neg-log -1.623395  [    0/30000]\n",
      "current batch loss: -1.383396 KL: 0.505221 Neg-log -1.888617  [12800/30000]\n",
      "current batch loss: -1.476325 KL: 0.505170 Neg-log -1.981496  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.311920 KL: 0.505148 Neg-log -1.817066 MSE 0.016260933130979538\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.325053 KL: 0.505148 Neg-log -1.830201 MSE 0.015980685129761696\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 352\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.165415 KL: 0.505147 Neg-log -1.670563  [    0/30000]\n",
      "current batch loss: -1.384410 KL: 0.505073 Neg-log -1.889483  [12800/30000]\n",
      "current batch loss: -1.387548 KL: 0.505006 Neg-log -1.892554  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.871095 KL: 0.504982 Neg-log -1.376076 MSE 0.02656923048198223\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.867039 KL: 0.504982 Neg-log -1.372020 MSE 0.027821889147162437\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 353\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.134317 KL: 0.504981 Neg-log -1.639298  [    0/30000]\n",
      "current batch loss: -1.232097 KL: 0.504926 Neg-log -1.737023  [12800/30000]\n",
      "current batch loss: -1.274623 KL: 0.504874 Neg-log -1.779497  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.352796 KL: 0.504839 Neg-log -1.857638 MSE 0.01514828484505415\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -1.330460 KL: 0.504839 Neg-log -1.835301 MSE 0.01493429858237505\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 354\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.387212 KL: 0.504841 Neg-log -1.892053  [    0/30000]\n",
      "current batch loss: -1.089578 KL: 0.504793 Neg-log -1.594371  [12800/30000]\n",
      "current batch loss: -1.529592 KL: 0.504719 Neg-log -2.034311  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.303575 KL: 0.504694 Neg-log -1.808270 MSE 0.015317699871957302\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.262313 KL: 0.504694 Neg-log -1.767008 MSE 0.016701452434062958\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 355\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.453503 KL: 0.504695 Neg-log -1.958199  [    0/30000]\n",
      "current batch loss: -1.414318 KL: 0.504640 Neg-log -1.918958  [12800/30000]\n",
      "current batch loss: -1.117466 KL: 0.504569 Neg-log -1.622036  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.341541 KL: 0.504547 Neg-log -1.846088 MSE 0.014417221769690514\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.333776 KL: 0.504547 Neg-log -1.838324 MSE 0.015114440582692623\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 356\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.538472 KL: 0.504548 Neg-log -2.043020  [    0/30000]\n",
      "current batch loss: -0.860938 KL: 0.504479 Neg-log -1.365418  [12800/30000]\n",
      "current batch loss: -1.064701 KL: 0.504426 Neg-log -1.569128  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.363648 KL: 0.504402 Neg-log -1.868049 MSE 0.018670890480279922\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.347396 KL: 0.504402 Neg-log -1.851797 MSE 0.014229428954422474\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 357\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.135077 KL: 0.504401 Neg-log -1.639479  [    0/30000]\n",
      "current batch loss: -1.523208 KL: 0.504341 Neg-log -2.027549  [12800/30000]\n",
      "current batch loss: -1.450191 KL: 0.504281 Neg-log -1.954472  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.303361 KL: 0.504271 Neg-log -1.807631 MSE 0.016093581914901733\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.297185 KL: 0.504271 Neg-log -1.801455 MSE 0.016388677060604095\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 358\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.381963 KL: 0.504270 Neg-log -1.886233  [    0/30000]\n",
      "current batch loss: -1.536672 KL: 0.504236 Neg-log -2.040908  [12800/30000]\n",
      "current batch loss: -1.585527 KL: 0.504196 Neg-log -2.089724  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.347506 KL: 0.504179 Neg-log -1.851684 MSE 0.015051261521875858\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.322516 KL: 0.504179 Neg-log -1.826694 MSE 0.01590590924024582\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 359\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.491735 KL: 0.504178 Neg-log -1.995914  [    0/30000]\n",
      "current batch loss: -1.026142 KL: 0.504129 Neg-log -1.530271  [12800/30000]\n",
      "current batch loss: -1.395739 KL: 0.504080 Neg-log -1.899819  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.345467 KL: 0.504061 Neg-log -1.849530 MSE 0.014562473632395267\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.349205 KL: 0.504061 Neg-log -1.853268 MSE 0.014674423262476921\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 360\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.461840 KL: 0.504063 Neg-log -1.965903  [    0/30000]\n",
      "current batch loss: -1.331411 KL: 0.504011 Neg-log -1.835421  [12800/30000]\n",
      "current batch loss: -1.140520 KL: 0.503959 Neg-log -1.644479  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.383391 KL: 0.503938 Neg-log -1.887330 MSE 0.014256893657147884\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.360435 KL: 0.503938 Neg-log -1.864375 MSE 0.014358642511069775\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 361\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.452851 KL: 0.503939 Neg-log -1.956790  [    0/30000]\n",
      "current batch loss: -1.499619 KL: 0.503892 Neg-log -2.003512  [12800/30000]\n",
      "current batch loss: -1.072836 KL: 0.503839 Neg-log -1.576675  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 2.981205 KL: 0.503828 Neg-log 2.477377 MSE 0.03191620111465454\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.156985 KL: 0.503828 Neg-log -1.660813 MSE 0.024799702689051628\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 362\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.235376 KL: 0.503828 Neg-log -1.739203  [    0/30000]\n",
      "current batch loss: -1.175537 KL: 0.503761 Neg-log -1.679297  [12800/30000]\n",
      "current batch loss: -1.333138 KL: 0.503703 Neg-log -1.836841  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.310649 KL: 0.503679 Neg-log -1.814329 MSE 0.015128786675632\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.302965 KL: 0.503679 Neg-log -1.806646 MSE 0.015742560848593712\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 363\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.483035 KL: 0.503681 Neg-log -1.986716  [    0/30000]\n",
      "current batch loss: -1.534477 KL: 0.503615 Neg-log -2.038092  [12800/30000]\n",
      "current batch loss: -1.512769 KL: 0.503569 Neg-log -2.016338  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.256765 KL: 0.503550 Neg-log -1.760316 MSE 0.021042343229055405\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.213334 KL: 0.503550 Neg-log -1.716885 MSE 0.020291747525334358\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 364\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.479404 KL: 0.503551 Neg-log -1.982955  [    0/30000]\n",
      "current batch loss: -1.495241 KL: 0.503486 Neg-log -1.998727  [12800/30000]\n",
      "current batch loss: -1.488226 KL: 0.503443 Neg-log -1.991669  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.950035 KL: 0.503420 Neg-log -1.453455 MSE 0.024728931486606598\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.892152 KL: 0.503420 Neg-log -1.395572 MSE 0.026787396520376205\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 365\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.956673 KL: 0.503420 Neg-log -1.460093  [    0/30000]\n",
      "current batch loss: -1.495805 KL: 0.503345 Neg-log -1.999150  [12800/30000]\n",
      "current batch loss: -1.497931 KL: 0.503277 Neg-log -2.001208  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.349251 KL: 0.503259 Neg-log -1.852511 MSE 0.015840623527765274\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.308315 KL: 0.503259 Neg-log -1.811575 MSE 0.01753738336265087\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 366\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.276170 KL: 0.503260 Neg-log -1.779431  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.353941 KL: 0.503234 Neg-log -1.857175  [12800/30000]\n",
      "current batch loss: 0.490515 KL: 0.503204 Neg-log -0.012689  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.341274 KL: 0.503182 Neg-log -1.844456 MSE 0.01460430957376957\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.332426 KL: 0.503182 Neg-log -1.835608 MSE 0.014570891857147217\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 367\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.462976 KL: 0.503182 Neg-log -1.966158  [    0/30000]\n",
      "current batch loss: -1.521852 KL: 0.503127 Neg-log -2.024979  [12800/30000]\n",
      "current batch loss: -1.433107 KL: 0.503075 Neg-log -1.936182  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.395443 KL: 0.503044 Neg-log -1.898487 MSE 0.013341882266104221\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.363143 KL: 0.503044 Neg-log -1.866188 MSE 0.014427912421524525\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 368\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.437347 KL: 0.503045 Neg-log -1.940391  [    0/30000]\n",
      "current batch loss: -1.417411 KL: 0.502995 Neg-log -1.920406  [12800/30000]\n",
      "current batch loss: -1.277638 KL: 0.502946 Neg-log -1.780584  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.099274 KL: 0.502930 Neg-log -1.602203 MSE 0.021154126152396202\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.078167 KL: 0.502930 Neg-log -1.581096 MSE 0.020999176427721977\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 369\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.455418 KL: 0.502929 Neg-log -1.958347  [    0/30000]\n",
      "current batch loss: -1.359663 KL: 0.502883 Neg-log -1.862547  [12800/30000]\n",
      "current batch loss: -1.473515 KL: 0.502842 Neg-log -1.976357  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.303247 KL: 0.502823 Neg-log -1.806070 MSE 0.01583303138613701\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.268482 KL: 0.502823 Neg-log -1.771306 MSE 0.018571283668279648\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 370\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.445468 KL: 0.502823 Neg-log -1.948291  [    0/30000]\n",
      "current batch loss: -1.304651 KL: 0.502773 Neg-log -1.807424  [12800/30000]\n",
      "current batch loss: -1.486508 KL: 0.502735 Neg-log -1.989242  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.405234 KL: 0.502722 Neg-log -1.907956 MSE 0.01796584762632847\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.392480 KL: 0.502722 Neg-log -1.895201 MSE 0.014293674379587173\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 371\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.575079 KL: 0.502721 Neg-log -2.077800  [    0/30000]\n",
      "current batch loss: -0.473466 KL: 0.502667 Neg-log -0.976133  [12800/30000]\n",
      "current batch loss: -1.096735 KL: 0.502603 Neg-log -1.599338  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.157958 KL: 0.502593 Neg-log -1.660551 MSE 0.018570348620414734\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.180003 KL: 0.502593 Neg-log -1.682594 MSE 0.017426155507564545\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 372\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.431222 KL: 0.502592 Neg-log -1.933814  [    0/30000]\n",
      "current batch loss: -1.155296 KL: 0.502547 Neg-log -1.657842  [12800/30000]\n",
      "current batch loss: -1.342688 KL: 0.502485 Neg-log -1.845173  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.294555 KL: 0.502471 Neg-log -1.797025 MSE 0.015858305618166924\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.241311 KL: 0.502471 Neg-log -1.743782 MSE 0.017214229330420494\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 373\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.542171 KL: 0.502470 Neg-log -2.044641  [    0/30000]\n",
      "current batch loss: -0.794999 KL: 0.502412 Neg-log -1.297410  [12800/30000]\n",
      "current batch loss: -1.104108 KL: 0.502359 Neg-log -1.606467  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.440139 KL: 0.502342 Neg-log -1.942481 MSE 0.013514523394405842\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.407963 KL: 0.502342 Neg-log -1.910306 MSE 0.014264117926359177\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 374\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.395576 KL: 0.502343 Neg-log -1.897919  [    0/30000]\n",
      "current batch loss: -1.553219 KL: 0.502290 Neg-log -2.055509  [12800/30000]\n",
      "current batch loss: -1.449698 KL: 0.502245 Neg-log -1.951943  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.268662 KL: 0.502214 Neg-log -1.770877 MSE 0.018144717440009117\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.236661 KL: 0.502214 Neg-log -1.738876 MSE 0.01806757226586342\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 375\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.365611 KL: 0.502215 Neg-log -1.867826  [    0/30000]\n",
      "current batch loss: -1.212772 KL: 0.502156 Neg-log -1.714928  [12800/30000]\n",
      "current batch loss: -1.618253 KL: 0.502106 Neg-log -2.120358  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.256763 KL: 0.502098 Neg-log -1.758859 MSE 0.017677100375294685\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.242591 KL: 0.502098 Neg-log -1.744689 MSE 0.01811818964779377\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 376\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.183254 KL: 0.502096 Neg-log -1.685350  [    0/30000]\n",
      "current batch loss: -1.244616 KL: 0.502048 Neg-log -1.746663  [12800/30000]\n",
      "current batch loss: -0.743645 KL: 0.502004 Neg-log -1.245649  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.362938 KL: 0.501982 Neg-log -1.864918 MSE 0.014666623435914516\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.358197 KL: 0.501982 Neg-log -1.860178 MSE 0.01486658863723278\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 377\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.584817 KL: 0.501980 Neg-log -2.086797  [    0/30000]\n",
      "current batch loss: -1.519479 KL: 0.501915 Neg-log -2.021394  [12800/30000]\n",
      "current batch loss: -1.475742 KL: 0.501865 Neg-log -1.977607  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.303834 KL: 0.501846 Neg-log -1.805682 MSE 0.016952306032180786\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.234654 KL: 0.501846 Neg-log -1.736501 MSE 0.017358070239424706\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 378\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.743595 KL: 0.501847 Neg-log -1.245442  [    0/30000]\n",
      "current batch loss: -1.323653 KL: 0.501781 Neg-log -1.825434  [12800/30000]\n",
      "current batch loss: -1.078495 KL: 0.501711 Neg-log -1.580207  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.429923 KL: 0.501686 Neg-log -1.931609 MSE 0.013142905198037624\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -1.417918 KL: 0.501686 Neg-log -1.919604 MSE 0.01334479171782732\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 379\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.967975 KL: 0.501686 Neg-log -1.469661  [    0/30000]\n",
      "current batch loss: -1.621361 KL: 0.501640 Neg-log -2.123000  [12800/30000]\n",
      "current batch loss: -1.461735 KL: 0.501592 Neg-log -1.963327  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.099460 KL: 0.501572 Neg-log -1.601031 MSE 0.02163039892911911\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.040349 KL: 0.501572 Neg-log -1.541921 MSE 0.02361289970576763\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 380\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.889296 KL: 0.501571 Neg-log -1.390868  [    0/30000]\n",
      "current batch loss: -1.409611 KL: 0.501513 Neg-log -1.911124  [12800/30000]\n",
      "current batch loss: -1.511447 KL: 0.501435 Neg-log -2.012882  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.396092 KL: 0.501404 Neg-log -1.897497 MSE 0.013478563167154789\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.385993 KL: 0.501404 Neg-log -1.887398 MSE 0.015121486969292164\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 381\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.304489 KL: 0.501405 Neg-log -1.805894  [    0/30000]\n",
      "current batch loss: -1.404217 KL: 0.501351 Neg-log -1.905569  [12800/30000]\n",
      "current batch loss: 0.064853 KL: 0.501295 Neg-log -0.436442  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.327909 KL: 0.501268 Neg-log -1.829177 MSE 0.015811283141374588\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.329411 KL: 0.501268 Neg-log -1.830680 MSE 0.015436151064932346\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 382\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.457782 KL: 0.501269 Neg-log -1.959051  [    0/30000]\n",
      "current batch loss: -1.382911 KL: 0.501213 Neg-log -1.884124  [12800/30000]\n",
      "current batch loss: -1.477793 KL: 0.501168 Neg-log -1.978961  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.348564 KL: 0.501142 Neg-log -1.849705 MSE 0.07250706851482391\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.355216 KL: 0.501142 Neg-log -1.856356 MSE 0.015199912711977959\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 383\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.221423 KL: 0.501141 Neg-log -1.722564  [    0/30000]\n",
      "current batch loss: -1.492710 KL: 0.501078 Neg-log -1.993787  [12800/30000]\n",
      "current batch loss: -1.547191 KL: 0.501018 Neg-log -2.048209  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.412476 KL: 0.500990 Neg-log -1.913465 MSE 0.014208554290235043\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.390233 KL: 0.500990 Neg-log -1.891222 MSE 0.014701004140079021\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 384\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.302345 KL: 0.500990 Neg-log -1.803335  [    0/30000]\n",
      "current batch loss: -1.361580 KL: 0.500923 Neg-log -1.862503  [12800/30000]\n",
      "current batch loss: -1.311261 KL: 0.500864 Neg-log -1.812126  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.365708 KL: 0.500854 Neg-log -1.866562 MSE 0.015350401401519775\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.362482 KL: 0.500854 Neg-log -1.863335 MSE 0.016411984339356422\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 385\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.507171 KL: 0.500854 Neg-log -2.008025  [    0/30000]\n",
      "current batch loss: -1.390562 KL: 0.500770 Neg-log -1.891331  [12800/30000]\n",
      "current batch loss: -1.487864 KL: 0.500712 Neg-log -1.988576  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.072771 KL: 0.500687 Neg-log -1.573459 MSE 0.019827593117952347\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.031698 KL: 0.500687 Neg-log -1.532385 MSE 0.02147563174366951\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 386\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.472541 KL: 0.500688 Neg-log -1.973229  [    0/30000]\n",
      "current batch loss: -0.787450 KL: 0.500648 Neg-log -1.288098  [12800/30000]\n",
      "current batch loss: -1.536847 KL: 0.500584 Neg-log -2.037431  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.313093 KL: 0.500559 Neg-log -1.813653 MSE 0.016385871917009354\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.270189 KL: 0.500559 Neg-log -1.770749 MSE 0.020381292328238487\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 387\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.635782 KL: 0.500559 Neg-log -2.136342  [    0/30000]\n",
      "current batch loss: -0.580963 KL: 0.500520 Neg-log -1.081483  [12800/30000]\n",
      "current batch loss: -1.120564 KL: 0.500467 Neg-log -1.621031  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.372627 KL: 0.500456 Neg-log -1.873083 MSE 0.015314395539462566\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.414714 KL: 0.500456 Neg-log -1.915169 MSE 0.0138564333319664\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 388\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.535786 KL: 0.500455 Neg-log -2.036242  [    0/30000]\n",
      "current batch loss: -1.578264 KL: 0.500388 Neg-log -2.078652  [12800/30000]\n",
      "current batch loss: -1.517382 KL: 0.500327 Neg-log -2.017710  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.455408 KL: 0.500312 Neg-log -1.955720 MSE 0.01527035515755415\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.439655 KL: 0.500312 Neg-log -1.939968 MSE 0.012777767144143581\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 389\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.076024 KL: 0.500311 Neg-log -1.576335  [    0/30000]\n",
      "current batch loss: -1.565538 KL: 0.500277 Neg-log -2.065815  [12800/30000]\n",
      "current batch loss: -1.495448 KL: 0.500235 Neg-log -1.995683  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.445292 KL: 0.500220 Neg-log -1.945511 MSE 0.014896825887262821\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.408442 KL: 0.500220 Neg-log -1.908661 MSE 0.014856372028589249\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 390\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.415041 KL: 0.500219 Neg-log -1.915260  [    0/30000]\n",
      "current batch loss: -1.609858 KL: 0.500176 Neg-log -2.110034  [12800/30000]\n",
      "current batch loss: -1.125432 KL: 0.500131 Neg-log -1.625564  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.194456 KL: 0.500123 Neg-log -1.694580 MSE 0.01875794678926468\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.148760 KL: 0.500123 Neg-log -1.648884 MSE 0.020514151081442833\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 391\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.049809 KL: 0.500124 Neg-log -1.549933  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.220857 KL: 0.500078 Neg-log -1.720935  [12800/30000]\n",
      "current batch loss: -1.542731 KL: 0.500049 Neg-log -2.042779  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.408021 KL: 0.500030 Neg-log -1.908051 MSE 0.014566658064723015\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.291353 KL: 0.500030 Neg-log -1.791384 MSE 0.016336223110556602\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 392\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.625390 KL: 0.500030 Neg-log -2.125420  [    0/30000]\n",
      "current batch loss: -1.489186 KL: 0.499980 Neg-log -1.989166  [12800/30000]\n",
      "current batch loss: -1.579739 KL: 0.499943 Neg-log -2.079682  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.371868 KL: 0.499922 Neg-log -1.871789 MSE 0.01525917463004589\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.350753 KL: 0.499922 Neg-log -1.850674 MSE 0.015330544672906399\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 393\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.570667 KL: 0.499921 Neg-log -2.070587  [    0/30000]\n",
      "current batch loss: -1.468348 KL: 0.499873 Neg-log -1.968221  [12800/30000]\n",
      "current batch loss: -1.196159 KL: 0.499839 Neg-log -1.695998  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.420090 KL: 0.499815 Neg-log -1.919905 MSE 0.018194109201431274\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.417183 KL: 0.499815 Neg-log -1.916998 MSE 0.012588604353368282\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 394\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.385010 KL: 0.499814 Neg-log -1.884824  [    0/30000]\n",
      "current batch loss: -1.428106 KL: 0.499767 Neg-log -1.927872  [12800/30000]\n",
      "current batch loss: -0.848790 KL: 0.499724 Neg-log -1.348515  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.443205 KL: 0.499710 Neg-log -1.942915 MSE 0.01391187496483326\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.445222 KL: 0.499710 Neg-log -1.944931 MSE 0.013729056343436241\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 395\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.553139 KL: 0.499710 Neg-log -2.052849  [    0/30000]\n",
      "current batch loss: -1.266460 KL: 0.499660 Neg-log -1.766120  [12800/30000]\n",
      "current batch loss: -1.435524 KL: 0.499622 Neg-log -1.935146  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.338537 KL: 0.499603 Neg-log -1.838139 MSE 0.014143414795398712\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.329233 KL: 0.499603 Neg-log -1.828835 MSE 0.015286230482161045\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 396\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.534560 KL: 0.499602 Neg-log -2.034162  [    0/30000]\n",
      "current batch loss: 0.107967 KL: 0.499563 Neg-log -0.391597  [12800/30000]\n",
      "current batch loss: -1.307122 KL: 0.499505 Neg-log -1.806627  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.432785 KL: 0.499468 Neg-log -1.932254 MSE 0.013728161342442036\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.415039 KL: 0.499468 Neg-log -1.914508 MSE 0.01230024453252554\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 397\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.338299 KL: 0.499469 Neg-log -1.837768  [    0/30000]\n",
      "current batch loss: -1.579958 KL: 0.499436 Neg-log -2.079394  [12800/30000]\n",
      "current batch loss: -1.563588 KL: 0.499383 Neg-log -2.062971  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.413602 KL: 0.499374 Neg-log -1.912975 MSE 0.012140263803303242\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.421811 KL: 0.499374 Neg-log -1.921185 MSE 0.012570495717227459\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 398\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.465863 KL: 0.499373 Neg-log -1.965236  [    0/30000]\n",
      "current batch loss: -1.538965 KL: 0.499330 Neg-log -2.038295  [12800/30000]\n",
      "current batch loss: -1.486519 KL: 0.499308 Neg-log -1.985826  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.342254 KL: 0.499298 Neg-log -1.841553 MSE 0.019030561670660973\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.372452 KL: 0.499298 Neg-log -1.871752 MSE 0.013512165285646915\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 399\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.519280 KL: 0.499299 Neg-log -2.018579  [    0/30000]\n",
      "current batch loss: -1.542510 KL: 0.499259 Neg-log -2.041769  [12800/30000]\n",
      "current batch loss: -1.531135 KL: 0.499229 Neg-log -2.030364  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.300137 KL: 0.499208 Neg-log -1.799346 MSE 0.01727823168039322\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.275665 KL: 0.499208 Neg-log -1.774875 MSE 0.016090674325823784\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 400\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.533263 KL: 0.499209 Neg-log -2.032473  [    0/30000]\n",
      "current batch loss: -1.306187 KL: 0.499151 Neg-log -1.805338  [12800/30000]\n",
      "current batch loss: -1.450443 KL: 0.499111 Neg-log -1.949553  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.056938 KL: 0.499098 Neg-log -1.556034 MSE 0.01956905797123909\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.005636 KL: 0.499098 Neg-log -1.504732 MSE 0.020974263548851013\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 401\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.357025 KL: 0.499096 Neg-log -0.856121  [    0/30000]\n",
      "current batch loss: -1.199913 KL: 0.499059 Neg-log -1.698972  [12800/30000]\n",
      "current batch loss: -1.735414 KL: 0.499008 Neg-log -2.234421  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.255905 KL: 0.499003 Neg-log -1.754909 MSE 0.015675051137804985\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.235550 KL: 0.499003 Neg-log -1.734554 MSE 0.016366148367524147\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 402\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.430637 KL: 0.499004 Neg-log -1.929641  [    0/30000]\n",
      "current batch loss: -1.234944 KL: 0.498929 Neg-log -1.733873  [12800/30000]\n",
      "current batch loss: -1.234407 KL: 0.498845 Neg-log -1.733252  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.347582 KL: 0.498816 Neg-log -1.846397 MSE 0.018010759726166725\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.327827 KL: 0.498816 Neg-log -1.826643 MSE 0.01623864471912384\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 403\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.479295 KL: 0.498815 Neg-log -1.978110  [    0/30000]\n",
      "current batch loss: -1.322625 KL: 0.498745 Neg-log -1.821370  [12800/30000]\n",
      "current batch loss: -1.500730 KL: 0.498683 Neg-log -1.999413  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.409962 KL: 0.498659 Neg-log -1.908621 MSE 0.01442409586161375\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -1.409705 KL: 0.498659 Neg-log -1.908365 MSE 0.014293600805103779\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 404\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.409079 KL: 0.498660 Neg-log -1.907739  [    0/30000]\n",
      "current batch loss: -1.270326 KL: 0.498607 Neg-log -1.768933  [12800/30000]\n",
      "current batch loss: -1.541242 KL: 0.498569 Neg-log -2.039812  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.353204 KL: 0.498551 Neg-log -1.851756 MSE 0.01590263471007347\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.367010 KL: 0.498551 Neg-log -1.865562 MSE 0.01597503386437893\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 405\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.108135 KL: 0.498551 Neg-log -1.606686  [    0/30000]\n",
      "current batch loss: -1.440737 KL: 0.498491 Neg-log -1.939228  [12800/30000]\n",
      "current batch loss: -1.698797 KL: 0.498419 Neg-log -2.197216  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.259833 KL: 0.498398 Neg-log -1.758231 MSE 0.01615176349878311\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.197057 KL: 0.498398 Neg-log -1.695456 MSE 0.01769072934985161\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 406\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.438871 KL: 0.498398 Neg-log -1.937269  [    0/30000]\n",
      "current batch loss: -1.562595 KL: 0.498344 Neg-log -2.060939  [12800/30000]\n",
      "current batch loss: -1.372152 KL: 0.498278 Neg-log -1.870430  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.487206 KL: 0.498259 Neg-log -1.985464 MSE 0.01246834546327591\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.435333 KL: 0.498259 Neg-log -1.933591 MSE 0.01338102575391531\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 407\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.448978 KL: 0.498258 Neg-log -1.947236  [    0/30000]\n",
      "current batch loss: -1.631647 KL: 0.498187 Neg-log -2.129834  [12800/30000]\n",
      "current batch loss: -1.531937 KL: 0.498126 Neg-log -2.030063  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.387206 KL: 0.498100 Neg-log -1.885306 MSE 0.016173984855413437\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.382400 KL: 0.498100 Neg-log -1.880499 MSE 0.014846323058009148\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 408\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.594252 KL: 0.498099 Neg-log -2.092351  [    0/30000]\n",
      "current batch loss: -1.637463 KL: 0.498019 Neg-log -2.135482  [12800/30000]\n",
      "current batch loss: -1.560927 KL: 0.497935 Neg-log -2.058862  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.014088 KL: 0.497911 Neg-log -1.512001 MSE 0.02193855307996273\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.919428 KL: 0.497911 Neg-log -1.417341 MSE 0.022525541484355927\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 409\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.432953 KL: 0.497912 Neg-log -0.930865  [    0/30000]\n",
      "current batch loss: -1.558949 KL: 0.497861 Neg-log -2.056810  [12800/30000]\n",
      "current batch loss: -1.187369 KL: 0.497802 Neg-log -1.685171  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 111.709326 KL: 0.497786 Neg-log 111.211510 MSE 0.020744750276207924\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.266878 KL: 0.497786 Neg-log -1.764662 MSE 0.017413534224033356\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 410\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.071117 KL: 0.497784 Neg-log -1.568901  [    0/30000]\n",
      "current batch loss: -1.501769 KL: 0.497727 Neg-log -1.999496  [12800/30000]\n",
      "current batch loss: -1.418996 KL: 0.497663 Neg-log -1.916659  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.442202 KL: 0.497648 Neg-log -1.939849 MSE 0.01954754814505577\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.424441 KL: 0.497648 Neg-log -1.922088 MSE 0.013586821034550667\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 411\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.572093 KL: 0.497647 Neg-log -2.069740  [    0/30000]\n",
      "current batch loss: -1.648623 KL: 0.497585 Neg-log -2.146208  [12800/30000]\n",
      "current batch loss: -0.996131 KL: 0.497511 Neg-log -1.493642  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.283594 KL: 0.497483 Neg-log -1.781079 MSE 0.014374797232449055\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.279754 KL: 0.497483 Neg-log -1.777238 MSE 0.014867068268358707\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 412\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.335098 KL: 0.497484 Neg-log -1.832582  [    0/30000]\n",
      "current batch loss: -1.422723 KL: 0.497437 Neg-log -1.920161  [12800/30000]\n",
      "current batch loss: -1.542715 KL: 0.497372 Neg-log -2.040087  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.108884 KL: 0.497351 Neg-log -1.606234 MSE 0.01745513081550598\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.133581 KL: 0.497351 Neg-log -1.630930 MSE 0.01699952594935894\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 413\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.327367 KL: 0.497350 Neg-log -1.824717  [    0/30000]\n",
      "current batch loss: -1.396363 KL: 0.497303 Neg-log -1.893665  [12800/30000]\n",
      "current batch loss: -1.334464 KL: 0.497251 Neg-log -1.831715  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.385090 KL: 0.497239 Neg-log -1.882329 MSE 0.01413493137806654\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.397448 KL: 0.497239 Neg-log -1.894687 MSE 0.013764764182269573\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 414\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.612065 KL: 0.497239 Neg-log -2.109305  [    0/30000]\n",
      "current batch loss: -1.469996 KL: 0.497176 Neg-log -1.967172  [12800/30000]\n",
      "current batch loss: -1.213405 KL: 0.497093 Neg-log -1.710498  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.366441 KL: 0.497063 Neg-log -1.863504 MSE 0.015167930163443089\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.318282 KL: 0.497063 Neg-log -1.815345 MSE 0.017494255676865578\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 415\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.109912 KL: 0.497063 Neg-log -1.606975  [    0/30000]\n",
      "current batch loss: -1.449542 KL: 0.496998 Neg-log -1.946540  [12800/30000]\n",
      "current batch loss: -1.648350 KL: 0.496965 Neg-log -2.145316  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.091062 KL: 0.496948 Neg-log -1.588007 MSE 0.014724518172442913\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.306281 KL: 0.496948 Neg-log -1.803228 MSE 0.01500612124800682\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 416\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.358595 KL: 0.496946 Neg-log -1.855542  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.425601 KL: 0.496896 Neg-log -1.922497  [12800/30000]\n",
      "current batch loss: -1.586827 KL: 0.496831 Neg-log -2.083658  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.379234 KL: 0.496817 Neg-log -1.876049 MSE 0.015275626443326473\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.342987 KL: 0.496817 Neg-log -1.839803 MSE 0.014490311034023762\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 417\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.489745 KL: 0.496815 Neg-log -1.986560  [    0/30000]\n",
      "current batch loss: -1.485462 KL: 0.496759 Neg-log -1.982221  [12800/30000]\n",
      "current batch loss: -1.400742 KL: 0.496686 Neg-log -1.897429  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.340696 KL: 0.496656 Neg-log -1.837351 MSE 0.016219470649957657\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.294834 KL: 0.496656 Neg-log -1.791488 MSE 0.01812599040567875\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 418\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.346563 KL: 0.496655 Neg-log -1.843218  [    0/30000]\n",
      "current batch loss: -1.310670 KL: 0.496587 Neg-log -1.807257  [12800/30000]\n",
      "current batch loss: -1.342977 KL: 0.496524 Neg-log -1.839501  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.273393 KL: 0.496505 Neg-log -1.769897 MSE 0.01848350465297699\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.257980 KL: 0.496505 Neg-log -1.754484 MSE 0.017009321600198746\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 419\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.415403 KL: 0.496505 Neg-log -1.911908  [    0/30000]\n",
      "current batch loss: -1.593317 KL: 0.496447 Neg-log -2.089764  [12800/30000]\n",
      "current batch loss: -1.421558 KL: 0.496390 Neg-log -1.917948  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.474198 KL: 0.496370 Neg-log -1.970570 MSE 0.013894074596464634\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.468077 KL: 0.496370 Neg-log -1.964448 MSE 0.017760412767529488\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 420\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.516645 KL: 0.496372 Neg-log -2.013016  [    0/30000]\n",
      "current batch loss: -1.260986 KL: 0.496328 Neg-log -1.757314  [12800/30000]\n",
      "current batch loss: -1.568578 KL: 0.496281 Neg-log -2.064859  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.323016 KL: 0.496261 Neg-log -1.819276 MSE 0.01619393192231655\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.228634 KL: 0.496261 Neg-log -1.724894 MSE 0.018978770822286606\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 421\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.604475 KL: 0.496260 Neg-log -2.100735  [    0/30000]\n",
      "current batch loss: -1.251989 KL: 0.496227 Neg-log -1.748216  [12800/30000]\n",
      "current batch loss: -1.609989 KL: 0.496163 Neg-log -2.106152  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.507582 KL: 0.496145 Neg-log -2.003725 MSE 0.012200835160911083\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.495069 KL: 0.496145 Neg-log -1.991213 MSE 0.012953737750649452\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 422\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.548448 KL: 0.496144 Neg-log -2.044593  [    0/30000]\n",
      "current batch loss: -1.158758 KL: 0.496105 Neg-log -1.654863  [12800/30000]\n",
      "current batch loss: -1.610221 KL: 0.496068 Neg-log -2.106289  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.931334 KL: 0.496054 Neg-log -1.427386 MSE 0.024698449298739433\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.916260 KL: 0.496054 Neg-log -1.412312 MSE 0.026202041655778885\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 423\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.113923 KL: 0.496052 Neg-log -1.609975  [    0/30000]\n",
      "current batch loss: -1.631712 KL: 0.496008 Neg-log -2.127720  [12800/30000]\n",
      "current batch loss: -1.607105 KL: 0.495954 Neg-log -2.103059  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.489318 KL: 0.495943 Neg-log -1.985262 MSE 0.011380370706319809\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.472630 KL: 0.495943 Neg-log -1.968574 MSE 0.01239789929240942\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 424\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.258762 KL: 0.495944 Neg-log -1.754706  [    0/30000]\n",
      "current batch loss: -1.417578 KL: 0.495911 Neg-log -1.913488  [12800/30000]\n",
      "current batch loss: -1.461198 KL: 0.495873 Neg-log -1.957071  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.126559 KL: 0.495859 Neg-log -1.622419 MSE 0.0190059095621109\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.114998 KL: 0.495859 Neg-log -1.610857 MSE 0.018811136484146118\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 425\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.452305 KL: 0.495859 Neg-log -0.948164  [    0/30000]\n",
      "current batch loss: 0.150956 KL: 0.495828 Neg-log -0.344871  [12800/30000]\n",
      "current batch loss: -0.994571 KL: 0.495733 Neg-log -1.490304  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.059204 KL: 0.495697 Neg-log -1.554901 MSE 0.03126192092895508\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.053523 KL: 0.495697 Neg-log -1.549219 MSE 0.030400574207305908\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 426\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.116484 KL: 0.495697 Neg-log -1.612181  [    0/30000]\n",
      "current batch loss: -1.362282 KL: 0.495602 Neg-log -1.857885  [12800/30000]\n",
      "current batch loss: -1.201982 KL: 0.495525 Neg-log -1.697507  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.285231 KL: 0.495506 Neg-log -1.780737 MSE 0.020532380789518356\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.273424 KL: 0.495506 Neg-log -1.768930 MSE 0.02065849117934704\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 427\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.371190 KL: 0.495506 Neg-log -1.866697  [    0/30000]\n",
      "current batch loss: -1.385680 KL: 0.495447 Neg-log -1.881127  [12800/30000]\n",
      "current batch loss: -0.918983 KL: 0.495383 Neg-log -1.414365  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.346861 KL: 0.495360 Neg-log -1.842220 MSE 0.01730283908545971\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.350443 KL: 0.495360 Neg-log -1.845802 MSE 0.01755414716899395\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 428\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.443161 KL: 0.495359 Neg-log -1.938520  [    0/30000]\n",
      "current batch loss: -1.424075 KL: 0.495310 Neg-log -1.919384  [12800/30000]\n",
      "current batch loss: -1.307880 KL: 0.495273 Neg-log -1.803153  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.354005 KL: 0.495254 Neg-log -1.849257 MSE 0.016612865030765533\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -1.320895 KL: 0.495254 Neg-log -1.816148 MSE 0.016573108732700348\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 429\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.455967 KL: 0.495253 Neg-log -1.951220  [    0/30000]\n",
      "current batch loss: -1.475087 KL: 0.495208 Neg-log -1.970295  [12800/30000]\n",
      "current batch loss: -1.487845 KL: 0.495162 Neg-log -1.983007  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.311169 KL: 0.495149 Neg-log -1.806319 MSE 0.02545139566063881\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.280259 KL: 0.495149 Neg-log -1.775408 MSE 0.018076151609420776\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 430\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.356558 KL: 0.495150 Neg-log -1.851708  [    0/30000]\n",
      "current batch loss: -1.518142 KL: 0.495104 Neg-log -2.013245  [12800/30000]\n",
      "current batch loss: -1.491706 KL: 0.495067 Neg-log -1.986773  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.511578 KL: 0.495056 Neg-log -1.006633 MSE 0.030973557382822037\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.429227 KL: 0.495056 Neg-log -0.924282 MSE 0.03307504206895828\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 431\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.020479 KL: 0.495055 Neg-log -1.515534  [    0/30000]\n",
      "current batch loss: -1.494699 KL: 0.495013 Neg-log -1.989712  [12800/30000]\n",
      "current batch loss: -1.512446 KL: 0.494958 Neg-log -2.007404  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.352292 KL: 0.494942 Neg-log -1.847234 MSE 0.01619993895292282\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.343650 KL: 0.494942 Neg-log -1.838593 MSE 0.017361342906951904\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 432\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.207160 KL: 0.494942 Neg-log -1.702102  [    0/30000]\n",
      "current batch loss: -1.482535 KL: 0.494895 Neg-log -1.977430  [12800/30000]\n",
      "current batch loss: -1.453644 KL: 0.494843 Neg-log -1.948487  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.429521 KL: 0.494821 Neg-log -1.924343 MSE 0.01368914358317852\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.411272 KL: 0.494821 Neg-log -1.906094 MSE 0.015077254734933376\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 433\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.489565 KL: 0.494822 Neg-log -1.984387  [    0/30000]\n",
      "current batch loss: -1.617008 KL: 0.494751 Neg-log -2.111759  [12800/30000]\n",
      "current batch loss: -1.666050 KL: 0.494695 Neg-log -2.160745  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.453472 KL: 0.494677 Neg-log -1.948150 MSE 0.014337907545268536\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.433236 KL: 0.494677 Neg-log -1.927914 MSE 0.014606134034693241\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 434\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.563883 KL: 0.494678 Neg-log -2.058561  [    0/30000]\n",
      "current batch loss: -1.500243 KL: 0.494616 Neg-log -1.994859  [12800/30000]\n",
      "current batch loss: -1.173989 KL: 0.494561 Neg-log -1.668550  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.466994 KL: 0.494551 Neg-log -1.961543 MSE 0.013276664540171623\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.433263 KL: 0.494551 Neg-log -1.927812 MSE 0.014156387187540531\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 435\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.304840 KL: 0.494550 Neg-log -1.799390  [    0/30000]\n",
      "current batch loss: -1.423748 KL: 0.494507 Neg-log -1.918255  [12800/30000]\n",
      "current batch loss: -1.413736 KL: 0.494464 Neg-log -1.908199  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.472076 KL: 0.494438 Neg-log -1.966514 MSE 0.013804684393107891\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.467545 KL: 0.494438 Neg-log -1.961982 MSE 0.013936822302639484\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 436\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.547558 KL: 0.494438 Neg-log -2.041996  [    0/30000]\n",
      "current batch loss: -1.554075 KL: 0.494383 Neg-log -2.048458  [12800/30000]\n",
      "current batch loss: -1.450375 KL: 0.494347 Neg-log -1.944722  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.468679 KL: 0.494324 Neg-log -1.963003 MSE 0.013712773099541664\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.445160 KL: 0.494324 Neg-log -1.939484 MSE 0.014140704646706581\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 437\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.574761 KL: 0.494324 Neg-log -2.069085  [    0/30000]\n",
      "current batch loss: -1.435930 KL: 0.494264 Neg-log -1.930194  [12800/30000]\n",
      "current batch loss: -1.599430 KL: 0.494205 Neg-log -2.093635  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.404964 KL: 0.494196 Neg-log -1.899160 MSE 0.016231462359428406\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.371173 KL: 0.494196 Neg-log -1.865369 MSE 0.01560601219534874\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 438\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.404974 KL: 0.494196 Neg-log -1.899171  [    0/30000]\n",
      "current batch loss: -1.328530 KL: 0.494148 Neg-log -1.822678  [12800/30000]\n",
      "current batch loss: -1.636130 KL: 0.494102 Neg-log -2.130231  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.506358 KL: 0.494086 Neg-log -2.000443 MSE 0.017464829608798027\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.489292 KL: 0.494086 Neg-log -1.983378 MSE 0.013694521971046925\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 439\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.602059 KL: 0.494085 Neg-log -2.096144  [    0/30000]\n",
      "current batch loss: -1.554259 KL: 0.494056 Neg-log -2.048315  [12800/30000]\n",
      "current batch loss: -1.366714 KL: 0.494018 Neg-log -1.860732  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.097961 KL: 0.494003 Neg-log -1.591963 MSE 0.02379082888364792\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.092851 KL: 0.494003 Neg-log -1.586853 MSE 0.020144283771514893\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 440\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.364855 KL: 0.494002 Neg-log -1.858857  [    0/30000]\n",
      "current batch loss: -1.548832 KL: 0.493949 Neg-log -2.042780  [12800/30000]\n",
      "current batch loss: -1.526704 KL: 0.493905 Neg-log -2.020609  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.535303 KL: 0.493889 Neg-log -2.029193 MSE 0.011786717921495438\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.503925 KL: 0.493889 Neg-log -1.997815 MSE 0.012884913943707943\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 441\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.709069 KL: 0.493890 Neg-log -2.202958  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.375730 KL: 0.493862 Neg-log -1.869592  [12800/30000]\n",
      "current batch loss: -1.521487 KL: 0.493821 Neg-log -2.015308  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.374557 KL: 0.493803 Neg-log -1.868358 MSE 0.01393524743616581\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.369737 KL: 0.493803 Neg-log -1.863538 MSE 0.014316430315375328\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 442\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.411087 KL: 0.493801 Neg-log -1.904888  [    0/30000]\n",
      "current batch loss: -1.617835 KL: 0.493756 Neg-log -2.111591  [12800/30000]\n",
      "current batch loss: -1.585315 KL: 0.493705 Neg-log -2.079021  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.177466 KL: 0.493691 Neg-log -1.671158 MSE 0.020360451191663742\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.189101 KL: 0.493691 Neg-log -1.682793 MSE 0.020121490582823753\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 443\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.340113 KL: 0.493691 Neg-log -1.833805  [    0/30000]\n",
      "current batch loss: -1.520118 KL: 0.493664 Neg-log -2.013782  [12800/30000]\n",
      "current batch loss: -1.630124 KL: 0.493639 Neg-log -2.123762  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.272612 KL: 0.493624 Neg-log -1.766238 MSE 0.027474576607346535\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.296105 KL: 0.493624 Neg-log -1.789731 MSE 0.016118206083774567\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 444\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.572355 KL: 0.493625 Neg-log -2.065980  [    0/30000]\n",
      "current batch loss: -1.468437 KL: 0.493583 Neg-log -1.962020  [12800/30000]\n",
      "current batch loss: -1.726749 KL: 0.493555 Neg-log -2.220304  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.512375 KL: 0.493544 Neg-log -2.005917 MSE 0.016886353492736816\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.472572 KL: 0.493544 Neg-log -1.966114 MSE 0.013477067463099957\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 445\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.506711 KL: 0.493542 Neg-log -2.000254  [    0/30000]\n",
      "current batch loss: -1.479809 KL: 0.493496 Neg-log -1.973305  [12800/30000]\n",
      "current batch loss: -1.513272 KL: 0.493455 Neg-log -2.006727  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.512416 KL: 0.493452 Neg-log -2.005867 MSE 0.012306597083806992\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.468519 KL: 0.493452 Neg-log -1.961969 MSE 0.014806474559009075\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 446\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.386513 KL: 0.493450 Neg-log -1.879964  [    0/30000]\n",
      "current batch loss: -1.496357 KL: 0.493419 Neg-log -1.989777  [12800/30000]\n",
      "current batch loss: -1.732425 KL: 0.493392 Neg-log -2.225816  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.481856 KL: 0.493379 Neg-log -1.975237 MSE 0.01365797407925129\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.491323 KL: 0.493379 Neg-log -1.984704 MSE 0.01379489991813898\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 447\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.490728 KL: 0.493380 Neg-log -1.984108  [    0/30000]\n",
      "current batch loss: -0.995247 KL: 0.493344 Neg-log -1.488591  [12800/30000]\n",
      "current batch loss: -1.678969 KL: 0.493303 Neg-log -2.172272  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.497164 KL: 0.493294 Neg-log -1.990458 MSE 0.01353685837239027\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.465201 KL: 0.493294 Neg-log -1.958495 MSE 0.013278705067932606\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 448\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.448739 KL: 0.493294 Neg-log -1.942033  [    0/30000]\n",
      "current batch loss: -1.083285 KL: 0.493252 Neg-log -1.576536  [12800/30000]\n",
      "current batch loss: -1.579320 KL: 0.493201 Neg-log -2.072521  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.387074 KL: 0.493187 Neg-log -1.880261 MSE 0.01616390235722065\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.390861 KL: 0.493187 Neg-log -1.884047 MSE 0.015950564295053482\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 449\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.253412 KL: 0.493186 Neg-log -1.746598  [    0/30000]\n",
      "current batch loss: 1.383055 KL: 0.493141 Neg-log 0.889915  [12800/30000]\n",
      "current batch loss: -1.606232 KL: 0.493101 Neg-log -2.099333  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.516391 KL: 0.493095 Neg-log -2.009485 MSE 0.012581354938447475\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.473085 KL: 0.493095 Neg-log -1.966179 MSE 0.013190985657274723\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 450\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.668398 KL: 0.493094 Neg-log -2.161492  [    0/30000]\n",
      "current batch loss: -1.675041 KL: 0.493059 Neg-log -2.168100  [12800/30000]\n",
      "current batch loss: -1.671922 KL: 0.493018 Neg-log -2.164941  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.522248 KL: 0.493006 Neg-log -2.015256 MSE 0.01852162927389145\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.486962 KL: 0.493006 Neg-log -1.979969 MSE 0.013789240270853043\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 451\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.742596 KL: 0.493007 Neg-log -2.235603  [    0/30000]\n",
      "current batch loss: -1.668889 KL: 0.492974 Neg-log -2.161864  [12800/30000]\n",
      "current batch loss: -1.602746 KL: 0.492915 Neg-log -2.095661  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.970801 KL: 0.492905 Neg-log -1.463705 MSE 0.01933690346777439\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.934894 KL: 0.492905 Neg-log -1.427799 MSE 0.020968342199921608\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 452\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.760389 KL: 0.492904 Neg-log -1.253294  [    0/30000]\n",
      "current batch loss: -1.369939 KL: 0.492867 Neg-log -1.862806  [12800/30000]\n",
      "current batch loss: -1.730908 KL: 0.492825 Neg-log -2.223733  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.940118 KL: 0.492814 Neg-log -1.432932 MSE 0.03435130789875984\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.903898 KL: 0.492814 Neg-log -1.396713 MSE 0.034280721098184586\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 453\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.961824 KL: 0.492814 Neg-log -1.454638  [    0/30000]\n",
      "current batch loss: -1.047198 KL: 0.492753 Neg-log -1.539951  [12800/30000]\n",
      "current batch loss: -1.182662 KL: 0.492697 Neg-log -1.675358  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.008095 KL: 0.492684 Neg-log -1.500780 MSE 0.023334844037890434\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -0.984696 KL: 0.492684 Neg-log -1.477381 MSE 0.024249326437711716\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 454\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.319692 KL: 0.492685 Neg-log -1.812377  [    0/30000]\n",
      "current batch loss: -1.649003 KL: 0.492647 Neg-log -2.141650  [12800/30000]\n",
      "current batch loss: -1.541765 KL: 0.492607 Neg-log -2.034372  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 44.445965 KL: 0.492594 Neg-log 43.953369 MSE 0.02166394144296646\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.392569 KL: 0.492594 Neg-log -1.885164 MSE 0.014212235808372498\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 455\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.189358 KL: 0.492595 Neg-log -1.681953  [    0/30000]\n",
      "current batch loss: -1.514494 KL: 0.492558 Neg-log -2.007052  [12800/30000]\n",
      "current batch loss: -1.260586 KL: 0.492506 Neg-log -1.753092  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.498468 KL: 0.492494 Neg-log -1.990963 MSE 0.013570343144237995\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.491323 KL: 0.492494 Neg-log -1.983818 MSE 0.012807482853531837\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 456\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.687613 KL: 0.492495 Neg-log -2.180108  [    0/30000]\n",
      "current batch loss: -1.696752 KL: 0.492455 Neg-log -2.189208  [12800/30000]\n",
      "current batch loss: -1.630569 KL: 0.492404 Neg-log -2.122973  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.558949 KL: 0.492387 Neg-log -2.051337 MSE 0.011554297059774399\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.532477 KL: 0.492387 Neg-log -2.024866 MSE 0.011984527111053467\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 457\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.529994 KL: 0.492388 Neg-log -2.022382  [    0/30000]\n",
      "current batch loss: -1.447649 KL: 0.492329 Neg-log -1.939979  [12800/30000]\n",
      "current batch loss: -1.483885 KL: 0.492279 Neg-log -1.976164  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.480387 KL: 0.492265 Neg-log -1.972653 MSE 0.017971599474549294\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.436770 KL: 0.492265 Neg-log -1.929036 MSE 0.013899147510528564\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 458\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.014316 KL: 0.492266 Neg-log -1.506582  [    0/30000]\n",
      "current batch loss: -1.584435 KL: 0.492225 Neg-log -2.076660  [12800/30000]\n",
      "current batch loss: -1.603000 KL: 0.492192 Neg-log -2.095192  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.517611 KL: 0.492179 Neg-log -2.009791 MSE 0.012162256054580212\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.520041 KL: 0.492179 Neg-log -2.012221 MSE 0.011789735406637192\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 459\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.667798 KL: 0.492179 Neg-log -2.159976  [    0/30000]\n",
      "current batch loss: -1.235321 KL: 0.492138 Neg-log -1.727458  [12800/30000]\n",
      "current batch loss: -1.445977 KL: 0.492086 Neg-log -1.938063  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.572500 KL: 0.492067 Neg-log -2.064569 MSE 0.011858966201543808\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.567419 KL: 0.492067 Neg-log -2.059487 MSE 0.011669659987092018\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 460\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.397168 KL: 0.492068 Neg-log -1.889236  [    0/30000]\n",
      "current batch loss: -1.400673 KL: 0.492041 Neg-log -1.892715  [12800/30000]\n",
      "current batch loss: 0.105223 KL: 0.491979 Neg-log -0.386756  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.513894 KL: 0.491965 Neg-log -2.005857 MSE 0.011188601143658161\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.473050 KL: 0.491965 Neg-log -1.965014 MSE 0.01273427065461874\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 461\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.320623 KL: 0.491963 Neg-log -1.812587  [    0/30000]\n",
      "current batch loss: -1.578323 KL: 0.491913 Neg-log -2.070236  [12800/30000]\n",
      "current batch loss: -1.540024 KL: 0.491858 Neg-log -2.031883  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.564374 KL: 0.491835 Neg-log -2.056207 MSE 0.011915784329175949\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.553077 KL: 0.491835 Neg-log -2.044911 MSE 0.011364322155714035\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 462\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.472724 KL: 0.491834 Neg-log -1.964558  [    0/30000]\n",
      "current batch loss: -1.712605 KL: 0.491791 Neg-log -2.204396  [12800/30000]\n",
      "current batch loss: -1.788838 KL: 0.491744 Neg-log -2.280581  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 1779026.219721 KL: 0.491723 Neg-log 1779026.875000 MSE 0.02316509187221527\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.165024 KL: 0.491723 Neg-log -1.656748 MSE 0.016552338376641273\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 463\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.073455 KL: 0.491723 Neg-log -1.565178  [    0/30000]\n",
      "current batch loss: -1.164589 KL: 0.491672 Neg-log -1.656261  [12800/30000]\n",
      "current batch loss: -1.287308 KL: 0.491605 Neg-log -1.778913  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.486356 KL: 0.491592 Neg-log -1.977947 MSE 0.01100765448063612\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.562930 KL: 0.491592 Neg-log -2.054521 MSE 0.011153791099786758\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 464\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.611176 KL: 0.491591 Neg-log -2.102767  [    0/30000]\n",
      "current batch loss: -1.543941 KL: 0.491538 Neg-log -2.035479  [12800/30000]\n",
      "current batch loss: -1.416952 KL: 0.491501 Neg-log -1.908454  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.485784 KL: 0.491485 Neg-log -1.977269 MSE 0.01229719165712595\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.451773 KL: 0.491485 Neg-log -1.943258 MSE 0.013525904156267643\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 465\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.726561 KL: 0.491484 Neg-log -2.218045  [    0/30000]\n",
      "current batch loss: -1.714481 KL: 0.491429 Neg-log -2.205910  [12800/30000]\n",
      "current batch loss: -1.569775 KL: 0.491369 Neg-log -2.061145  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.495420 KL: 0.491341 Neg-log -1.986762 MSE 0.0252437274903059\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.450442 KL: 0.491341 Neg-log -1.941785 MSE 0.013719026930630207\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 466\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.588839 KL: 0.491342 Neg-log -2.080181  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.602720 KL: 0.491285 Neg-log -2.094006  [12800/30000]\n",
      "current batch loss: -1.575950 KL: 0.491234 Neg-log -2.067184  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.390861 KL: 0.491228 Neg-log -1.882090 MSE 0.017131267115473747\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.403046 KL: 0.491228 Neg-log -1.894274 MSE 0.01209856104105711\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 467\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.551156 KL: 0.491229 Neg-log -2.042384  [    0/30000]\n",
      "current batch loss: -1.652216 KL: 0.491193 Neg-log -2.143409  [12800/30000]\n",
      "current batch loss: -1.340402 KL: 0.491153 Neg-log -1.831555  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.609751 KL: 0.491142 Neg-log -2.100895 MSE 0.009647677652537823\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.579773 KL: 0.491142 Neg-log -2.070915 MSE 0.010718341916799545\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 468\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.623017 KL: 0.491143 Neg-log -2.114160  [    0/30000]\n",
      "current batch loss: -0.848297 KL: 0.491075 Neg-log -1.339371  [12800/30000]\n",
      "current batch loss: -1.572141 KL: 0.491001 Neg-log -2.063142  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.555636 KL: 0.490982 Neg-log -2.046618 MSE 0.012912466190755367\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.499445 KL: 0.490982 Neg-log -1.990426 MSE 0.012178284116089344\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 469\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.606553 KL: 0.490982 Neg-log -2.097534  [    0/30000]\n",
      "current batch loss: -1.401046 KL: 0.490919 Neg-log -1.891965  [12800/30000]\n",
      "current batch loss: -1.100160 KL: 0.490852 Neg-log -1.591012  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.565428 KL: 0.490831 Neg-log -2.056260 MSE 0.011586489155888557\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.549548 KL: 0.490831 Neg-log -2.040380 MSE 0.011060054413974285\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 470\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.357044 KL: 0.490832 Neg-log -1.847876  [    0/30000]\n",
      "current batch loss: -1.772085 KL: 0.490782 Neg-log -2.262866  [12800/30000]\n",
      "current batch loss: -1.674148 KL: 0.490734 Neg-log -2.164881  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.509207 KL: 0.490723 Neg-log -1.999930 MSE 0.01229926384985447\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.482315 KL: 0.490723 Neg-log -1.973040 MSE 0.012403980828821659\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 471\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.532877 KL: 0.490724 Neg-log -2.023601  [    0/30000]\n",
      "current batch loss: -1.700432 KL: 0.490675 Neg-log -2.191107  [12800/30000]\n",
      "current batch loss: -1.686193 KL: 0.490645 Neg-log -2.176838  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.559696 KL: 0.490626 Neg-log -2.050323 MSE 0.012107345275580883\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.516264 KL: 0.490626 Neg-log -2.006891 MSE 0.011320068500936031\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 472\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.358989 KL: 0.490627 Neg-log -1.849616  [    0/30000]\n",
      "current batch loss: -1.400127 KL: 0.490570 Neg-log -1.890696  [12800/30000]\n",
      "current batch loss: -1.276134 KL: 0.490503 Neg-log -1.766638  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.316941 KL: 0.490485 Neg-log -1.807424 MSE 0.017033616080880165\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.272394 KL: 0.490485 Neg-log -1.762878 MSE 0.018866298720240593\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 473\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.254147 KL: 0.490484 Neg-log -1.744631  [    0/30000]\n",
      "current batch loss: -1.653142 KL: 0.490442 Neg-log -2.143584  [12800/30000]\n",
      "current batch loss: -1.594499 KL: 0.490389 Neg-log -2.084888  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: 2398.456722 KL: 0.490372 Neg-log 2397.966553 MSE 0.02336641401052475\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.574612 KL: 0.490372 Neg-log -2.064984 MSE 0.012027513235807419\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 474\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.318099 KL: 0.490372 Neg-log -1.808471  [    0/30000]\n",
      "current batch loss: -1.576418 KL: 0.490334 Neg-log -2.066752  [12800/30000]\n",
      "current batch loss: -0.839042 KL: 0.490292 Neg-log -1.329334  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.492501 KL: 0.490278 Neg-log -1.982778 MSE 0.011636167764663696\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.468648 KL: 0.490278 Neg-log -1.958925 MSE 0.012287262827157974\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 475\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.535545 KL: 0.490277 Neg-log -2.025822  [    0/30000]\n",
      "current batch loss: -1.669931 KL: 0.490228 Neg-log -2.160159  [12800/30000]\n",
      "current batch loss: -1.027247 KL: 0.490191 Neg-log -1.517437  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.590510 KL: 0.490172 Neg-log -2.080681 MSE 0.011079303920269012\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.554043 KL: 0.490172 Neg-log -2.044213 MSE 0.012024429626762867\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 476\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.483132 KL: 0.490171 Neg-log -1.973303  [    0/30000]\n",
      "current batch loss: -1.536585 KL: 0.490132 Neg-log -2.026716  [12800/30000]\n",
      "current batch loss: -1.759703 KL: 0.490078 Neg-log -2.249781  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.528491 KL: 0.490064 Neg-log -2.018554 MSE 0.011223132722079754\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.488411 KL: 0.490064 Neg-log -1.978474 MSE 0.015083812177181244\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 477\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.299114 KL: 0.490063 Neg-log -1.789177  [    0/30000]\n",
      "current batch loss: -1.322690 KL: 0.490019 Neg-log -1.812709  [12800/30000]\n",
      "current batch loss: -1.371486 KL: 0.489980 Neg-log -1.861466  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.558027 KL: 0.489961 Neg-log -2.047989 MSE 0.01009468175470829\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.548793 KL: 0.489961 Neg-log -2.038755 MSE 0.0116086071357131\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 478\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.650261 KL: 0.489962 Neg-log -2.140224  [    0/30000]\n",
      "current batch loss: -1.545408 KL: 0.489910 Neg-log -2.035318  [12800/30000]\n",
      "current batch loss: -1.575273 KL: 0.489848 Neg-log -2.065121  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.269540 KL: 0.489832 Neg-log -1.759374 MSE 0.021300753578543663\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg val loss per batch: -1.246242 KL: 0.489832 Neg-log -1.736075 MSE 0.019627492874860764\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 479\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.535466 KL: 0.489833 Neg-log -2.025300  [    0/30000]\n",
      "current batch loss: -1.624709 KL: 0.489791 Neg-log -2.114501  [12800/30000]\n",
      "current batch loss: -1.714061 KL: 0.489754 Neg-log -2.203814  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.622253 KL: 0.489740 Neg-log -2.111994 MSE 0.010529393330216408\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.599929 KL: 0.489740 Neg-log -2.089670 MSE 0.011033719405531883\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 480\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.617190 KL: 0.489741 Neg-log -2.106931  [    0/30000]\n",
      "current batch loss: -1.470967 KL: 0.489707 Neg-log -1.960674  [12800/30000]\n",
      "current batch loss: -1.748920 KL: 0.489663 Neg-log -2.238583  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -0.981253 KL: 0.489646 Neg-log -1.470899 MSE 0.0248783640563488\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.018310 KL: 0.489646 Neg-log -1.507956 MSE 0.02200491726398468\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 481\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.875274 KL: 0.489646 Neg-log -1.364920  [    0/30000]\n",
      "current batch loss: -1.697810 KL: 0.489599 Neg-log -2.187409  [12800/30000]\n",
      "current batch loss: -1.697784 KL: 0.489565 Neg-log -2.187349  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.620191 KL: 0.489546 Neg-log -2.109736 MSE 0.011164993047714233\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.592360 KL: 0.489546 Neg-log -2.081905 MSE 0.011068289168179035\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 482\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.656576 KL: 0.489545 Neg-log -2.146121  [    0/30000]\n",
      "current batch loss: -1.377184 KL: 0.489519 Neg-log -1.866703  [12800/30000]\n",
      "current batch loss: -1.583442 KL: 0.489473 Neg-log -2.072916  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.579391 KL: 0.489464 Neg-log -2.068856 MSE 0.014275004155933857\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.531259 KL: 0.489464 Neg-log -2.020724 MSE 0.013124898076057434\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 483\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.754587 KL: 0.489465 Neg-log -2.244052  [    0/30000]\n",
      "current batch loss: -0.938304 KL: 0.489441 Neg-log -1.427745  [12800/30000]\n",
      "current batch loss: -1.697520 KL: 0.489396 Neg-log -2.186916  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.639422 KL: 0.489387 Neg-log -2.128808 MSE 0.011103548109531403\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.622839 KL: 0.489387 Neg-log -2.112226 MSE 0.01026178989559412\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 484\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.688057 KL: 0.489386 Neg-log -2.177444  [    0/30000]\n",
      "current batch loss: -1.100312 KL: 0.489350 Neg-log -1.589663  [12800/30000]\n",
      "current batch loss: -1.598150 KL: 0.489310 Neg-log -2.087459  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.164518 KL: 0.489296 Neg-log -1.653814 MSE 0.015178722329437733\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.118863 KL: 0.489296 Neg-log -1.608160 MSE 0.017207320779561996\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 485\n",
      "-----------------------------------------------\n",
      "current batch loss: -0.856336 KL: 0.489297 Neg-log -1.345634  [    0/30000]\n",
      "current batch loss: -1.587177 KL: 0.489254 Neg-log -2.076431  [12800/30000]\n",
      "current batch loss: -1.391098 KL: 0.489233 Neg-log -1.880331  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.093645 KL: 0.489212 Neg-log -1.582857 MSE 0.019099388271570206\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.074294 KL: 0.489212 Neg-log -1.563506 MSE 0.019591737538576126\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 486\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.146554 KL: 0.489212 Neg-log -1.635766  [    0/30000]\n",
      "current batch loss: -1.546238 KL: 0.489178 Neg-log -2.035416  [12800/30000]\n",
      "current batch loss: -1.713303 KL: 0.489140 Neg-log -2.202443  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.634947 KL: 0.489135 Neg-log -2.124081 MSE 0.011824632994830608\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.611946 KL: 0.489135 Neg-log -2.101081 MSE 0.010439037345349789\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 487\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.774767 KL: 0.489134 Neg-log -2.263902  [    0/30000]\n",
      "current batch loss: -1.278780 KL: 0.489103 Neg-log -1.767882  [12800/30000]\n",
      "current batch loss: -1.585738 KL: 0.489075 Neg-log -2.074813  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.658490 KL: 0.489074 Neg-log -2.147564 MSE 0.011455404572188854\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.646490 KL: 0.489074 Neg-log -2.135563 MSE 0.009582102298736572\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 488\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.742277 KL: 0.489073 Neg-log -2.231351  [    0/30000]\n",
      "current batch loss: -1.664595 KL: 0.489060 Neg-log -2.153655  [12800/30000]\n",
      "current batch loss: -1.711130 KL: 0.489035 Neg-log -2.200165  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.535669 KL: 0.489022 Neg-log -2.024691 MSE 0.014149886555969715\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.568500 KL: 0.489022 Neg-log -2.057523 MSE 0.013635244220495224\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 489\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.685045 KL: 0.489022 Neg-log -2.174067  [    0/30000]\n",
      "current batch loss: -1.647557 KL: 0.488992 Neg-log -2.136549  [12800/30000]\n",
      "current batch loss: -1.733268 KL: 0.488967 Neg-log -2.222236  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.530495 KL: 0.488968 Neg-log -2.019462 MSE 0.014234019443392754\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.540092 KL: 0.488968 Neg-log -2.029060 MSE 0.01175965927541256\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 490\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.623749 KL: 0.488967 Neg-log -2.112716  [    0/30000]\n",
      "current batch loss: -1.721064 KL: 0.488963 Neg-log -2.210027  [12800/30000]\n",
      "current batch loss: -1.619232 KL: 0.488960 Neg-log -2.108192  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.669334 KL: 0.488961 Neg-log -2.158295 MSE 0.010897893458604813\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.641602 KL: 0.488961 Neg-log -2.130563 MSE 0.009983289055526257\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 491\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.675480 KL: 0.488961 Neg-log -2.164441  [    0/30000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current batch loss: -1.666992 KL: 0.488952 Neg-log -2.155944  [12800/30000]\n",
      "current batch loss: -1.732500 KL: 0.488951 Neg-log -2.221451  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.013248 KL: 0.488947 Neg-log -1.502197 MSE 0.021591050550341606\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -0.989703 KL: 0.488947 Neg-log -1.478651 MSE 0.02194080874323845\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 492\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.595816 KL: 0.488948 Neg-log -2.084765  [    0/30000]\n",
      "current batch loss: -1.464908 KL: 0.488921 Neg-log -1.953829  [12800/30000]\n",
      "current batch loss: -1.575606 KL: 0.488899 Neg-log -2.064505  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.660338 KL: 0.488886 Neg-log -2.149226 MSE 0.011779655702412128\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.640785 KL: 0.488886 Neg-log -2.129672 MSE 0.009751678444445133\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 493\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.679045 KL: 0.488888 Neg-log -2.167933  [    0/30000]\n",
      "current batch loss: -1.517259 KL: 0.488897 Neg-log -2.006156  [12800/30000]\n",
      "current batch loss: -1.433535 KL: 0.488886 Neg-log -1.922421  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.663587 KL: 0.488875 Neg-log -2.152461 MSE 0.010131672024726868\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.642117 KL: 0.488875 Neg-log -2.130991 MSE 0.009786676615476608\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 494\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.785473 KL: 0.488874 Neg-log -2.274346  [    0/30000]\n",
      "current batch loss: -1.374068 KL: 0.488867 Neg-log -1.862935  [12800/30000]\n",
      "current batch loss: -1.626831 KL: 0.488854 Neg-log -2.115685  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.664418 KL: 0.488844 Neg-log -2.153262 MSE 0.009777786210179329\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.632549 KL: 0.488844 Neg-log -2.121393 MSE 0.01059669815003872\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 495\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.726734 KL: 0.488843 Neg-log -2.215578  [    0/30000]\n",
      "current batch loss: -0.996970 KL: 0.488830 Neg-log -1.485800  [12800/30000]\n",
      "current batch loss: -1.634932 KL: 0.488817 Neg-log -2.123749  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.266772 KL: 0.488821 Neg-log -1.755592 MSE 0.015497514978051186\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.205405 KL: 0.488821 Neg-log -1.694225 MSE 0.015048323199152946\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 496\n",
      "-----------------------------------------------\n",
      "current batch loss: 0.248363 KL: 0.488820 Neg-log -0.240456  [    0/30000]\n",
      "current batch loss: -1.573730 KL: 0.488780 Neg-log -2.062510  [12800/30000]\n",
      "current batch loss: -1.358614 KL: 0.488758 Neg-log -1.847372  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.625807 KL: 0.488754 Neg-log -2.114561 MSE 0.00982434768229723\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.603568 KL: 0.488754 Neg-log -2.092322 MSE 0.010316058993339539\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 497\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.708957 KL: 0.488754 Neg-log -2.197711  [    0/30000]\n",
      "current batch loss: -0.679948 KL: 0.488751 Neg-log -1.168699  [12800/30000]\n",
      "current batch loss: -1.517058 KL: 0.488744 Neg-log -2.005801  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.580685 KL: 0.488733 Neg-log -2.069419 MSE 0.018878990784287453\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.580224 KL: 0.488733 Neg-log -2.068958 MSE 0.01143394224345684\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 498\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.236940 KL: 0.488734 Neg-log -1.725674  [    0/30000]\n",
      "current batch loss: -1.678340 KL: 0.488717 Neg-log -2.167057  [12800/30000]\n",
      "current batch loss: -1.697545 KL: 0.488707 Neg-log -2.186252  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.481853 KL: 0.488701 Neg-log -1.970553 MSE 0.013991580344736576\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.471985 KL: 0.488701 Neg-log -1.960685 MSE 0.012798687443137169\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 499\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.712005 KL: 0.488700 Neg-log -2.200705  [    0/30000]\n",
      "current batch loss: -1.211237 KL: 0.488698 Neg-log -1.699936  [12800/30000]\n",
      "current batch loss: -1.621109 KL: 0.488664 Neg-log -2.109772  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.700286 KL: 0.488657 Neg-log -2.188942 MSE 0.009232429787516594\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.671082 KL: 0.488657 Neg-log -2.159740 MSE 0.010351433418691158\n",
      "-----------------------------------------------\n",
      "|\n",
      "-----------------------------------------------\n",
      "Epoch 500\n",
      "-----------------------------------------------\n",
      "current batch loss: -1.537790 KL: 0.488657 Neg-log -2.026448  [    0/30000]\n",
      "current batch loss: -1.544588 KL: 0.488647 Neg-log -2.033235  [12800/30000]\n",
      "current batch loss: -1.666191 KL: 0.488632 Neg-log -2.154823  [25600/30000]\n",
      "-----------------------------------------------\n",
      "avg trn loss per batch: -1.503757 KL: 0.488632 Neg-log -1.992389 MSE 0.013578449375927448\n",
      "-----------------------------------------------\n",
      "avg val loss per batch: -1.483506 KL: 0.488632 Neg-log -1.972137 MSE 0.011474902741611004\n",
      "-----------------------------------------------\n",
      "|\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# a useful function to present things clearer\n",
    "def seperator():\n",
    "    print( \"-----------------------------------------------\" )\n",
    "\n",
    "# reset some parameters\n",
    "batch_size = 128\n",
    "trn_dataloader = DataLoader( trn_dataset, batch_size=batch_size, shuffle=True )\n",
    "val_dataloader = DataLoader( val_dataset, batch_size=batch_size, shuffle=True )\n",
    "tst_dataloader = DataLoader( tst_dataset, batch_size=batch_size, shuffle=True )\n",
    "epochs = 500\n",
    "\n",
    "# re-initialise the model and the optimizer\n",
    "hdn_dim = 50\n",
    "trn_len = trn_amplp.shape[0]\n",
    "print(f\"Training dataset length: {trn_len}\")\n",
    "model = bayes_amp_net( trn_len, hdn_dim=hdn_dim ).to(device)\n",
    "learning_rate = 5e-4\n",
    "optimizer = torch.optim.Adam( model.parameters(), lr=learning_rate )\n",
    "seperator()\n",
    "print( \"model architecture \")\n",
    "seperator()\n",
    "print( model )\n",
    "\n",
    "# track train and val losses\n",
    "trn_nl_losses = []\n",
    "trn_kl_losses = []\n",
    "trn_losses = []\n",
    "trn_mse_losses = []\n",
    "val_nl_losses = []\n",
    "val_kl_losses = []\n",
    "val_losses = []\n",
    "val_mse_losses = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    seperator()\n",
    "    print( f\"Epoch {t+1}\" )\n",
    "    seperator()\n",
    "    train_epoch( trn_dataloader, model, optimizer )\n",
    "    seperator()\n",
    "    trn_nl_loss, trn_kl_loss, trn_loss, trn_mse_loss = trn_pass( trn_dataloader, model )\n",
    "    trn_nl_losses.append( trn_nl_loss )\n",
    "    trn_kl_losses.append( trn_kl_loss )\n",
    "    trn_losses.append( trn_loss )\n",
    "    trn_mse_losses.append(trn_mse_loss)\n",
    "    seperator()\n",
    "    val_nl_loss, val_kl_loss, val_loss, val_mse_loss = val_pass( val_dataloader, model )\n",
    "    val_nl_losses.append( val_nl_loss )\n",
    "    val_kl_losses.append( val_kl_loss )\n",
    "    val_losses.append( val_loss )\n",
    "    val_mse_losses.append( val_mse_loss )\n",
    "    seperator()\n",
    "    print( \"|\" )\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the train and validation losses as a function of the epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots( 1, 4, figsize=(18,5) )\n",
    "\n",
    "c1 = 'tab:red'\n",
    "c2 = 'tab:green'\n",
    "\n",
    "axs[0].plot( trn_losses, label=\"train\", color=c1 )\n",
    "axs[0].plot( val_losses, label=\"val\", color=c2 )\n",
    "#axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel( \"epoch\", fontproperties=axislabelfont )\n",
    "axs[0].set_ylabel( \"Total loss\", fontproperties=axislabelfont )\n",
    "xticks0 = [ int(x) for x in axs[0].get_xticks() ]\n",
    "axs[0].set_xticklabels( xticks0, fontproperties=tickfont )\n",
    "yticks0 = axs[0].get_yticks()\n",
    "axs[0].set_yticklabels( yticks0, fontproperties=tickfont )\n",
    "axs[0].set_ylim( (-4,1) )\n",
    "\n",
    "axs[1].plot( trn_nl_losses, label=\"train\", color=c1 )\n",
    "axs[1].plot( val_nl_losses, label=\"val\", color=c2 )\n",
    "#axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel( \"epoch\", fontproperties=axislabelfont )\n",
    "axs[1].set_ylabel( \"Neg-log-gauss loss\", fontproperties=axislabelfont )\n",
    "xticks1 = [ int(x) for x in axs[1].get_xticks() ]\n",
    "axs[1].set_xticklabels( xticks1, fontproperties=tickfont )\n",
    "yticks1 = axs[1].get_yticks()\n",
    "axs[1].set_yticklabels( yticks1, fontproperties=tickfont )\n",
    "axs[1].set_ylim( (-4,1) )\n",
    "\n",
    "axs[2].plot( trn_kl_losses, label=\"train\", color=c1 )\n",
    "axs[2].plot( val_kl_losses, label=\"val\", color=c2 )\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_xlabel( \"epoch\", fontproperties=axislabelfont )\n",
    "axs[2].set_ylabel( \"KL loss\", fontproperties=axislabelfont )\n",
    "xticks2 = [ int(x) for x in axs[2].get_xticks() ]\n",
    "axs[2].set_xticklabels( xticks2, fontproperties=tickfont )\n",
    "yticks2 = axs[2].get_yticks()\n",
    "axs[2].set_yticklabels( yticks2, fontproperties=tickfont )\n",
    "\n",
    "axs[3].plot( trn_mse_losses, label=\"train\", color=c1 )\n",
    "axs[3].plot( val_mse_losses, label=\"val\", color=c2 )\n",
    "axs[3].set_yscale('log')\n",
    "axs[3].set_xlabel( \"epoch\", fontproperties=axislabelfont )\n",
    "axs[3].set_ylabel( \"MSE Loss\", fontproperties=axislabelfont )\n",
    "xticks2 = [ int(x) for x in axs[2].get_xticks() ]\n",
    "axs[3].set_xticklabels( xticks2, fontproperties=tickfont )\n",
    "yticks2 = axs[2].get_yticks()\n",
    "axs[3].set_yticklabels( yticks2, fontproperties=tickfont )\n",
    "axs[3].legend( loc='best', prop=tickfont )\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both the train and validation losses are being reduced during training, the model is fitting well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to get some visualisation of how well our amplitude regression has worked.\n",
    "\n",
    "The simplest thing we can do is to pass our data through the neural network to get a predicted amplitude for each event, then histogram this and compare it to the histogram of the true amplitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction( model, dataloader, n_monte=30):\n",
    "    \n",
    "\n",
    "    # we don't need gradients here since we only use the forward pass\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # sample from weight distributions\n",
    "        amps_samples = []\n",
    "        sigma2_samples = []\n",
    "        for i in range(n_monte):\n",
    "            print(f\"Evaluating prediction: {i+1} / {n_monte}\")\n",
    "            \n",
    "            # go through dataset\n",
    "            amps = []\n",
    "            sigma2 = []\n",
    "            for X, y in dataloader:\n",
    "                pred = model( X ).detach().numpy()\n",
    "                amps.extend(pred[:, 0]) # dimensions: [batch_size, 2]\n",
    "                sigma2.extend(np.exp(pred[:, 1]))\n",
    "\n",
    "            amps_samples.append(amps)\n",
    "            sigma2_samples.append(sigma2)\n",
    "           \n",
    "    # dimensionaility (n_monte, batch_size)\n",
    "    amps_samples = np.stack(amps_samples, axis=0)\n",
    "    sigma2_samples = np.stack(sigma2_samples, axis=0)\n",
    "                \n",
    "    return amps_samples, sigma2_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating prediction: 1 / 30\n",
      "Evaluating prediction: 2 / 30\n",
      "Evaluating prediction: 3 / 30\n",
      "Evaluating prediction: 4 / 30\n",
      "Evaluating prediction: 5 / 30\n",
      "Evaluating prediction: 6 / 30\n",
      "Evaluating prediction: 7 / 30\n",
      "Evaluating prediction: 8 / 30\n",
      "Evaluating prediction: 9 / 30\n",
      "Evaluating prediction: 10 / 30\n",
      "Evaluating prediction: 11 / 30\n",
      "Evaluating prediction: 12 / 30\n",
      "Evaluating prediction: 13 / 30\n",
      "Evaluating prediction: 14 / 30\n",
      "Evaluating prediction: 15 / 30\n",
      "Evaluating prediction: 16 / 30\n",
      "Evaluating prediction: 17 / 30\n",
      "Evaluating prediction: 18 / 30\n",
      "Evaluating prediction: 19 / 30\n",
      "Evaluating prediction: 20 / 30\n",
      "Evaluating prediction: 21 / 30\n",
      "Evaluating prediction: 22 / 30\n",
      "Evaluating prediction: 23 / 30\n",
      "Evaluating prediction: 24 / 30\n",
      "Evaluating prediction: 25 / 30\n",
      "Evaluating prediction: 26 / 30\n",
      "Evaluating prediction: 27 / 30\n",
      "Evaluating prediction: 28 / 30\n",
      "Evaluating prediction: 29 / 30\n",
      "Evaluating prediction: 30 / 30\n",
      "Evaluating prediction: 1 / 30\n",
      "Evaluating prediction: 2 / 30\n",
      "Evaluating prediction: 3 / 30\n",
      "Evaluating prediction: 4 / 30\n",
      "Evaluating prediction: 5 / 30\n",
      "Evaluating prediction: 6 / 30\n",
      "Evaluating prediction: 7 / 30\n",
      "Evaluating prediction: 8 / 30\n",
      "Evaluating prediction: 9 / 30\n",
      "Evaluating prediction: 10 / 30\n",
      "Evaluating prediction: 11 / 30\n",
      "Evaluating prediction: 12 / 30\n",
      "Evaluating prediction: 13 / 30\n",
      "Evaluating prediction: 14 / 30\n",
      "Evaluating prediction: 15 / 30\n",
      "Evaluating prediction: 16 / 30\n",
      "Evaluating prediction: 17 / 30\n",
      "Evaluating prediction: 18 / 30\n",
      "Evaluating prediction: 19 / 30\n",
      "Evaluating prediction: 20 / 30\n",
      "Evaluating prediction: 21 / 30\n",
      "Evaluating prediction: 22 / 30\n",
      "Evaluating prediction: 23 / 30\n",
      "Evaluating prediction: 24 / 30\n",
      "Evaluating prediction: 25 / 30\n",
      "Evaluating prediction: 26 / 30\n",
      "Evaluating prediction: 27 / 30\n",
      "Evaluating prediction: 28 / 30\n",
      "Evaluating prediction: 29 / 30\n",
      "Evaluating prediction: 30 / 30\n",
      "Mean std pred:  0.054855086\n",
      "Mean std stoch:  0.36942917\n"
     ]
    }
   ],
   "source": [
    "# TURN OFF shuffeling to not mess up the weight sampling!\n",
    "trn_dataloader = DataLoader( trn_dataset, batch_size=64, shuffle=False )\n",
    "val_dataloader = DataLoader( val_dataset, batch_size=64, shuffle=False )\n",
    "tst_dataloader = DataLoader( tst_dataset, batch_size=64, shuffle=False )\n",
    "\n",
    "# dimensionality is (n_monte, batch_size)\n",
    "pred_trn_ampls_samples, sigma2_trn_samples = get_prediction( model, trn_dataloader )\n",
    "pred_val_ampls_samples, sigma2_val_samples = get_prediction( model, val_dataloader )\n",
    "\n",
    "# compute mean prediction, standard deviation of predictions and mean sigma-output\n",
    "pred_trn_ampls = np.mean(pred_trn_ampls_samples, axis=0) # mean prediction\n",
    "pred_trn_ampls_std = np.std(pred_trn_ampls_samples, axis=0)\n",
    "pred_trn_ampls_std_stoch = np.sqrt(np.mean(sigma2_trn_samples, axis=0))\n",
    "pred_trn_ampls_std_tot = np.sqrt(pred_trn_ampls_std**2 + pred_trn_ampls_std_stoch**2)\n",
    "\n",
    "# same for validation data\n",
    "pred_val_ampls = np.mean(pred_val_ampls_samples, axis=0) # mean prediction\n",
    "pred_val_ampls_std = np.std(pred_val_ampls_samples, axis=0)\n",
    "pred_val_ampls_std_stoch = np.sqrt(np.mean(sigma2_val_samples, axis=0))\n",
    "pred_val_ampls_std_tot = np.sqrt(pred_val_ampls_std**2 + pred_val_ampls_std_stoch**2)\n",
    "\n",
    "print(\"Mean std pred: \", np.mean(pred_trn_ampls_std))\n",
    "print(\"Mean std stoch: \", np.mean(pred_trn_ampls_std_stoch))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First for the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQgAAAFgCAYAAAD3iJRKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABtfUlEQVR4nO3dX5Bc5Znn+d/jlmx1G0upQsUfLdZASuyo0BDbUypudgNE45J9pRtISbtXfbFDFQjYufFITcSCApgYttR9tSBMFbMR67uVqmAudLN0FRjs2L1RqTwTtih2kEpMgwG7cCnV2EYecL97kSdLmadOZp5zMs+/zO8nIkOV7zl58sl/jzLf877Pa845AQAAAAAAABhM38g6AAAAAAAAAADZoYMQAAAAAAAAGGB0EAIAAAAAAAADjA5CAAAAAAAAYIDRQQgAAAAAAAAMsE1ZBzAIduzY4e68886swwCQgAsXLnzunBvOOo48INcB/YtcV0OeA/obua6GXAf0t1a5jg7CFNx5551aXFzMOgwACTCz/5J1DHlBrgP6F7muhjwH9DdyXQ25DuhvrXIdU4wTZGaHzGzm2rVrWYcCAAAAAAAABKKDMEHOuXPOuYlt27ZlHQoAAAAAAAAQiA5CAAAAAAAAYIDRQQgAAAAAAAAMMDoIAQAAAAAAgAFGByEAAAAAAAAwwDZlHQCQR9euXdPnn3+u//pf/2vWoSAj3/zmN7Vjxw4VbZEhM6tImnTOHQzYNuWcO9GwX1VS2Tk3E6UN/Y8cODiKmuuAXiDXDQ5yHQbVH//4R62tremLL77Qn/70p6zDQYL+7M/+TN/5znc0NDSkb33rW7GOQQch4HP9+nX9+te/1h133KE///M/l5llHRJS5pzTl19+qY8//ljf+ta3tGXLlqxDCs05N2dmk/52MxuXVPb+rnj7LpjZhLetFKbNObeQ0kNBRsiBg6PIuQ7oFrlucJDrMKj++Mc/6h/+4R+0fft23Xnnndq8eTO5rk855/TVV1/pH//xH/UP//AP2rVrV6xOQqYYAz6rq6saHh7WX/zFX5BAB5SZ6S/+4i+0Y8cOra6uZh1O18ysLGmloem+husrkkYjtKHPkQMHR7/lOiAKct3gINdhUK2trWn79u3asWOHvvnNb5Lr+piZrY+U3r59u9bW1mIdhw5CwOf69eu66aabsg4DOfCd73xH169fzzqMXig75xo7CEu+7TdHaGvijSxcNLNFvnT3B3Lg4OmjXAeERq4bPOQ6DJovvvhCW7duzToMpGzr1q364osvYt2WDkLA5+uvv9amTcy+h7Rp0yZ9/fXXWYfRlRbTgquShmK2NXHOzTjnxpxzY8PDw11EirwgBw6efsh1QFTkusFDrsOg+dOf/qTNmzdnHQZStnnz5tj1JvlfEQjA8GtIffM+WGuoJ1g2s1FJ53VjdGBZ0rx3PUwbBkCfvPcREq83BhXv/cHC641BxPt+8HTzmtNBiFx76PR/p9Wb/imRYw9Xnd7+179M5NhAVrzOwDEzqzjn5pxzS177hG4sOjJnZsfrHYf1EYZh25Jw6aHv6atPPpEk7Xn3XV2/eFG//rf/VnvefiupuwSA3FreO7L+900PPqjvvvqjDKMBgO7Vv+vd9txz2n70iJb3jmjk/eWswwLQgA5C5NrqTf+kX/z1LxI59r0/vjeR4wJZ8jrxtge0z0iaabh+yvtzIWpbEr79P/wPuv2F59evb771Fn187FiSdwkAuXT1zNkNP5o/euxxOgkBFNpXn3xChyCQc3QQAhFceuh7uvV//V+1Zd8+XTpwYL29dPiwbn/heV15+BFdf+89SdKm4WHd/bOfavWll/X56dPr+945NydJ+rBSWW/b8cQTGn7qSX1w/wP62lvoYcs99+iuN17Xp888q+rs7Pq+/MeKftTYOYh8Iv8B6fjs5EltP3qkqe1377yTTTADiFwHJOOOV17JOgQ0INchiDnnsg3ArCRpQtLNzrkTAduPS1qRVyjfGwWT2vao8QQZGxtzi4uLnXZDgHt/fG+iIwjPvlgrVHzHK6+sJ8evTr+su2+9VX+2fbu++d/8N/rjpUv6J2/Fsw8rhzXy/rK++vVv9PXqb9aP9a3duyVJf7x8WbZ5s7b883+eSMxf/fo32nzrLYkcO6zJyUlJ0vT0dM+OWa1W9eijj2pubk5Z5yS/5eVljYyMtNxuZhecc2MphpRb3eS6Kw8/orveeL2p7eqZsxt+JCN5rd7zWU8FykP+k/o3B5LrwknjO13QZy3rz18/Ite1R64bbEnkOv97m5HRyWv3fifX1ZDrmmW6irFX12pc0m7dKITfuH1K0opXR2tG0m4zq6S1PWo8KJad396pI09v0pGnN+m//+h/0ej//T0deXqTVrdKK7eZPvhWVRc/v6hLpT9q5TbTym21Yp8XP7+o//xnq+ttK7eZln+/ouXfr2jlNtN/KSW3Otr1ixdj3e7UqVOddwrp8OHDOnz4cM+OJ0mlUkmzDWeToujlY0N26mcoG9E5iEZx859EDgRQHOS6YOS64mscpSaJzsEBR64LlnWuy3SKcUMR/PsU0EEoacI3qvCMpClJcyltjxoPCuTNypuB7cvLyxrZEdzbfvW557R9x762x734efxk18nHx47FOtNz/vz5nsUwPj7es2P1Qi8fG/Il6zObaHbbc89lev9x859EDkSxBE3DIxemh1xXQ65D0hhBmC1yXQ25rlmmIwjbMbPRgOaqaiMOE98eNR4MhiKOaDpxYsPM/b7Rz49t0GwaHs46BHRQxPwn9Xee6OfHNsi27Nt4IvLqmbMZRDKYyHX508+PbZBRWzVb5Lr8ycNjy/MiJUOS1nxtaylujxpPEzObUK22onbt2tXmsCiSoo1oWlhY0MrKipaWlnTq1CmVSiVNTExoYWFBJ06c0NjYmA4ePKgzZ87o6NGjqlQqWlpa0tramqrVqs6fP6+DBw+un1lZWlpaT1zz8/Pr10ul0nr9hvn5ee3evVsTExMd4ztx4oR2796toaEhlUqlDdvbxdLqsXW6HfLp7p/9NOsQ0EHR8p9EDiQHFtOlAwc2fNaCFi5BMsh15Doko9TjaZzoDrmOXBfIOZf5RbVputO+toqky762kiTn/Zvo9oAYI+3feNm/f79DPP/i//wXqd/ne++913rbP9/b8fa/XP1lL8NpsvZ/nYl8m9nZWVepVDa0T09Pu3K57K5eveouXLjgLly44JxzbnR01M3Ozq7vVyqVmm43Pz/vxsfHm45fLpfd5cuXnXPOXb161dVSS3vj4+Pr9+mcc5cvX95wu06xtHpsnW4XRbv3g3POSVp0Ocijebh0k+t+87+/tKHtHyYfi308xNfqPR8m/yUpTv5zjhwYdLsg5Lrk81xYQZ+1rD9//YhcR64LQq7LNteht7r9XZskcl0+c12eRxBW5a0U3GAoxe1R4wES18vRA0NDtbdvqVTS6OiNGfSzs7Mql8tN+1ar1cCzIPXbS1q/Tf16u9ssLS1pZWWl6X799xknlm5vh+x8fvq0hp96sqmNujRo1OvRU+RAAHlEruscS7e3QzauPPyI7nrj9fXrRRu9ht4i13WOpdvbxZHnDsI1bVy4pCRJzrmqmSW6PWo8QQ/AzA5JOrRnz56gzSigmx58MNP77/VQ8MYkVjc0NLQ+rLmeiNbW1tomoKAE2M7i4mKohBYnlm5uh3yheHW+9Fv+k8iByKegaXhBC5cgGeS6UsvjkOvSZWYVSZPOuYPe9ZKksne5z3mLZ3r7VSWVnXMzUdrSdP2995quXz1zltIJGSLXlVoeZ5BzXW47CJ1zS2ZW9TUPSVpIY3vUeFrc5pykc2NjY4+22gfFUvTOipWVFUntk97+/fs1Ozu7IcH28ixFuVxej6WdKLE0PrY0HgOSR/HqfCl6/pPIgeTAYrj9hec3tAUtXIJkkOvIdXnhnJszs8mGpiNe+4yZ3efVvF/z2hbMbMLMxnVjEEvbNudcy9+xaaC2arbIdeS6ILldxdhz1jvTUXdQ0nRa282s7Nve6Xjocx899njWIURWLpdVrVYl1RJNuwRaL4BaTz7120m1wqmtrK21W99no/HxcZXLZS0tLTXdd9RYgh5b3MeAbN05N5d1COigiPlPIgeSA4vnysOPbGi7dOBABpEMJnIduS6vnHMzDSP/ypJWJN3n/Svv39EIbanaNDyc9l2iDXIduS5Iph2EZjZqZsdVWwBk3MyOm9l6snLOTUoqm9m4d4bksnNuLq3tXlyTEfZHn/vdO+9oee/I+uXLX17Ul7+82NRm/8cZSdIH9z+w3lb/sv/pM8827fvVr3+jL97+SVPb1TNnJamprZ7A4wwFHx0dVblc1szMzPqZiIWFBU1PT6+vklRPNKOjozpy5IhOnTqlhYUFLS4u6rXXXtPU1NR6gpqentbi4qJmZma0tLSkqakpraysaGZmRtVqdX0lqBMnTrQ9k/LWW2/pzJkzmpub08LCwnoinpycVLVa7RhLq8cW5nYAoguT/1ZfellSfvKfRA4kBxaPfxoe0kWuI9flnZmVJa15IwBLvs03R2jzH3fCzBbNbHF1dbU3wTa4+2c/7fkxER+5jlwXxGoLmCAJDTUIH/3ggw+yDqeQ7v3xvfrFX/8i1ftcXl7WyMhI7Ntf/Pyi9u1gKlC/6PR+MLMLzrmxFEPKrbGxMbe4uBjrtknUIUE83eZAFBO5Lpxu8lxYQfmQHNl75LrBVLRcZ2bz9RqEDW3HnXOnvL+nJM17U4fHVZvhpjBt9RqGQZLIdasvvdy0IN0Xb/9E33nor3p6H2hGnhtccXNd3qcYF5pz7pxzbmLbtm1ZhwIAhVM/6wgAgyRoGl7QwiUABo+ZVRo6B0clndeN0YFlSfMR2lL1+enTTdeprQrkDx2EAIBc+uzkyaxDAIDUBU3DC1q4BEB/80b6jdVr4HvXp8zsgpldkDTklbsq1xcicc4thG3L6GGto7YqkD+5XcW4HzRMMc46FADItR1PPJF1CACQC/5peFJt4ZK73ng9o4gAZMHrxNvuu747YL9T3p8LUdsAoBEjCBPEFGMACMf/YxgAWjGzipnNN1wveQvfVbx6XI371ReWi9SWJf80PImFSwAU351zrO0J5B0dhACAzH1w/wMb2u545ZUMIoEksYDZYCna6+1NlWt0RNJYvd1bibPi7bvgtY2HbUvnUSAPivbeR3d4vfOF2qrp4H0/eLp5zekgBABk7uvV1Q1tFK/OxubNm/Xll19mHQZS9OWXX2rz5s1ZhxGbc27GOTfjXS1LWpF0n/evvH9HI7TlTtDCJegOuW7wFD3XFd2HlUrTdWqrJu+b3/wmeW4Affnll/rWt74V67Z0EAIAconi1dm45ZZb9Ktf/Up/+MMfOOvc55xz+sMf/qBf/epXuuWWW7IOp2tmVpa05o0GLPk23xyhzX/cCTNbNLPF1YCTGb0WNA0vaOESdIdcNzj6Ldf1iysPP5J1CH1vx44d+vjjj7W2tqavvvqKXNfHnHP66quvtLa2po8//lg337zh60woLFKSIBYpAYBwttxzT9YhwLN161ZJ0ieffKKvvvoq42iQtM2bN+vWW29df90LruKcm/T+rkoa8m0P29bEG504I0ljY2OZ/LoKWrgE3SHXDZY+y3V9gdqqydu2bZu+9a1vaXV1Vb/97W/19ddfZx0SErRp0yZt2bJFu3bt0pYtW+Ido8cxoYFz7pykc2NjY49mHQsA5Bmrc+bL1q1b+RGFQjGzSn2FTjMblXReN0YHliXNe9fDtGXqw0pFI+8vN7V9fvo0HYQJINcB6dnxxBNZhzCQtmzZou9+97tZh4GCYIoxACBznz7z7IY2ilcDCOItJDJWX2DEuz5lZhfM7IKkIW/BkrK3reScWwjbltHDAoC+5j/JQW1VIH8YQQgAyFx1dnZDsWqKVwMI4nXibfdd3x2w3ynvz4WobQCA3vrg/gea6qlSWxXIHzoIgQh+MPcDffL7TzK7/53f3qk3K29mdv9Amq48/AhTjwEMnKBpeEELlwBAkXztW+SJ2qpA/tBBmCAWKek/n/z+E/3ir3/Rdp+Ln1/Uvh37Ern/e398byLHjWJyslb/fXp6OuNIOqtWq3r00Uc1NzfHql0FRPFqAIOIH8wABgG1VYH8oQZhgpxz55xzE9u2bcs6FAy4U6dOdd4ppMOHD+twQWrDlUolzc7OZh0GQtjz7rtZhwAAufDB/Q9saPuwUskgEgDonS333JN1CAA6YAQhMADOnz/fs2ONj4/37FhA3fWLF7X51lua2iheDWAQ+afhAUA/oGwMkH+MIAT63IkTJ7IOAejo42PHNrRRvBoAAKA/fPrMs03Xqa0K5A8jCIE+trCwoJWVFS0tLenUqVMqlUqamJjQwsKCTpw4obGxMR08eFBnzpzR0aNHValUtLS0pLW1NVWrVZ0/f14HDx5cHzW4tLS03uE4Pz+/fr1UKq3XJpyfn9fu3bs1MTHRNq4TJ06oXC7r4MGDGhoa0vnz55tu1y7GarWqF198Uffdd9+GGKVap+ju3bs1NDSkUqm04f5PnTql0dFRVatVzc/Pr8eCfKF4NYBBFDQNL2jhEgAokursrG5/4fmswwDQBh2EQB8bHx9XtVqVJB0/frypfXJyUlNTU5qammrqHHv00Uf19NNPq1KpqFKpaPv27bp69aokaXR0VCdOnNDU1NT69cnJyfUOtnK5rLGxMW3fvr1tB+H4+LiefvppnThxYr1GYKVSWa9tODEx0TbG/fv368KFCyqVSqpUKtq/f7/eeustlUolHTx4UFNTUxodHZUkraysNN33zMyMyuVyU4di/TlCvlC8GsAgCpqGRy4E0G8+rFQ08v5y1mEAaEAHYYJYxRh5NjQ0JKm2kEe9M02SZmdnN4ymq1argSPx6reXtH6b+vV2t6lrvF+ptkLy4cOH1zsXg2Kcm5tTqVRqOvbY2JjOnj2rsbExraysNB3X/1jK5bImJye1tram8fFxVSj8ngu3Pfdc1iEAQC58+syzG0bZfHD/A5RdAAAAiaIGYYJYxRh55++gk2qdcqdOndLMzIwWFhYkSWtra22P06vpueVyecNoPn+M9RGBCwsL65fDhw9rfHxci4uLHTslx8fHNT09rfn5ee3fv1/79+/vqxGEZlYxs/mG6yUzG/Xap3z7jZvZRNS2JGw/eiTJwwNAYVS9kfWNWLgEQNHteffdrEMA0AEjCIEBUu9ca9eht3//fs3Ozm7omAszIrBbKysrHTsb652IQaspl8vlDVOK/RYWFjQ+Pr5++8nJSc3MzDRNwS4y59ycmU02NB3x2mfM7D6vo2/Na1swswkzG5dUCtPmnFtIIu7lvSMbpplQvBoAAKA/XL94UZtvvWX9OrVVgfxhBCHQ5xpH5XXqgKsvUFLvHGwcWVcfTRik0wjDdvfXaGpqquOqy5VKRaVSqakjcGVlZb3jr1wuNx3Xfx9LS0tNj6W+uEq/cs7NOOdmvKtlSSuS7vP+lffvaIQ2AEDKghYuAYAi+fjYsabr1FYF8ocRhEAEO7+9U/f++N5M7z+q0dFRlctlzczMrLctLCxoenpaKysrOnXqlCYmJtbr/B05cmR9lV9Jeu211zQ1NaXJyUktLS1penpai4uLmpmZ0djYmKamprSysqKZmRkdOXJEL774oqTaSsKdVgeuxzU0NKSVlRVNTk6u1wRsFaMkvfXWW+urGEu1GoX1EYH1bSsrK00jHusLntQ7F+e80WkrKyt9M3qwHTMrS1rzRgMe9m2+Wd5owRBt/uNOSJqQpF27dvUk1jqKVwMYREHT8IIWLgGAIqO2KpA/dBACEbxZebPjPhc/v6h9O/alEE1409PTTdcbp9h22ldS00Ies77aSPPz803X66sOh1EqlVqudtwuxlKp1PI+grY559b/bre6cp+rOOfqwyWrkoZ828O2NfFGJ85I0tjYmGu3bzs3Pfhg3JsCQF/xT8OTghcuAYAio7YqkD90EKJrP5j7gT75/SeJHDvOiDkURz8tDpJnZlZxzp3y/h6VdF43RgeWJc1718O0JeK7r/4oqUMDQKF8fOzYhtHT1dlZOggBFNptzz2XdQgAOqCDEF375Pef6OyLX68vKPBhw2izHU88oeGnntQH9z+wfpZoyz336K43XtenzzzbtFLfnnff1fWLF5vqU9z23P+c0qNAmurTh+tTlQd4VF/PeYuLjHmdgnPe9Skze9rb5YTXfry+EEl94ZGwbUn46LHHN3QSUrwaAACgP2w/eqTpOrVVgfyhgzBBZnZI0qE9e/ZkHUriGs90B9UMC6ovcfsLz284G7751luoOTYA2k0fRne8Trztvuu7A/Y75f25ELUtCb97550NbRSvBgAA6A/Le0eafudRWxXIH1YxTpBz7pxzbmLbtm1ZhwIAhfPB/Q9kHQIApC5oGl7QwiUAUGSfPvNs1iEA8KGDEAjQuKgFBhfvg2xRvBrAIPJPw5NqC5cAQD+p+hY+BJA9OggBn82bN+vLL7/MOgzkwJdffqnNmzdnHcZAoLQAANQs7x3Z0NZYnxkAiuimBx/MOgQAHdBBCPjccsst+tWvfqU//OEPjCAbUM45/eEPf9CvfvUr3XLLLVmHMxCunjm7oY3i1QAAAP3BvxgdgPxhkRLAZ+vWrZKkTz75RF999VXk23/2u8/0jVX63otu8+bNuvXWW9ffD0jWZydPbphWR/FqAACA/vDRY483dRJSWxXIHzoIgQBbt26N3TF05MdH9Iu//kWPIwIGz6fPPLthpXMA6HdB0/CCFi4BgCL53TvvNF2/fvGiNt/KTB0gTxjmBADIJYpXAxhEQdPwghYuAYAio7YqkD90EAIAMnfHK69kHQIA5MJHjz2+oS1o4RIAAIBeooMQAJC5Lfv2ZR0CAOSCfxoeAPSDkfeXsw4BQAd0EAIAMnfpwIENbRSvBgAA6A9Xz5xtuk5tVSB/6CBMkJkdMrOZa9euZR0KABTO9YsXsw4BAHIhaOESACiSz06ebLpObVUgf+ggTJBz7pxzbmLbtm1ZhwIAhUPxagCDKGgaXtDCJQBQZNRWBfKHDkIAQOZKhw9nHQIA5IJ/Gp4UvHAJgP5mZhUzmw9oGzeziV60AUAjOggBAJm7/YXnsw4BAHLBPw1PYuESYBA55+Yar5tZxWtf8K6Pd9OW1uOou+OVV9K+SwAR0UEIAMjclYcf2dBG8WoAAIB190la8f5ekTTaZVuqtuzb13Sd2qpA/tBBCADI3PX33tvQRvFqAACAdSXf9Zu7bGtiZhNmtmhmi6urq7GDbOXSgQNN16mtCuRPzzoIzWyrmd3Zq+MBwCAjp1K8GhgE5LqNgqbhBS1cAqA4epTrqpKGetjWxDk345wbc86NDQ8Pxw4yLGqrAvkTuYPQzP43M3vTzF6sJzkzOyPpgqS/MbMzfNEDgHDIqTWbUvgiCiA75Lrw/NPwpOCFSwDkT8K57rxujAQsS5rvsi1T1FYF8mdTjNuclzTtnLsiSWb2bySNOufuru9gZj+U9He9CREA+ho5VdLdP/tp1iEASBa5LqRLBw5sGDH42cmTlF0AiqFnuc5bSGTMzCrOuTnn3JyZHffaSw0LjsRuS1Pp8OG07xJARHE6CLfXE55nUtKrvn2uCAAQBjlV0upLL2v4qSeb2iheDfSVnuU6bzXOSefcQV9bVVLZOTfTbRsAxNSzXOd14m33tZ3y/lzoRVuabn/h+SzuFkAEcWoQXq3/YWbbVBui7E8yrpugAGCAkFMlfX769IY2ilcDfaVnuc45N9d43evgU8MomfFu2iI/MgC4ge91LVx5+JGm69RWBfInTgdhY0KbkFR1zv1H3z4bVkUCAAQip7ZA8WqgrySZ6+6TtOL9vSJptMu2Jkmv7OkXNA0vaOESALnE97oWrr/3XtN1aqsC+ROng/Camf3QzB6VNCXpX9U3mNkjZnZeOSh6CmTp02ee1fLekfXLV7/+jb54+ydNbfX/FBvb6h0iHz32eFO7VPtP9NJD38vsMSEx5NQWKF4N9JUkc13Jd/3mLtuapL2yZ9A0vKCFSwDkEt/rQvrs5MmsQwDgE7kGoXPuLTNbkTQuab9z7ufSegFWSTrrbfv3PYsSKJjbX3h+wxf8zbfeEjiUPqgtaGrl9qNH+I+0D5FTa+6cm+u8E4DCSjjXVSUN9bAtU1cefkR3vfF6U1vQwiUA8ofvda1tSuEEC4DuxFmkRF7h1dd8bX/bk4iAgtv57Z2698f3JnLs4cf/TG8ncmRkiZwKYBAkmOvO68ZIwLJqo3NKXbRlyj8ND0Cx8L0u2N0/+2nWIQDoIHIHoZnd6Zz70Ne2TdIR1WourDnn3uhFcGZWUq12w83OuRMB24+rVi9mSKpNAenl9qj3B0jSm5U3Ezt2Uh2PyE6aOTXPPqxUNoyOYbQM0D96meu8hUTGzKzinJtzzs2Z2XGvvdSw4EjsNgCIg+91ra2+9LKGn3py/Tq1VYH8iVODcENHnXPumnPuNefcv3fOvWFm/yrohlF4X9TGJe3WxvowMrMpSSveF8MZSbvrK9H1YnvU+wOAmFLJqUVE8Wqgr/Qs1znnFpxz2xtXM3bOnfLaT/WiLUtB0/CCFi4BkEt8r2vh89Onm65TWxXInzgdhNbzKAJ4X9TmVKsNE2Si8YuhpDOSJnu4Per9AUAcqeTUIqLmJtBXyHUhBU3DC1q4BEAuketCunTgQNYhAPDpOMXYzL6n5uXa7zKzh1rsXpJ0n/dvYoVXzWw0oLmq2ojDrrdHvT8ACCuPOTUPdjzxRNYhAOghcl18/ml4UvDCJQCyR64D0E/C1CBcUa1o82HV6gE61ab9tjLvnHu8B7G1MyRpzde21sPtUe8PAMLKY07NnP/HMIDCI9fF9Pnp0xtyIguXALlFrgvpzrm5zjsByFTHDkJvFaYrkt4yszlJFefcY4lH1l6p1QZvYZOutjvnqlHuL2B/mdmEav9JaNeuXa1uDmDA5DSnZu6D+x/YMK2O4tVAcZHrAAwCcl189dqqVx5+ZP0kyKbhYVY7BjIUaRVj59yCtwpTW2b2kHPu7fhhdVSVt5Jwg6Eebo96fxt4C5nMSNLY2Jhrty+AwZSjnJq5r1dXN7RRvBroD+S67gUtXAIgX8h17X1YqWjk/eX16/XaqpRPAPIj8iIlzrkwn+CkF+9Y08ZRfSVJ8kbzdbs96v0BQCy9zqlmVjGz+YC2cW9kc9dtaaF4NdA/cvL9sRCCpuExogYoBnJdd1ZfejnrEICBFrmD0My2mtnfm9mfWlz+SVIlgVjXOeeWtHF14yFJC73YHvX+WjGzQ2Y2c+3atXa7ARhgvc6pvtXWZWYVr33Buz7eTVvXD7iFLffck9ShAeRAHr4/Fhk/moFiINd15/PTp7MOARhokTsIVVtxaVbSmKQ9LS5v9SrANs7Wf7x6Dkqa7tV2Myv7tnc63gbOuXPOuYlt2zqONAcwuJLOqfepVkBb3r+jXbYlguklQN/Ly/fH3PuwsrHvgB/NQGGQ61rY8cQTWYcAoININQg9886519rtYGZtO87CMLNRSePyzrCY2XFJC95oPjnnJs3suDeipSzpcuPImW63e/d7UNJcyP0BII6kc2rJd/3mLtua9GpBpk+feXa9Fk1dvXg1gL6QyvdHAMgYua4F/+rsAPInTgfhWqcdQtZe6HSMJUlLkk612afltm63e9tOBbSFZmaHJB3as2dPlJsBGCxJ59SqNi6q1E1bk14tyFSdnd3QQei/DqDQUvn+CAAZI9e18MH9D3SspxpUgxVAeuJMMa6a2Z3tdjCzH8YLp78wxRhACEnn1PO6MRKwLGm+y7bUXHn4kTTvDkCy+P4YUtA0PH40A4VBrmvh69XVrEMA0EGcEYROUsXMdku6oOCzJEcl/V03gQHAgOhpTvXKIIyZWcU5N+ecm2soj1BqWHAkdlta/lStannviDYND+vun/1Uqy+9rGv/4T9oz9sDWboHKDq+P4bENDyg0Mh1XfiwUtHI+8tZhwEMrDgdhPVTmGuqFbD3K0m6K25AADBgeppTvU687b62enmEhV60JWHPu+9ubPN1BA4/9SSF+oHi4vtjSEHT8PjRDBQGua6FLffck3UIADqI00G46Jz7frsdzOzVmPH0FWoQAgiBnCrp+sWL2nzrLVmHASA55LqQmIYHFBq5roW73hjI0otAocSpQTgZYp+pGMftO9QgBBACOVXSx8eOhdqPOlxAYZHrAAwCcl0Lnz7zbMd9gmqwAkhP5A5C59wVSTKzrWb2kJltrW8zs79s3AcA0B45FcAgINeFFzQNjx/NQDGQ61qrzs523IcarEC24kwxrg+LnpB0WdIJSW/c2GQ/dM5RdDWHfjD3A33y+096ftyd397Z82MCg4ScGh51uIDiIteFEzQNjx/NQHGQ6+ILqsEKID2ROwjN7N9Iuuyc+4Z3/ZH6NufczyX93Mweds690eoYgyJvNQg/+f0n+n+/+79ry759unTgwHp76fBh3f7C87ry8CO6/t57ktS0amjjogD16X0fVirrbTueOJTSIwD6Dzm15rbnnss6BAAJIteF9+kzz+r2F55vauNHM1AM5LruUIMVyFacEYRV59xrDdddr4LpN865c5LOjY2NPZp1LHXfeeivJClwBE6rM9ZBZ60ZwQP0DDlV0vajR7IOAUCyyHUhVWdnN3QQ8qMZKAxyXQt73n036xAAdBBnkZLfhtinHOO4ADCIyKmSlveOhNqPOlxAYZHrAAwCcl0L1y9e7LhPUA1WAOmJ00G423fdmq6Y3SlpR9yAAGDAkFMjoA4XUFjkui7woxkoDHJdCx8fO9Zxn6AZbQDSE6eDcMHM3jSzv/JWZXJSLdl5NRfmJf27XgYJAH2MnBrBB/c/kHUIAOIh14UUNA2PH81AYZDruvDpM89mHQIw0CJ3EHrFVf9W0muSrkqaNbM/qbZK05ik7zvn/rGnURaUmR0ys5lr165lHQqAnCKn1tz04IOh9qMOF1BM5Lrwgqbh8aMZKAZyXXeqs7NZhwAMtDirGN/pnFuQtMfM/qVqNRSqkhadc/SENcjjIiUA8oWcWvPdV3+UdQgAEkSuC+/jY8c2LAYXtHAJgPwh17V223PPZR0CgA7irGI8K+k+6cZS7T2NCAAGCzlV0kePPR6qk5A6XEBhkesADAJyXQvbjx7JOgQAHcSpQbjfq6vwcM+jAYDBQ06V9Lt33gm1H3W4gMIi1wEYBOS6Fpb3jnTcJ6gGK4D0xOkgPOGc+4Gkn5vZo2b2Q281JgBAdOTUCKjDBRQWuS6koGl4/GgGCoNc14WgGqwA0hN5irFz7m+9f6+oVnxVZvY9Mzuo2ipNZym8CgDhkFOjoQ4XUEzkuvCCpuFdv3hRm2+9JYNoAERBrutOUA1WAOmJM4JwA+fcW865+kpNV8zsTC+OW3SsYgwgjkHMqXwZBAbPIOa6MIKm4X187FgGkQDoBXJdzU0PPph1CAA66LqD0MzuNLMXzey3kmZUO1PyN11H1gecc+eccxPbtm3LOhQABTGoOfXqmbNZhwAgRYOa6wAMFnLdDWEWowOQrcgdhGZ2xsy+Y2b/yswWJV1Wbfn2I865m51zf+MNqQYAdEBOrfns5MlQ+1GHCygmch2AQZB0rjOzipmNm9lEL9rS9NFjj3fcJ6gGK4D0xBlBeFhSVdKkpGlJQ865o865t3oZGAAMCHJqBBSvBgqLXBdS0DQ8fjQDhZFYrjOzcUkrzrkFSStmNmpmFUny2uR1AIZq6zaeqH73zjsd9wmqwQogPXE6CFckjTnn7nPOveaco8AeAMRHTo2AOlxAYZHrQgqahsePZqAwksx1i5JmzWxUUtk5tyTpPu8+6/c9GqGtiZlNmNmimS2urq72MOzwgmqwAkhPnA7Caefcz3seCQAMJnKqpDteeSXrEAAki1wXUtA0PH40A4WRWK5zzlVVG5U4K2m/11zy7XZzhDb/8Wecc2POubHh4eEuowVQRJE7COtLt5vZVjN7yMy21reZ2V/2MDYA6Hvk1Jot+/ZlHQKABJHrwgszDQ9APiWZ67xpwQvOud2Sqt604aqkId+uYdtSNfL+cpZ3DyCEWKsYm9mrqiWZaUnjzZvshz2ICwAGBjlVunTgQKj9qMMFFFeSua7IhfsB9JcEc92oN61Ykl5UrcPvvG6MDixLmo/QlqqrZ8523CeoBiuA9MRZxfjfSLrsnPuGc+5uSVbf5pz7uXPu78zs4V4GWVRmdsjMZq5do8wOgGDk1GiowwUUU5K5ruiF+8PgRzNQDAl/r5vx6gSOq7Yq8oxzbk5S2WsrOecWwrZ190ij++zkyY77BNVgBZCeOCMIq/Wh0x7Xq2D6jXPunHNuYtu2bVmHAiC/yKkRUIcLKKwkc11fFe4PmobHj2agMBLLdc65qtcpuOCcm2loP+W1nYraljdBNVgBpCdOB+FvQ+xTjnFcABhE5FRJpcOHsw4BQLISy3X9Vrg/aBoeP5qBwuB7XReowQpkK04H4W7fdWu6YnanpB1xAwKAAUNOlXT7C89nHQKAZCWW64peuN8vaBoeP5qBwuB7XQt3vPJK1iEA6CBOB+GCmb1pZn/lrcrkpFqy82ouzEv6d70MEgD6GDlV0pWHHwm1H3W4gMJKMtcVunA/gL7C97oWtuzbl3UIADrYFPUGzrmfm9nfSnpN0l2SZLZ+YmRO0vedc//YswgBoI+RU2uuv/deqP2owwUUU8K5bsZbgXhFtRqEM97xj/sL8odtA4A4+F7X2qUDBwJrrDbqtB1AsiJ3EErrK73tMbN/qdrZ1qqkReccy/UCQETk1PA+euxxOgmBgkoq13k1CGcC2uuF+BeitmUpaBoeP5qB4uB7XXxXz5zV9qNHsg4DGFixOgjrnHM/l/TzHsUCAANtkHPqppCF/6nDBRTfIOe6MIKm4fGjGSgecl10n508Sa4DMhSnBiEAAD11989+mnUIAJALlw4c2NAWtHAJABRJ6fDhrEMA0AEdhADQ58ysYmbjXo2urtuSsPrSy0keHgAAABm6/YXnsw4BQAd0EAJAH/MK76949XBWzGzUzCrSeo0ceR2AodqSivPz06dD7UcdLgAAgOK58vAjHfcJqsEKID10EAJAf1uUNGtmo6qt7rkk6T7VVvuU9+9ohLZMXT1zNusQACBRQdPw+NEMoOiuv/dex32CarACSA8dhAkys0NmNnPtGgtWAciGt7rntKRZSfu95pJvt5sjtDUxswkzWzSzxdXV1S6j7Yw6XAD6XdA0PH40AxgEQTVYAaSnZQehmf1LMztjZn+ZYjx9xTl3zjk3sW3btqxDAZCxrHKqNy14wTm3W1LVmzZclTTk2zVsWxPn3Ixzbsw5NzYcciXiIHfOzcW+LYD84Ptj94Km4fGjGcgXcl10m7r4ngggHe1GEI5LuuJvNLMfdjqomW3tJigA6ENZ5dRRb1qxJL2oWoffed0YHViWNB+hDQDa4ftjl8JMwwOQOXJdRHf/7KdZhwCgg7ZTjJ1zf+Oc+4++5t0hjvt07IgAoE9llFNnvGnA45KOeCP+5iSVvbaSc24hbFsXcbT1YaUSaj/qcAH5x/dHAIOAXBfN6ksvd9wnqAYrgPRsarNtwczOSzojaamhvWxmD7W5XUm1MyoDmfgAoIVMcqpXg3AmoP1UPa6obVmiDheQe3x/7FLQNDx+NAO5Q66L6PPTpzX81JNt9wmqwQogPS07CJ1zPzezo5KOS/ofGzaVJZ0KvpWkWtK7qyfRAUCfIKf2xqUDBzTy/nLWYQBogVzXvaBpePxoBvKFXJeMKw8/orveeD3rMICB1W4EoZxzK5Iea2wzs1edc4+1uMn6Pj2IDQD6Cjm1tR1PPJF1CAB6hFzXndWXXt4wyoYfzUD+kOt6jxqsQLba1iBsYTbEPlMxjgsAg4icKnWccgKg8Mh1IX1++vSGNn40A4VBrmvhzrm5rEMA0EHkDkLn3Fv1v81sq5k95F22NuyzYUUnAMBG5NSaD+5/INR+1OECiolcB2AQkOu6E1SDFUB64owgrCe7s5KqqhWuX5B01czeNLN/1sP4AKDvkVOlr1dXQ+1HHS6guMh18fGjGSgOcl2wDyuVjvsE1WAFkJ7IHYRmtk3SnKR5Sbudc9+QtF3SHklvSZprPEMCAGiNnBrNlYcfyToEADGQ68ILmobHj2agGMh13Vl96eWsQwAGWpwRhI9KOuyce60+PNo5d805d8U5d0rSQQ3gsu0AEBM5VdKWe+4JtR91uIDCItd1gR/NQGGQ67oQVIMVQHrarmLcwjXn3LVWG51zVTNb6SKmgfaDuR/ok99/ksixh6sukeMC6Ao5VWJ1TqD/ketC+rBS0cj7y01tn58+zWJOQDGQ61rY8cQTWYcAoIM4HYRhepnoiYrpk99/ol/89S8SOfby3hHpXydyaKRs9aWXm86w1acjNdb22PHEExp+6kl9cP8D6/Xdttxzj+5643V9+syzqs7eWGRtz7vvavOtt6QUPXzIqZI+febZUPUFqcMFFBa5DsAgINe1wEkOIP/idBBub7fRq6mwJ1440ZhZSdKEpJudcycCth+XtCJpSJKcczNRtkc9Xi8t7x1Z//umBx/Ud1/9kT567HH97p131ttH3l/W1TNn9dnJk+ttd7zyirbs26dLBw6st5UOH9btLzwfegof8m/4qScD/5P1jziQgusW3f7C802dMV+8/RM6CLOTm5yapersbKgOQupwAYVFrgMwCMh1LXxw/wMdv8cF1WAFkJ44HYQzZvb3kn4k6S3n3D9K68nuiKRJSd/rXYjBzGxcUknS7hbbpySdd87N1a+bWaXxervtUY/Xa0EdPd999Ucb2rYfPaLtR4+Euj1T+NDKx8eOBb5nkIpc5NSiWH3pZc5AA8VErgspaBoeP5qBwiDXtVCf0QQgvyIvUuLVVHhM0uOSqmb2JzP7k6SrqiW8I/VEmCTn3ILXOVdtscuEr/PujBdf2O1RjwcAkeUlpxYFxauBYiLXhcdJEKC4yHXdaSyXBCB9cUYQyjm3Iun7ZnaXpFGveam+UlPWzGw0oLkqaTzM9qjHA4Bu5D2npmHPu+9mHQKAhJHrwgmahhe0cAmAfCLXBaPcFZB/sToI67wkl8dENyRpzde2FmF71OMBhXbbc89lHQKU65yauOsXL1IHExgQg5zrwmAaHtAfyHXNKHcF5F9XHYQ5Vmq1wVvYpO1251w1yvEC9peZTai2gIp27drVJlQgvJ3f3ql7f3xvIsd9UxtrWQJpCVsHkzpcAAAAxfPpM892XJAuqAYrgPT0awdhVd5Kww2GImyPerwNvBWOZyRpbGxsIJeyR++9WXkzkeMm0ekIAACiC5qGx49mAEVXnZ3t2EFIDVYgW5EXKSmINW0c9VeSJG+0X6ftUY8HAEgBxasB9LugaXj8aAYwCD64/4GsQwAGWl92EDrnlrRxdeMhSQthtkc9XitmdsjMZq5duxYmbAAYWNTBBICaT595dkMbP5oBDAJqsALZ6ssOQs9ZM2scanJQ0nTY7WZW9m3vdLwNnHPnnHMT27Ztix49AAyQ7UepgQkAUm0anh8/mgEU3Z533806BAAdxOogNLOtvQ4kRgyjZnZcUkXSuJkdN7P6MvJyzk1KKpvZuLdgyGXn3FzY7d5xJyPsDwCx5CGnZm1570io/ajDBRQXuQ7AICDXBbt+8WLHfYJqsAJIT+RFSszs7yXtl3Rz78MJz5v2uyTpVJt9Wm7rtN3bdiqgLTQzOyTp0J49e6LcDMAAyUtOLQrqcAHFRK7rDj+agWIg17X28bFjGnl/ue0+QTVYAaQnzgjCWUnlXgfSj5hiDCAEcmoE1OECCotcF1LQNDx+NAOFkWiu82bRVRpLX3nX67PcIrXlTVANVgDpidNBuCbJtdvBzF6MFw4ADBxyqqSbHnww1H7U4QIKi1wXUtA0PH40A4WRdK572itzNdRYM985t+AdezxsWxcxJCaoBiuA9ESeYizpsqQJM7tZ0nnVVvdda9g+JGlc0tNdRwcA/Y+cKum7r/4o6xAAJItcF1LQNLzq7Kxuf+H5jCICEEFiuc4b+XfezMrOuRmvbVLSGW+XFUmjqk1vDtO2EHD8CUnatWtX1PA6uu2553p+TAC9FaeD8G3v3zVJhwO2D0liTq2oQQggFHKqpI8eezxUJyF1uIDCSjTXeQvVlSWpvoicN2KmKqnxx3SoNgCIKclct7t+bDOblnRCUsm3z80R2pp4+W9GksbGxtqOgoxj+9EjvT4kgB6L00G44pwba7eDmb0aM56+4pw7J+nc2NjYo1nHAiC3yKmSfvfOO6H2ow4XUFhJ57qnnXOHzWzCzMqqjY6Rc27BaxuX9wO5U1t9Ch4AxJB0rrvsnKua2QXVRvtVVet0bBS2LVXLe0c6LlISVIMVQHri1CAM09k1FeO4ADCIyKkRUIcLKKzEcp1/2p1zbkXSfapNo5NuTKcL25apoGl4/GgGCiPJ73XnG/4uqdbpd143RgeWJc1HaMudoBqsANITuYPQOfdzSTKzrWb2kJltrW8zs7/09rnSswgBoI+RU6OheDVQTAnnut2qTZdbM7NpMyuph9PuvJGFi2a2uJrCQklB0/D40QwUQ5K5ziufUKovMOKdEJmTVK6PiHbOLYRt6+ZxJuXjY8eyDgEYaHFGENaHRVclTatWZLVhk/2wB3H1BTM7ZGYz165dyzoUADlGTlXHKScAii/hXHfZOVeV1PNpd96P8DHn3Njw8HCXYXa2vHdkQxs/moHiSDLXOedOeR1+p3rRlqabHnwwi7sFEEHkDkIz+zeqfQn7hnPubklW3+ac+7lz7u/M7OFeBllUzrlzzrmJbdv6fn0BADGRU2uunjmbdQgAEpRwruv7aXcAioHvda2FWYwOQLbijCCsOuf+tuF6z1c4AoABQk6V9NnJk6H2ow4XUFiJ5bpBmHYHoDD4XtfCR4893nGfoBqsANITZxXj34bYpxzjuAAwiMipEVy/eFGbb70l6zAARJdormuYMrfQi7YsBU3D40czUBh8r2vhd++803GfoBqsANITZwThbt91a7pidqekHXEDAoABQ06NgDpcQGGR60IKmobHj2agMMh1XQiqwQogPXE6CBfM7E0z+ytvVSYn1ZKdV3NhXtK/62WQRcUiJQBCSDynmtmomVXMrNLQVjGzcTObiNqWhDteeSXJwwPIHt8fQwqahsePZqAwyHUACityB6G3dPvfSnpN0lVJs2b2J0mXJY1J+r5z7h97GmVBsUgJgE5SyqlPe3W2hsysXO8orNfa8joAQ7V1GUdLW/btS+rQAHKA74/hhZmGByCfyHWtjby/nHUIADqIM4JQXlHnPZLuk3RE0vclDTnnjjrnrvQyQADod0nmVG/k33kzK3uF+1e8+1nxdlmRNBqhbcPxzWzRzBZXV1djx3npwIFQ+1GHCyguvj/Gt3nnzvWRhR899riW947o0kPfyzgqAEHIdcGunjnbcZ+gGqwA0hNnkZJ1zrklSUs9igUABlpCObVeC2fNzKYlnZBU8u1zc4S2Js65GUkzkjQ2Npb4Sn3U4QKKj++P0e15+631v+s1Cpl2DOQbua7ZZydPdvweF1SDFUB6Yo0grDOzrWb2kHfZ2qugAGAQJZhTLzvnqpIuSJqQVJU05NsnbFum+EEMFB/fH9sLOw2P6XpAvpHroguqwQogPbE6CL0iq3+v2o/HBe9y1SvISvIDgAgSzqnnG/4uefdxXjdGB5ZVK5gdti0RpcOHkzo0gJzg+2M4YabhRdkPQLrIdfFRgxXIVuQOQjO7S9KcpFnVpq5t9y57JL0l6S0SHwCEk3RO9RYnKdUXGPHqEM5JKnttJa9WTqi2Lh5qW7e/8HxShwaQA3x/DO+zkyd7uh+A9JDrWrvjlVeyDgFAB3FqEE4458YC2q9JOmVmM5Ke9i4DzcwOSTq0Z8+erEMBkF+J51Tn3Cnvz4VetCXhysOP6K43Xu+4H8WrgcLi+yOAQUCua2HLvn1ZhwCggzhTjBfbbfTqXLXdZ1A458455ya2bduWdSgA8oucKun6e++F2o/i1UBhkesADAJyXQuXDhzouA+1VYFsxekgvNqjfQAA5NRIKF4NFBa5LqSw0/CYrgfkErmuC9RWBbIVp4Nwe4/2AQCQUyVJm4aHQ+1H8WqgsMh1IYWdhsd0PSCXyHVdoLYqkK22NQjN7C8Dmq+a2RlJZ1RbmalRWbVC9n/Xk+gAoI+QU1u7+2c/zToEAD1CruvOpQMHQk2zC7sfgGSQ66IpHT6cdQgAOui0SMnbkpyCh0Hvb3UjM9OgJj4AaIOc2sLqSy9r+Kknsw4DQG+Q6wAMAnJdBLe/8HzWIQDooFMH4aJz7vupRAIA/Y+c2sLnp0+H6iBktAxQCOQ6AIOAXBfBlYcf0V1vvN52H2qrAtnqVIPwRJyDmtnWOLcDgD5HTu0SxauBQiDXdSHsNDym6wGZI9dFcP299zruQ21VIFttOwidcz+PedypmLfrK2Z2yMxmrl27lnUoAHKAnNo9ilcD+Ueu607YaXhM1wOyRa7rvUsHDmQdAjDQOk0xDmRm/0rSwRabS5LGJD0eM6a+4Zw7J+nc2NjYo1nHAiC/yKnSnXNzWYcAIGHkunDCTMOLsh+AdJHrgm0aHs46BAAdRO4gNLP/TdKopCVJvw3Y5WbVVmgCAHRATgUwCMh14YWZhhdlPwDpIde1dvfPfpp1CAA6iDOC8LedirGaWcxwAGDgkFMlfViphFqAhOLVQGGR6wAMAnJdC6svvdxxQTpqqwLZ6rRISZDLnXZwzv1NjOMCwCAip0ZA8WqgsMh1IYWdhsd0PSCXyHUtfH76dMd9qK0KZCtOB+HNnXYws4diHBcABhE5NQKKVwOFRa4LKew0PKbrAblEruvClYcfyToEYKBF7iB0zr1mZg95l1ZLtE92GReAlNX/Q/70mWe1vHdk/fLVr3+jL97+SVPb1TNnJamp7aPHarWWP3rs8aZ2tEdOrdnxxBNZhwAgQeS68FZfermn+wFID7muO9RWBbIVZ5GSOyX9jaRxSS6ghoJJcl1HBiBV9ZUQb3/h+Q3D+zffektgfbigtu+++qOm61fPnNX2o0d6GGl/IafWdKpJA6DYyHXhfX76dKicGHY/AOkh17V259xc1iEA6CDOIiWnJM1KOiGpGrDdJL3aRUwA+shnJ0/SQdgeOVXSB/c/EGq6HMWrgcIi1wEYBOS6LlBbFchWnA7Ceefca+12MLPpmPEAwKAhp0r6enU11H4UrwYKi1wHYBCQ61r4sFIJnH3UiNqqQLbiLFKy1mkH59zrMY4LAIOInBoBxauBwiLXhRR2Gh7T9YBcItd1gdqqQLbidBBWvdoKLZnZD+OF01/M7JCZzVy7di3rUIDM3PHKK1mHkHfkVElb7rkn1H4UrwYKi1wHYBCQ67rw+enTWYcADLQ4U4ydpIqZ7ZZ0QcFnSY5K+rtuAusHzrlzks6NjY09mnUsQFa27NuXdQh5R07VjUVyAPQtcl1IYabhRdkPQKrIdS3seOKJrEMA0EGcDsL6fIY1SfcFbC9JuituQAD6y6UDB/gB0x45VdKnzzwbqr4gxauBwiLXARgE5LoWWHUdyL84HYSLzrnvt9vBzFiZCQDCIadKqs7OhuogpHg1UFjkOgCDgFzXwgf3P9Dxexy1VYFsxalBOBlin6kYxwWAQUROjYDi1UBhketCCjsNj+l6QC6R61r4enU16xAAdBC5g9A5dyXEbgM5bBrARqXDh7MOIdfIqdFQvBooJnJdeGGn4TFdD8gfcl13PqxUsg4BGGhxRhC2ZWZbNaBnRQBsFGbaKFoblJy65913sw4BQIYGJdeF8cH9D/R0PwD50atcZ2ZTDX9XzGzczCaitqVpyz33ZHG3ACKI3EFoZv9kZn9qdZF0VdJo70MFUERXHn4k6xByjZxac/3ixaxDAJAgcl14YafhMV0PyJ80cp2ZjUsqe39XJMk5t1DfFratmxjiuOuN19O+SwARxVmkZEnSo5KqvvaSpN2qDZmmuihQIDu/vVP3/vjeRI49fMDp7USO3DfIqZI+PnYs1GrXFK8GCiuVXGdmU865E97fFe/+ys65mShtABBTornOzMqSVhqa7pN0xvt7RbXOx5tDti3EjSOOT595tuPMImqrAtmK00H4onPu5y22/VySzOxhSWHqLwDIgTcrbyZ27KQ6HvsIORXAIEg817UaVWNmE962Upi2+gibrISdhsd0PSCXks51ZS9f1a+XfNtvjtDWxJt6PCFJu3btihlea9XZ2Y4dhNRWBbIVZ5ESxgYDQI+QU6OheDVQTEnnuhajaurX66NlwralannvyPrl02eeDT0Nj+l6QP4kmetanMCoShqK2dbEOTfjnBtzzo0NDw93EWl81FYFshVnBGEY5YSOCwCDqO9z6m3PPZd1CACy102uK+yomj3vvqvNt94S+XZhpusByKW4uW6tYeRz2cxGJZ3XjTxWljTvXQ/TljvUVgWyFbmD0BsS3cqQarUVSnEDAoBBQk6t2X70SNYhAEhQkrkujVE1kmYkaWxszMWJsZ3rFy/G6iAMM10PQLqSzHXOuSXvPiZ0ozzCnJkdr3ccNixCEqotTXvefTftuwQQUZwRhP/e+3elxfZ5SX8TLxwAGDjkVNWm2IVZpITi1UBhJZnrCj2qJuwiTQAKIfHvdY0nLbzrp7w/F6K2pSnMyRBqqwLZitNBuOic+37PIwGAwZRaTu2H1T0pXg0UVmK5ruijagD0FX4rtxDmZAi1VYFsRV6kRNJkz6NIiJmVvC99Uy22Hzezirdq3USI40XaHwBCSCWntlrds74tbFsasbZD8WqgsBLPdV6B/d31DkPn3Cnn3ELDqJnQbUXAdD0glwrzWzmPPn3m2axDAAZanFWMOy7JbmYPxQund7wfsuNqUefB6zRccc7NeaNidtd/DLc4XqT9ASCMNHJqkqt7eidMFs1scbWLwtI3PfhgqP0oXg0UU1G+P2Yh7iJN1y9e7HEkALpFrutOdXY26xCAgRZnBGEYmZ858c4Ez6k2NS7IhLe97ozaxx11fwDolW5zTdk519hBWPJtj726pzdiZ8w5NzY8PBw7wO+++qPYtwXQNwbye1XcRZo+Pnasx5EASMlA5rq4J0MApCdyB6GZbTWzvzezP7W4/JOkXI+s84pX+1VVG3HY9f4AEFbSOTXp1T175aPHHg+1H8WrgWLqh++PSVneO5J1CAB6hFzXWtyTIQDSE3cV41lJJxQ8Os8kvdpFTGkYkrTma/Nf72b/eqHsCUnatWtX1PgADI6kc2ohVvf83TvvhNqP4tVAYfXD90cA6IRc18Ly3pGOi5RQWxXIVpwOwnnn3GvtdjCz6ZjxpKXUaoOZlZxz1S73b1p+fmxszMUJEsBASDSn9tvqnp8+86xuf+H5rMMAEF0/fH/MFabrAblEruvC9YsXtfnWW7IOAxhYcWoQth05J0nOubwP8ahq47S5dtPoou4PAGGlklP7ZXVPilcDhdUP3x8TEXaRJj+m6wG5RK7rArVVgWzF6SCsmtmd7XYwsx/GCyc1a9o4KrAkSUGjAWPsL0kys0NmNnPt2rVYQQIYCP2QU7vWacoJgMIj17UQd5EmahcCuUSuayHuyRAA6YkzxdhJqpjZbkkXFHyW5Kikv+smsCQ555bMrOprHpIUOH0u6v4Ntzsn6dzY2NijMUMF0P8Kn1N74eqZs4yGAfobua6Fjx57nJXcgf5BrmuBPAfkX5wOwjnv3zVJ9wVsL0m6K25AKTprZhXnXP3xHJS0Xg/CzMqSRhu2t90fAGLql5zalc9OngzVQUjxaqCwyHUthF2kCUAhkOtaCHMyhNqqQLbidBAuOue+324HM8t8ZSZvpc5xecvIm9lxSQsN9bcmG4rvlyVdbuj8k3e7g/KSfIj9g2I4JOnQnj17evzoAPSRQuTUvKB4NVBY5LoeY7oekEvkuhbCnAzZfvRIU/mEmx58kJGHQIridBBOhthnKsZxe8rrCFyS1LKwfrui+962UwFtUWJgijGATgqRU/Pi42PHqFcIFBO5rsf40QzkErmuS3zPA7ITeZES59yVXuwDACCn1t3xyitZhwAgQeS61uL+GP7oscd7HAmAbpHreos8B6QrzirGAAD01JZ9+7IOAQAycfXM2Vi3o3YhgCKJczKEPAekiw7CBJnZITObuXbtWtahAECuXTpwINR+FK8G0G8+O3ky6xAAIHFxT4YASA8dhAlyzp1zzk1s27Yt61AAoC+EWekYAAAA+cLJECD/6CAEABRG48p2ADDIKOQPoN+R54B00UEIAMhc6fDhrEMAgEzEXaSJ6XoA+h15DkgXHYQJogYhAIRz+wvPZx0CAGQi7iJNTNcDUCRxToaQ54B00UGYIGoQAkA4Vx5+JNR+Nz34YLKBAEDKwi7SBABFFvdkCID00EEIAMjc9ffeC7Xfd1/9UcKRAAAAoNc4GQLkHx2EAIDC+Oixx7MOAQByIW7tQgAoCvIckC46CAEAmds0PBxqv9+9806ygQBAyuIu0sR0PQD9jjwHpIsOQgBA5u7+2U+zDgEAMhF3kSam6wEokjgnQ8hzQLo2ZR1APzOzQ5IO7dmzJ+tQgMwMV53u/fG9vT/u776ht5/4Tz0/LrKx+tLLGn7qydD7Xz1zVp+dPKnNO3dqz9tvJRgZACTrysOP6K43Xs86DABIVNyTIQDSQwdhgpxz5ySdGxsbezTrWICsvP2vf5nIcZPodER2Pj99OlQH4cj7y5Kk7UePaPvRI1reO5J0aACQqLCLNAFAkXEyBMg/phgDAAqL4tUABlXc2oUAkIU4J0PIc0C66CAEABQWxasBFF3YRZr8mK4HoN+R54B00UEIAMjcnXNzsW5H8WoARRd3kaYrDz/S40gAIDlxToaQ54B00UEIAAAAZGT1pZdj3Y7ahQCKJM7JEPIckC46CBNkZofMbObatWtZhwIAufZhpZJ1CACQic9Pn846BABIXNyTIQDSQwdhgpxz55xzE9u2bcs6FADoSxSvBjCo6tP1Vl96Wct7R3Tpoe9lHBEAtBbnZEjcGq0A4qGDEABQWBSvBjCo6tP1hp96UiPvL+urTz7JOCIA6K24NVoBxEMHIQAgczueeCLW7SheDaDo4i7SlNRxACAvmJYMpIsOQgBA5oafejLW7SheDQAAkH9xTmJQoxVIFx2EAIDMfXD/A1mHAACZ6NUiTSz2BPQ3MyuZ2aiZVcxsqqG9YmbjZjYRtQ0AGtFBCADI3Nerq7FuR/FqAPxoBjAgjkgac87NSZKZTZhZRZKccwte23jYtrSD5yQGkH90EAIACovi1QBU8B/NABCGc27GOTfjXS1LWpF0n/evvH9HI7TlHrVVgXTRQZggMztkZjPXrl3LOhQAyLUt99wT63YUrwZQ9B/NcRdpSuo4APLNzMqS1rwTGyXf5psjtPmPO2Fmi2a2uBpzZgeAYqODMEHOuXPOuYlt27ZlHQqAAVWUqXd3vfF6rNtRvBpAXVF/NMddpCmp4wDIvYpzbtL7uyppyLc9bFsT72TLmHNubDiBEi5xTmIwLRlIFx2EANDfCjH17tNnnk3q0AAGRyF/NPdqkSYWewL6n5lVnHOnvL9HJZ3XjRMdZUnzEdpSxUkMIP/oIASAPlaUqXfV2dmkDg1gABT5R3PcRZqSOg6AfPJO1E6Z2QUzuyBpyDsBXPa2lZxzC2Hb0o6fkxhA/m3KOgAAQPIap96Z2WHf5q6m3kmakKRdu3b1JNYoKF4NoOFH89Ne0wnn3JyZHff/GA7bBgB54+Wn3QHtp7w/F6K2pSnOSQxqqwLpooMQAAZDYlPvJM1I0tjYmOs2SACIqug/muMu0pTUcQAgL5iWDKSLKcYA0OeKMPVuz7vvxrodxasBFF3cRZqSOg4AJCHOSQymJQPpooMQAPpYUerVXL94MalDA0Cu9WqRJhZ7ApBncU5iUFsVSBcdhADQx7yOvt3Ouf3eZcFrP+VtO9Wwb6i2JHx87FiShweA3OrVIk0s9gQgzziJAeQfHYQAgMKieDUAAED+xTmJQW1VIF10EAIACovi1QAAAP2J2qpAuuggTJCZHTKzmWvXrmUdCtCXlveOrF+unjm7oe2jxx6XJH302ONN7ZJ09czZprYv3v6Jvvr1b7S8d0SXHvpeZo9pUN323HOxbkfxagBFF3eRpqSOAwB5wbRkIF2bsg6gnznnzkk6NzY29mjWsQD9aOT95VBt3331Rxvath89ou1HjwTevt6JiPQEvRZhULwaQNFdv3hRm2+9JTfHAYAkxDmJ8fv/5/9Z/16+5913df3iRf363/5b7Xn7rV6HB0CMIASADUqHD2cdwsChUxbAoOrVIk0s9gQgz65fvBj5Nnvefksj7y9r5P1lbb71Fn3nob/SV598kkB0ACQ6CAFgg9tfeD7rEBASxasBAADyj5MYQP7RQQgAPlcefiTrEBASxasBoGbzzp0b6vFSUxdAv4lbtxpAZ3QQAoDP9ffeyzqEgXPTgw/Guh3FqwEUXa9+7O55+631eq71KXnf+m//254cGwDyIm7dagCd0UEIAMhc0EIyYdSLVy/vHdFXv/6Nvnj7J4yYAVAoSf7YjZtbAaDXenUyhLrVQHLoIAQAn03Dw1mHMHA+euzxWLejeDWAokvyx27c3AoAvcbIPyD/6CAEAJ+7f/bTrEMYOL97552sQwCAvkNuBZAXjPwD8o8OQgDwWX3p5axDQBcoXg0AANCf4tatBtAZHYQA4PP56dNZh4AuMIUFQJHwYxcAwqO2KpAcOggBAJkbeX+5Z8diCguAIknyx24vcysAdKNXJ0OorQokhw5CAEDmrp45m3UIAJCJJH/sklsB5EWvTob88T//Zy3vHVk/IXz1zFldeuh7PTk2MOjoIAQAnzvn5rIOYeB8dvJk1iEAQCaSXEiE3AogL3p1MmTP229p5P3l9RHS248e0VeffNKTYwODjg5CAEBfoZ4XANRs3rlTy3tH9MXbP9FXv/6NlveOMNIGQCZYVR3Iv01ZB5AlMytJmpB0s3PuRIj9j0takTQkSc65mUQDBJCJDysV6jYVGMWrAaBmz9tvNV0feX+ZOq0A+s4dr7ySdQhAXxjYEYRmNi5pXNJuSaUQ+09JWnHOzXkdg7vNrJJslAAwGHr5xY7i1QCKJO0TUqXDh1O9PwBI2pZ9+7IOAegLA9tB6JxbcM7NSaqGvMmEt3/dGUmTPQ8MAAZQL7/YMYUFQJGkvZDI7S88n+r9AYCU7MmQSwcOJHZsYJAMbAdhFGY2GtBcVW0EIoA+s+OJJ7IOYeDwxQ7AoEp7IZErDz+S6v0BgMSq6kAR0EEYzpCkNV+b/zqAPjH81JNZhwAAQCKuv/de1iEAGEBJngzZvHOnPn3mWUm1kyAsxgTEM9CLlERQarXBzErOuWpA+4RqC6Bo165diQUGDKqd396pe398byLHHv7iG3r7yf+UyLGRPBaYAYDWNu/cqQ/uf0B3/+ynWn3pZV37D/9hw2ImAFAkjTnsrjdeZzEmICY6CMOpylu5uIH/ehNvIZMZSRobG3PJhAUMrjcrbyZ27KQ6HtFaL4vmXz1ztuks9R2vvKIt+/Zp86239Ow+AKBX0l59s/GH9PBTT+rz06dTvX8ASNqm4eGsQwAKiQ7CcNa0cRRhSZKCRg/WmdkhSYf27NmTVFwA0Bd6WTR/+9Ej2n70SFPb8t4RRhYCyCVW3wQwCNI8GXL3z36a2n0B/YQahCE455a0cbXjIUkLHW53zjk3sW3btqRCA4C+QNF8AIMq60Wa7pyb05e/vKjlvSPrl9WXXs40JgD9J82TIasvvdyU07785UV9+cuLqd0/UFSMIGzBzMqSRp1zc17TWTOrNFw/KGk6m+gAoL9QNB8AsvHn/6L2o51R1gCSdOnAgdTyzPBTT25YdJDZJEBnAzuC0MxGzey4pIqkcTM7bmajDbtUJE3WrzjnJiWVzWzcW4DkckNnIQAgx+o1Dq88/IiW946wuh0AtPHB/Q9kHQIAAEjZwHYQOueWnHOnnHO7vcspbypxffsp59xB321OOecWnHMz3iIkbZnZITObuXbtWhIPAQD6RtLFpOs1Du9643WNvL8s99VXid4fAITVy0WaesU2b9by3pH18g+fPvNsxhEBQHc279y5Xj7hg/sf4GQxEIApxglyzp2TdG5sbOzRrGMBgDxLu5g0xasB5EUvF2nqlcaVjiWpOjubyzgBFEfWJ0Ma89rdP/uplveOZBgNkE8DO4IQAJAfaRfEp3g1gLwowiJNm3fu1PLeEX3169/oi7d/QqkGAJHl7STDlnvukVQbId34nRAYZHQQJogpxgAQzuenT6d6f8NPPamR95fXL3/+L/bpw0plwwqeH9z/wHpbEX7EAyieIizStOfttzTy/rI233qLvvPQX60X+r965qwkNf24/uixxyVJHz32OJ2IANbl7XvUXW+8LqnWcVn/Prjn3XfXT4LUL/U8BwwCphgniCnGAIrOzCqSqpLKYWqvFlnQynb+qcifPvOsqrOz69f3vPuurl+8qO889FeJxwcgGYOU53qpcbpeUP787qs/0qWHvre+cujVM2f12cmT2rxz54YpzACSl3WuK8LJkM233qLNt96yIac1jiy86cEH9d1Xf6SPHntcv3vnnfV2VkhGP6CDEAAQyPsiKefcgplNmNm4c24h67iydPsLz2+YIvNf/qf/SR8fOyZJuu2557T96JHAL5IA8icPeS7pRZqy1NgRuP3oEW0/ekSXHvqevnj7J9qyb58uHTiwvr10+LBuf+F5XXn4kfWOhE3Dw7r7Zz/V6ksvN400v3NuTpL0YaWy3rbjiSc0/NSTST8koJDykOuKrNVJkEb1kyB1d7zySlOe4+QIioAOQgBAK/dJOuP9vSJpVFIiXybrP/aKKOjLnv+LZNBZ5k5fJKVwP5j5wgl0JbU818qgLZrUaeRhfdpfo+Gnngzs/PPf/oP7H9DXq6uSavXF7nrj9ZYjv+sndqT2J3eSyN9ABjLPdf18MkS6cRLEr56n6qvBd3sSJK08h8FkzrmsY+h7ZrYq6b/4mndI+jyDcIIQS7A8xSLlKx5iueGfOef68huPmU1LmnbOLZnZuKSDzrkTvn0mJE14V/+5pP8v5OGzft3iIOZ0FDFmqZhxR4m5L3NdwnlO6v/3RV4QczqKGLNEruM7XbAixk3M6RiEmANzHSMIUxD0xJvZonNuLIt4/IglWJ5ikfIVD7EMjKqkoXY7eDVsItexKeLrRszpKGLMUjHjLmLMCagqoTwnFfM5JuZ0EHN6ihp3j1XFd7omRYybmNMxyDGzijEAoJXzkkre32VJ89mFAgCJIM8BGATkOgAd0UEIAAjknJuTVPamopQoZg2g35DnAAwCch2AMJhinJ3Ul5Zvg1iC5SkWKV/xEMuAcM6d8v7s9RfJIr5uxJyOIsYsFTPuIsbccwnmOamYzzExp4OY01PUuHuK73QbFDFuYk7HwMbMIiUAAAAAAADAAGOKMQAAAAAAADDAmGIMAEiUmVVUWz2v7K2QF2l7FtrFZGYl1Qp8lyXd55w7kXqAAcI+j2Y2VZSYzWxUtee5Xj8pcwV+P0865w622V5VjmIumgK/L6oqUJ6TyHVpKfB7mlyXoAK/L6oqUK4rYp6TyHVpSTLXMYKwh8ysZGbHvcusmU0E7HPczCpmNhG0vdv928Q0FbBt1szGzazs7bd+aXGsCTOb9m4z7v1d7lEskY/dzXPTIZaOr2O3sYeNxdue6num4Tipvj86xJLq+wO94/0HpXoxbK84dujtWQgR0xFJY/UvNnl4f4V9Hr32nnwuuxUy5qe953moV/mkGyHez+OSVrztK94X4cy1+xKex89g0ZDn0kOuSwe5DkHIdekoYp6TyHVpSjLX0UHYW0875055l8OSTjQmGa8DaMU5N+f15O6uv4BBou4fcPtxSeOSduvGsvaNRlVb4v6ypKsNl3ZvoiPebaYkTTvnVnoUS6Rjd/PchIil7evYbexRYkn7PeOT2vsjpFTeH+i5+yTVX6sV1d5XUbZnoW1MzrmZhrNx5YZ9s9TxefS+iOUh1rq2MXt597yZlb3nPA+xd3qeFyXNel8gy865pTSDiymPn8GiIc+lh1yXDnIdgpDr0lHEPCeR6/Kiq88hHYQ9YjeGJzealtQ45HfC19t7RtJkm8NG3b+Jc27Bu321xS7TzjlrvEg60a5H2jm33dt3f5QPSIhYoh479nPTLpaQr2PQMZN6XlJ9z/ik9v4II633B3qu5Lt+c8TtWSj5rgfG5H05W6ufoctYyXc9KOZyTr6M1ZV81/0x7/ba1rxRw/79s1DyXW+K2TlXVe3/jFlJ+9MJqWsl3/U8fAaLpuS7Tp5LTsl3nVyXjJLvOrkOErkuLSXf9SLkOYlclxcl3/VIn0M6CHtr3DdUtiqvs6nFcNSqWozGirp/TP4aDMedc6d6ePxEpPDctHwd05SD9wzvD/RCVdJQF9uzUFW4mCrOubx0PFfVJmYzG8/Jl95GVXV+ni97X84uSMp82o9CPM+SFpxzuyVVCzJyuar8fQaLpiryXFqqIteloSpyHTaqilyXhqqKl+ckcl1eVNXF55BFSnrEe6Nv9zUflFT/8A5JWvNt919vFHX/yLyYJd1483e6jTc0eM2LT66HhTojHDux5ybE6xgooecl0/cM7w/0yHndOJNVVm2aeJTtWegYk5lV6h3mZjaagykHnWJe8z7HJUnlgsR8Xje+4JTUZgR6ijrFPNpwIuVF1Uoj5F0eP4NFQ55LD7kuHeQ6BCHXpaOIeU4i1+VFV59DRhAmxBsyO64bU1NLHfb1i7p/tw6HSCyLqvWg1+u6HexhL3qUY5daHaTXz03A6xgkqeel1CGubvePgvcHYvGmepfrX2TcjYK58+22Z6lTzF77lJldMLMLysHZ8hDP85LXNqQ2n5E0hXxvlOrFlXt5wiGuTjFLmrHawkjjko7kIWZp/T071pg38/wZLBryXHrIdekg1yEIuS4dRcxzErkuTUnmOnPO9TRY1JjZrGo13BpXj5l1zm1v2Kes2gIQ2xtHa8XZv0MsU6q9OQKHTXtvrKGob3gzOy7pqHMu9Hz8TrGEOXavnpswsfhfx5DH7cnzkuV7xnfc1N4fvTh2Us8DAAAAAAD9ihGEMZjZvJldbrj4l8M+ro2dSmva2MNfkpqncsbZv1M8IUwqxCpIAccNWp0oVixhjt0g1HPT7fPS4nUM2i+p5yWx90zE2Hr2/ghxjMBYknh/AAAAAACAGmoQxuCcO9hqmzfaqj7sd72IqHNuycyqvt2H1KKuW5T928UTUqcptPURWPNm5h+B1dRxFCeWsMduuI9Qz003z0ur1zFu7HFiSfI9EzG2nr0/OgmKJan3BwAAAAAAqGEEYQ95o5yGJC2aWcnr2Ggc5XTWmuumHVRt2ez67cu+7W3371HMJe/PasC29XhcbRn1E74OmqOSprqNIcyx03xuOr2OaT0vnkzfM7w/AAAAAADof9Qg7BGvI+VqwKY559zhhv2OS1pSbUWZpuKc3raDjaOo2u0fIqZR1UZ/1evaTau20MNSwz4l1ZYZ3x8wdbkpHq+jrN7pcrNqy5SHiqdTLJ2O3cvnpl0sYV7HNJ+XTo+z1++ZgPhKSuH9ESKO1N4fAAAAAAAMGjoIAQAAAAAAgAHGFGMAQGGY2ZSZXTAz5/073XCZ9S6RFsfpMp4JL46rvvayF0upx/eXyHFD3veUt5DQ+nMfsM+smV31LgMxrT/L1wQIyyuZctVbAGy2IW9e8NqD2npVLiVsjGUvx1wNWJys1W3ISwHISygK77067X2W65eyt20io3gi5aE0JPGZJn8GG/T8yQhCAECheF8cL6s2rXwhYNu8aiuQn0opnlFJbznntvvbVJueH2mxHu8xlFssjBT7uL3Q7rlv2GdC0kqnFeDzoN1zHeEYXb8mvYgDaMd7j81K+l5jyRCvHMeUc858+0+o9p6eVEi9eh+b2WVJk2GPQ14KPAZ5CbnnvcemJR325aUJ1eqHrzjnTvj2T+U9GTUP9eg+U//+R/4MPMZA509WMQYAFNWav8E5t2JmJyTNmllTPc8EVQPiWJK0feOuoZRbbejyuGlZUcQVzDPU8rkOq0evSddxAB2UJL3oryfcinNuJsZokV69j6s9Ok4j8lIGcQAdTGvjQoT1/HMwYP8035PVFO+rLq/f/8ifGcSRFaYYAwD6Tf1sXW6mhkR0uPMu6JG8PNd5iQP9a0i1hbuiuBBxf97HvZGX5zEvcaB/jal1x9OLAW39/p7s98eXhrw8h3mJIzI6CAEA/ermrAOIyqt3k3rNnUGUl+c6L3Gg75ViTJXaMEq7Fd7HvZGX5zEvcWAgBJ7M9UZx/bZ+vd/fk/3++NKQl+cwL3HExRRjdMXMylnUwQLqeA8iwJj37xlpvZbIa6oN9/+e9++QajVv1qewePuNq3Y2e0i1H9Qb6hh6hfsvq/bjeUjSom97SbVaX2PefSz4tj3t3b7urHOuamYV1WruSNIJM6uffZzypk5vOK5XP2zSe0xzzrn1M5b12mKqjRo67B0j1GPspYYaQ2O6cUa15N3/QUmP+qcXtXueGvZp+Vg6veadnuuG+xj3brsm6T5J8wGvp/81Cf1428UhqaIIr62ANpxzc3Fv473PJ3Rjyl1J0kyY93GUz1OayEutHy95CSmakfSama0ElYRp+OyE/WyU1CZXNQrzefb2G1fn3NAxtzUcR96x1iTd55w7Eef7X9TH0Uvkz9aPty/yp3OOC5dYF0nHVfvgZh4Ll8G9qJZsx7OOg0uqr3lZkpM0GrCtpNqXj+MB267W85Z3uVrPYap9IZn37X9ctcVOGo99QbWiw437TUu6GnB/lxvfmw2x+W9/vN3tQhx31Hs+SgH7zjf83fExRnju28U37n+Mvue/3NA2ERBTx+cp7GNp95p3eq69xzrua7sgqdLpNYnyeNvFUX9tW8Q3G/Wzw4WL/+K9R12b7eUWn9F5f87p4efpQrsc0+LY5KWN+5KXuOT+4uUS572Ppzp8jjt9NsLmqjCf53o8nXJDx8+kt4//u15QvFG//3V8HCGef/In+bPpwhTjPmAZLMfurWa04BI8OxHHoC1L3uq1z+J5MLMJM7tgZlfTuk9pfYTDQe/sDgbLpJkdb7hMqXZ28bALHhW3Julm51zVu2xvyGHTqn0RXOcdY6Lhc/SaannPf1ZvtkV8Vd/111Q7Y+g/kzmlaJqO62pn3ZckHWlsbzjjWRfmMSZpTdJu3/O3qI3Ti8I8T2EfS7vXvJOKmp+/+v0GreoadMywj7cl77Vd8f7PXec9xqgLSABxTMv3XvM+Q7OqfVbDivJ5ShN5ibyEDLnaTI5J1d6bxyXVf9dEnaIZJVeF/T5WCvFZCfOZHNfG724ril4Xtuq73qvvlXGRP/swf9JB2Aeccytecg1dK6Yb3ht4v4u4OqjXaZV0B2ZJtQ/pUML3kwttXvuSAp6HJF8D59yMpEeTOHYILyq9/wyRH7POuVMNlxPOucMdctN5f4M3baEs31Rhz4puTFmuyJu27BM291ZUO5PdaFG9+YEc9AVn3N2YIhj2MSapqo2LHlQD9mv7PMV4LBte85DmtDGv1KeVh1FVuMfbSdBre8RlNDUTg8M7yTCuGws/NVqQVIlwcqHbz1NSqiIvVWPEQV5CzzjnZpxzB51zJmm/ap+jaW+6ZkcxclXY72NhPithPpP1x3PcF0e3HUJJfq8MoyryZzVGHLnOn9Qg7C/VlO5nSvE6YxIf4eWyXQI+S9XGK22eh6Rfg2rHPRLgavXbVsxsPC/JFblVDWirfy7Gzcy/7YSkRe/LS6vbd9Rw+6bRh95Zz5k4x/Q5q9qXz8aanKWG7R0fYw9iCKNtZ2rI5ynqY6lGDdK7z5X6fXpf6Muq1auJohcn7mYkTRn1VpG+UWn989fE1epiSbUfbh3/3+3R5ykp5KXoyEtIhPcb5qCZzar2ezNM/dTQuSri97GOn5Uwn0nn3JJXi+411T43K6pNnY1dAzqF75VhkT+jy3X+pIMQccR9Mx9W66l4SEc/vwb1oel0EKKdoP/Yq1L7Iv4NX1hSGantu+9Sp+kTXif5nGpnJE94I4UbH0/V2y/yQgW++6l/0S612a3VWeBeqXqxhH0sUVZibXquG4pNX1Att5xXhKkkcTXG4b22C6qdgT/lfdlOq0MXCBRm5GBanyfyEnkJxWRmx9t0kr2ojaO1/Lfv+P0ojRIqYT6TXm6Ya1iIY9LM7nMNC1UEHLfj4+sW+ZP86ccUY0Tifaj8Q4TD3K7Qy333g35/DbxO69GOOwIbLUrrU1QCNUxbjjUKt8vbH+m8i6RaJ3n9M+4/kdPxMUawovaPI/YX2pDPUy8fi9/6c+3VtJx0zk1605/SPMvrf80bp6OMRS3xAcS0JLX8gV2fktXuR02anyfyUvLIS+i1lqO3Qr6f6u/J0Lmq2+9zfmE+k1ZboVb1+/fK4uyWNNqhA7Pl978ePw7yZ/IKkz/pIOxzZlby6h1MeBd/7YP6fuWG/Y571+u3aZxOfFARC6p6nYr1syMnzGzau5S97aPmLW7h/V3x7nfed5xxr71iZlP+WnreY21asMN8i3h4l/rxIy/iESKGTvdXf8z1Y9QXVmg8xmjDMerPR33f9eetTYxBz0On16Ax7krDsSrea+Na3NdUw2OZUIuzT97jON7wXBz3bR9veJzrz2+7x9lC49QBIBTvS8+camfymnjv3fp7ak7BZxnDfqGZ043PYeN9lAPet6WQx1xXn15vATV7IjzGME6oRX0bL6dWIxwrSNvnqcePRWr9XB/XxnIaQ/X9LXoB9bhx1M+qD/n/zwGS1FBEP+hHakXBi9WVWhwu6c8TeUnkJRROpdXvGu8zEzQrqORviJGronwf6yTUZzLou5lqj89f/64U4b579TjInyJ/rnM5WEqZS28uqg2VbVz6PNRy795+l33XrzZe991HKWZ8nZZub7lsuVJclrxNfFFiaHl/AceYlzTR4hj+pd3LXrt/mfgLAccNeh7CvAYVX9uG5di91+dCQBzTje8dr63tsvXeYzru277hvRvyNTruPxaX/rt47w/X7r3c4nZXW92mngcD3tPHG/6uv+9Lvn2m/Z8Rr/1y4+fJu/1lSaOt7qPheFMN1/2fycv+toZtU425M+pjjPBcTrfIT1NtbrMh7vpr6Wvr+DyFfSztXvNOz7X3HvPHO1HPcb59gx5bqMcb5jVv2Ody0GvLhUvci5czXJvtZX/eU/vvAIl8nkI+FvISeYlLgS7eZ2Eq4HMVJ8dEyVVhPs9hc0PHz6Rqv08uBDz+2bCPLyimMI8jwmtB/iR/1uLKOgAuPXwxN3YQzrd4M040JqQWCeGCgjutLncRX6fOqcutkpCXWC/72gI7+PzPQ8Ox/Y9xQ8dXh/ijxNDy/gJim/L/B9FwjKDXb8p/ny0ec6hOw4DbhEn0s0GvlWqdgVfD3Kf3XJS85zDovdbyP6Q28Vf8zzuX/rp4n8N57/1zIcz7xHsPT3e6jfd+nPLuo9Li81ffp+JdJho+2/Pe3/7783+Zm/buYzzoPrz96tOFJ9o8jqD4ykH5JMpjjPBaVLxcUK//GfiFNCDu4w23r7+Ws2r+/6vj89TusYR9zVs91177qC+Gca+9vlDXeNBrEufxtovDF0/kEydcuARdvPfwtGo/tur5a9r/vvT2rX/WJrzLlFr8oOnx5ynOj1zyEnmJS0EuDe/DiYb38LR3Kbe4Tcv3ZMRcFfh5jvpZCfmZnPCOO6Eb3x+bBpK0e3xBn+lOjyPm60H+JH/KvODQB8zsgqQTzrkFb7j2ZUnbnW/6h3+bN5V3yTl3omGfeUkrzrlJ322vOudirRJsZpdVm/cfuIiEt/2ECyhQ6sU87pybaWirSHraObfft+/68+Brm/bdvj5ycsNySS3iixpD4P3J95p40203FKlt9Xx5w6wvNB6nzWP2t3V6DS5IerHxNQh6nrwpx/udr16CF9tb9fdIUKz+WFQrNHtBteHtMw2PKfJiON4w7Un/cwkARedN8xkP+j8SALJAXgKAePKaP1nFuH+FXu5dtcKkJd9uQ8pmtdtqUKPLwbLkMWIIvL+g1ySieqdZ/fVLVUMdiGqI3TsuW+91Uh+W9JpqS76vqNa52mpVs05KMW8HAHl2pPGkEwDkAHkJAOLJZf6kg3AA2caFOabV0BnY0Pl1NuDm/tt2FUdAZ1nLTjzLaFnyvMXQSy1eg7DCdLhWpc7L1nvb57zOx3FJk2a2YVRlSGmuSAUAiagXbo86khoAkkJeAoB4ipI/6SDsX+vLvQd0ADUt965ah8qct2rsZUm7VZs+6r+d1P0qRo2OyBuR14kX26hz7mBDW6qr1eYhBk99VN5i273CCfMalBqvOOeWvNGAZXVe0Xp92fpWydDMjtdHC3pTlpcknTKzyzE6MEvq7XsUALIypdqJmEmvfELQSTsASBN5CQDiKUT+/EbWASAZLtpy7xPOuRPeZcb7t1XP9lrACMQo4t427WXJ8xJDKaBtUs2vXy+O2WjId70csM+cgkdONu3rQi5b743M9FsIiKWTsqTfRrwNAOTRi5Lm6/mxB+UpAKBb5CUAiKcQ+ZMOwv5SUnPnz2HVeqjX27y/j6rWyVS34i2UEcaCarXv4lhQc80+/xTVIbXvECoFtNX3X/Pt59836LZxRIkhrJvb7H+08UrDFFz/1NtSwDGC2jq9BguqjSBtVPbuu/FYj0o6GtBZfDDgPk+o9j70dzSONyxy8rQ2GooxBHu3Oo9qBIDcc84tOefmvEvq9WYBwI+8BADxFCV/sopxH/A6Xk6otoz2kqQz9SmbXgfO06pNHZZqHSgvtlhRtrEDpz4C8VHfirsV1ZZkj7WAhJlNq1a/T/WinAHxLzSuqOztM6pap+Zlbx95qzXXR/TNezE3HudF798Nz433OCZV62ybU21RjLYf1JgxtL0/77YV1ToZz6q26nDVu7/6Kr8l7/hDkvb79tnw2nvHb3oefKsSb3gNGraVVBsleVk3avktNTzm9VWRG95b5xviW9SN+own6h2ADfv+tn7cekzeyMsF77mpd1iWJc3FWMX4gn9FaQAAAAAA0B4dhKh3GE03jOaqd+hMqNapc5evk3C+sQ4fklHvIMzzGYY88d6zr8Vc2AQAAAAAgIHFFOMB500tvtzYOSjV5sR7owTPamMdw5WA6aJA1iZUW5EbAAAAAABEQAchpParvl4OaDvhXYBc8EYP3sdoSwAAAAAAoqODEDOSDgetTOyNEjwo3xLc3nTjC/UVaJGY9RWS0dHTotMaAAAAAIBYqEGIxnqDVd1YJGJIUqndYiTe9OSZvC7RXVRex2x98ZKmRWewkZmNS7UFY7KOBQAAAACAIqKDEF0xs3LUlWaBXuI9CAAAAABAd+ggBAAAAAAAAAYYNQgBAAAAAACAAUYHIQAAAAAAADDA6CAEAAAAAAAABhgdhAAAAAAAAMAAo4MQAAAAAAAAGGD/P2I5Q61/pG1fAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots( 1, 4, figsize=(18,5) )\n",
    "\n",
    "c1 = 'tab:red'\n",
    "c2 = 'tab:green'\n",
    "\n",
    "(n1, bins, patches1 ) = axs[0].hist( trn_ampl, histtype='stepfilled', fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "(n2, bins, patches2 ) = axs[0].hist( pred_trn_ampls, histtype='stepfilled', fill=None, edgecolor=c2, label=\"train preds\", bins=bins )\n",
    "\n",
    "bins= np.linspace(0, 1., 50)\n",
    "(n3, bins, patches3 ) = axs[1].hist( pred_trn_ampls_std, bins=bins, histtype='stepfilled', fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "(n4, bins, patches4 ) = axs[2].hist( pred_trn_ampls_std_tot, bins=bins, histtype='stepfilled', fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "(n5, bins, patches5 ) = axs[3].hist( pred_trn_ampls_std_stoch, bins=bins, histtype='stepfilled', fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "\n",
    "axs[0].set_yscale( 'log' )\n",
    "axs[0].set_xlabel( \"log( train amplitudes )\", fontproperties=axislabelfont )\n",
    "axs[0].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "xticks = axs[0].get_xticks()\n",
    "axs[0].set_xticklabels( xticks, fontproperties=tickfont )\n",
    "yticks = axs[0].get_yticks()\n",
    "axs[0].set_yticklabels( yticks, fontproperties=tickfont )\n",
    "axs[0].legend( loc='best', prop=tickfont )\n",
    "\n",
    "axs[1].set_xlabel( \"Predictive Uncertainty\", fontproperties=axislabelfont )\n",
    "axs[1].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "axs[1].legend( loc='best', prop=tickfont )\n",
    "\n",
    "axs[2].set_xlabel( \"Total Uncertainty \", fontproperties=axislabelfont )\n",
    "axs[2].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "axs[2].legend( loc='best', prop=tickfont )\n",
    "\n",
    "axs[3].set_xlabel( \"Stochastic Uncertainty\", fontproperties=axislabelfont )\n",
    "axs[3].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "axs[3].legend( loc='best', prop=tickfont )\n",
    "\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots( 1, 4, figsize=(20,5) )\n",
    "\n",
    "c1 = 'tab:red'\n",
    "c2 = 'tab:green'\n",
    "\n",
    "n_bins = 50\n",
    "bins = np.linspace(-5, 5, n_bins)\n",
    "\n",
    "pull = (trn_ampl - pred_trn_ampls) / trn_ampl\n",
    "pull_normalized_tot = (trn_ampl - pred_trn_ampls) / pred_val_ampls_std_tot\n",
    "pull_normalized_stoch = (trn_ampl - pred_trn_ampls) / pred_val_ampls_std_stoch\n",
    "pull_normalized = (trn_ampl - pred_trn_ampls) / pred_val_ampls_std\n",
    "\n",
    "\n",
    "(n1, bins1, patches1 ) = axs[0].hist( pull, histtype='stepfilled', bins=n_bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "(n2, bins2, patches2 ) = axs[1].hist( pull_normalized_tot, histtype='stepfilled', bins=np.linspace(-5, 5, n_bins), fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "(n3, bins3, patches3 ) = axs[2].hist( pull_normalized_stoch, histtype='stepfilled', bins=np.linspace(-5, 5, n_bins), fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "(n4, bins4, patches4 ) = axs[3].hist( pull_normalized, histtype='stepfilled', bins=n_bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "\n",
    "#axs[0].set_yscale( 'log' )\n",
    "axs[0].set_xlabel( \"Pull\", fontproperties=axislabelfont )\n",
    "axs[0].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "#xticks = axs[0].get_xticks()\n",
    "#axs[0].set_xticklabels( xticks, fontproperties=tickfont )\n",
    "#yticks = axs[0].get_yticks()\n",
    "#axs[0].set_yticklabels( yticks, fontproperties=tickfont )\n",
    "axs[0].legend( loc='best', prop=tickfont )\n",
    "\n",
    "#axs[1].set_yscale( 'log' )\n",
    "axs[1].set_xlabel( \"Pull total unc\", fontproperties=axislabelfont )\n",
    "axs[1].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "#xticks = axs[1].get_xticks()\n",
    "#axs[1].set_xticklabels( xticks, fontproperties=tickfont )\n",
    "#yticks = axs[1].get_yticks()\n",
    "#axs[1].set_yticklabels( yticks, fontproperties=tickfont )\n",
    "axs[1].legend( loc='best', prop=tickfont )\n",
    "\n",
    "#axs[2].set_yscale( 'log' )\n",
    "axs[2].set_xlabel( \"Pull stochastic unc\", fontproperties=axislabelfont )\n",
    "axs[2].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "#xticks = axs[2].get_xticks()\n",
    "#axs[2].set_xticklabels( xticks, fontproperties=tickfont )\n",
    "#yticks = axs[2].get_yticks()\n",
    "#axs[2].set_yticklabels( yticks, fontproperties=tickfont )\n",
    "axs[2].legend( loc='best', prop=tickfont )\n",
    "\n",
    "axs[3].set_yscale( 'log' )\n",
    "axs[3].set_xlabel( \"Pull predictive unc\", fontproperties=axislabelfont )\n",
    "#axs[3].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "#xticks = axs[3].get_xticks()\n",
    "#axs[3].set_xticklabels( xticks, fontproperties=tickfont )\n",
    "#yticks = axs[3].get_yticks()\n",
    "#axs[3].set_yticklabels( yticks, fontproperties=tickfont )\n",
    "#axs[3].legend( loc='best', prop=tickfont )\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same plots for exp(log (train amplitudes) ) = train amplitudes\n",
    "\n",
    "fig, axs = plt.subplots( 1, 4, figsize=(20,5) )\n",
    "\n",
    "c1 = 'tab:red'\n",
    "c2 = 'tab:green'\n",
    "\n",
    "n_bins = 50\n",
    "bins =np.linspace(-5, 5, n_bins)\n",
    "\n",
    "# revert preprocessing\n",
    "trn_ampl_exp = np.exp(trn_ampl)\n",
    "pred_trn_ampls_exp = np.exp(pred_trn_ampls)\n",
    "pred_val_ampls_std_tot_exp = np.exp(trn_ampl) * pred_val_ampls_std_tot # error propagation\n",
    "pred_val_ampls_std_stoch_exp = np.exp(trn_ampl) * pred_val_ampls_std_stoch # error propagation\n",
    "pred_val_ampls_std_exp = np.exp(trn_ampl) * pred_val_ampls_std # error propagation\n",
    "\n",
    "pull = (trn_ampl_exp - pred_trn_ampls_exp) / trn_ampl_exp\n",
    "pull_normalized_tot = (trn_ampl_exp - pred_trn_ampls_exp) / pred_val_ampls_std_tot_exp\n",
    "pull_normalized_stoch = (trn_ampl_exp - pred_trn_ampls_exp) / pred_val_ampls_std_stoch_exp\n",
    "pull_normalized = (trn_ampl_exp - pred_trn_ampls_exp) / pred_val_ampls_std_exp\n",
    "(n1, bins1, patches1 ) = axs[0].hist( pull, histtype='stepfilled', bins=bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "(n2, bins2, patches2 ) = axs[1].hist( pull_normalized_tot, histtype='stepfilled', bins=bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "(n3, bins3, patches3 ) = axs[2].hist( pull_normalized_stoch, histtype='stepfilled', bins=bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "(n4, bins4, patches4 ) = axs[3].hist( pull_normalized, histtype='stepfilled', bins=bins, fill=None, edgecolor=c1, label=\"train data\", ls=\"--\" )\n",
    "\n",
    "\n",
    "#axs[0].set_yscale( 'log' )\n",
    "axs[0].set_xlabel( \"Pull\", fontproperties=axislabelfont )\n",
    "axs[0].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "#xticks = axs[0].get_xticks()\n",
    "#axs[0].set_xticklabels( xticks, fontproperties=tickfont )\n",
    "#yticks = axs[0].get_yticks()\n",
    "#axs[0].set_yticklabels( yticks, fontproperties=tickfont )\n",
    "axs[0].set_xlim([-5, 5])\n",
    "axs[0].legend( loc='best', prop=tickfont )\n",
    "\n",
    "#axs[1].set_yscale( 'log' )\n",
    "axs[1].set_xlabel( \"Pull total unc\", fontproperties=axislabelfont )\n",
    "axs[1].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "#xticks = axs[1].get_xticks()\n",
    "#axs[1].set_xticklabels( xticks, fontproperties=tickfont )\n",
    "#yticks = axs[1].get_yticks()\n",
    "#axs[1].set_yticklabels( yticks, fontproperties=tickfont )\n",
    "axs[1].legend( loc='best', prop=tickfont )\n",
    "\n",
    "#axs[2].set_yscale( 'log' )\n",
    "axs[2].set_xlabel( \"Pull stochastic unc\", fontproperties=axislabelfont )\n",
    "axs[2].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "#xticks = axs[2].get_xticks()\n",
    "#axs[2].set_xticklabels( xticks, fontproperties=tickfont )\n",
    "#yticks = axs[2].get_yticks()\n",
    "#axs[2].set_yticklabels( yticks, fontproperties=tickfont )\n",
    "axs[2].legend( loc='best', prop=tickfont )\n",
    "\n",
    "axs[3].set_yscale( 'log' )\n",
    "axs[3].set_xlabel( \"Pull predictive unc\", fontproperties=axislabelfont )\n",
    "axs[3].set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "#xticks = axs[3].get_xticks()\n",
    "#axs[3].set_xticklabels( xticks, fontproperties=tickfont )\n",
    "#yticks = axs[3].get_yticks()\n",
    "#axs[3].set_yticklabels( yticks, fontproperties=tickfont )\n",
    "axs[3].legend( loc='best', prop=tickfont )\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error is lowest in the regions where there is more training data, this is expected.  The more data the network has to learn from, the better it can learn to predict the correct amplitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then for the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots( 1, 1, figsize=(7,5) )\n",
    "\n",
    "c1 = 'tab:red'\n",
    "c2 = 'tab:green'\n",
    "\n",
    "(n1, bins, patches1) = axs.hist( val_ampl, histtype='stepfilled', fill=None, edgecolor=c1, label=\"val data\", ls=\"--\" )\n",
    "(n2, bins, patches2) = axs.hist( pred_val_ampls, histtype='stepfilled', fill=None, edgecolor=c2, label=\"val preds\", bins=bins )\n",
    "\n",
    "axs.set_yscale( 'log' )\n",
    "\n",
    "axs.set_xlabel( \"log( train amplitudes )\", fontproperties=axislabelfont )\n",
    "axs.set_ylabel( \"number of events\", fontproperties=axislabelfont )\n",
    "\n",
    "xticks = axs.get_xticks()\n",
    "axs.set_xticklabels( xticks, fontproperties=tickfont )\n",
    "\n",
    "yticks = axs.get_yticks()\n",
    "axs.set_yticklabels( yticks, fontproperties=tickfont )\n",
    "\n",
    "axs.legend( loc='best', prop=tickfont )\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAFgCAYAAABEyiulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABHUklEQVR4nO3deXhU5dk/8O+dfc8kEAgJa8B9x+AGtFVD3RcwwfbXulUNFrWKShARtC7QgAt1bdC6930LxF3rAm1fO0FcAopWtGqiLAlLIJnATPbM8/tjTugwmUkyk5l5Zvl+rmsuPOc8c86dkzj3POsRpRSIiIgovMToDoCIiIi8xwROREQUhpjAiYiIwhATOBERURhiAiciIgpDcboDCAVDhw5VY8eO1R0GERFRLxs2bNijlMpx3c8EDmDs2LGorq7WHQYREVEvIrLF3X42oRMREYUhJnAiIqIwxAROREQUhpjAiYiIwhATOBERURhiAiciIgpDTOBERERhiAmciIgoDDGBExERhaGQX4lNRMoA1ALIBgCl1Io+ypoAlBqbkwCs6as8ERFRuArpBC4i5QA+VUpV9myLSHHPthvzlVLznN5fIyJ9Jn0iomilOjqA+HiIiO5QyAeh3oRe6pKsVwKY5a6gUfsucNldAWBe79JERNGtc9cu/OeUU7Ft1ix0bN2qOxzyQcgmcBGZ6Ga3BUBRH28rEhHnJG5B76RORBT1rB98ANXSgpZPPkXt+Reg4dHHYG9r0x0WeSFkEzgcfd6NLvtctw9QSlmUUllKqVqn3dMArHVXXkRKRaRaRKobGhoGHy0RURixmasQl5uL8e+9i/SiIux5/HHUXnAhrB98oDs0GqBQTuAmTweM5vI+GWWK4KEJXSm1QilVqJQqzMnp9ZhVIqKIpTo7YVu/HmlTpyB++HDkP/QgRj/7DCQ+HttmXYdt19+Azro63WFSP0I5gVtgjDx34rrdl6cAlCilNvotIiKiCNC6aRPsVitSp0w9sC/11FNR8NqryLn1Ftg+/BA1552PPX+qgL2jQ2Ok1JdQTuCN6F0LNwGO5vK+3mhMPatQSrltPiciimZWcxUQG4vUU085aL8kJGDotddi/NtvIW3qVDQsX44fLrwItg8/1BQp9SVkE7hRc7a47M6Ghz7tHiJSDGBjT/IWkb4GvRERRR2b2Yzk449HbEaG2+PxeXkY+egjGPXUCii7HVt/czW23zwHnTt3BjlS6kvIJnDDKiMh95gGx9QwAICIFDgfN5J1NoBqETEZI9LdjWYnIopKXXv2oG3zZqRNndJv2bSpU1Hw5hsY+rsbYf3nP1Fz7nnY++dnoDo7gxAp9SekE7hSahaAAhEpEpFSADUu88KLYcwLNwatrYEjwTcZrxo4VmQjIiIAtnXrAOCg/u++xCQmImf2bBS89SZSTzoJu5ctww8zZsD2ySeBDJMGQJRSumPQrrCwUFVXV+sOg4go4Opumwvbhx/ikCozJMb7Otz+f/wDu+67H5319ci44AIML5uLOM7kCSgR2aCUKnTdH9I1cCIi8h/V3Q1bVRVSp0z2KXkDQPoZZ6Dg7bcw5LfXYf+776LmnHPR+MKLUF1dfo6W+sMETkQUJdo2b0a3xYK0qQNrPvckJjkZw266CePeeB3Jxx2HXYsX44eSmWjZ+JmfIqWBYAInIooSVrMZEEHq5Ml+OV/iuHEY9fRTyF++HN1NTdjy//4f6u9YgK5Gj4tmkh8xgRMRRQmbuQpJRx2FuGxv1sTqm4gg4+yzMP7ttzDkmqvR/MYbqDnnXDT99a9Q3d1+uw71xgRORBQFupub0bppE1IHMH3MFzGpqRh2220oeO1VJB12GHbe/Xv8eOkv0PrllwG5HjGBExFFBdv69YDdPuj+7/4kTpiA0c8/h7xly9C5ayd+nHkpdtx1N7otloBeNxoxgRMRRQGr2YyY9HQkH3tswK8lIsi84HyMf+cdZF9+GSyVlag551xYXn4Zym4P+PWjBRM4EVGEU0rBZq5C6mmnQeLignbd2LQ0DJ8/H+NerkTCuHHYseBObPnVr9H29ddBiyGSMYETEUW49m+/Q9fu3QNaPjUQkg4/HGNeehEjFi9Gx5Yt+OGSYuy8735079+vJZ5IwQRORBThbFVmAEDqFD0JHAAkJgamGdMx/p2/IesXl6LpL39BzTnnovmNN8AVQX3DBE5EFOGs5iokHnII4nNzdYeC2MxM5C5ahLGrVyM+Lw/1ZfOw9fIr0P7dd7pDCztM4EREEcxus6FlwwakBnj0ubeSjz4KY//6v8j9/e/R/u23qJ0+A7vKl6LbatMdWthgAiciimC2jz8BOju19X/3RWJikHXpTBS8+w5M0y9G47PPova887DvnXfYrD4ATOBERBHMVmWGpKQg+cQTdYfiUVxWFkbcey/G/vV/ETskG3VzbsG2q69Be+0PukMLaUzgREQRSikF67/MSD35ZMQkJOgOp1/Jxx+PcatXY/idd6L1yy9Re9FF2P3Qw7C3tuoOLSQxgRMRRajOLVvQuX17wJZPDQSJjUX2r3+F8e/8DZnnnou9K1ag5rzzsP/vf9cdWshhAiciilBWcxUABHz51ECIGzoUeeV/wJiXXkRsahq2X38DbJ98ojuskMIETkQUoaxVZiSMGYOEUaN0h+KzlMJCjF29CjGZmbD89a+6wwkpTOBERBHI3t6Olo8/CbnpY76ISUpC5kUXYv+atehqatIdTshgAiciikAt1dVQbW0hOX3MF1klJVCdnWh+7XXdoYQMJnAioghkM1dBEhKQMmmS7lD8IvGQQ5B8/PGwrF7NOeKG4D2Wpg8iUgagFkA2ACilVvRT3gSgFMAQpdQ8D+ezGJsmpdRSf8ZLRBTqrFVmpBQWIiYlRXcofmMqKcGOBQvQumEDUgoLdYejnfYauIiUA6hVSlUaiXu8iBT3Ub4IQBGA8QBMbo6XKaWWKqVWGOdbayR0IqKo0Flfj47vayKi/9tZxjlnIyYtDZbVq3WHEhK0J3AApUqpSqftlQBmeSqslFprlLd4KHKpS/mNACKjDYmIaACsVT3TxyKj/7tHTEoKMi44H/vefQ/dzc26w9FOawIXkYludlvgqGH7qlFEDnw9E5FSOL4UEBFFBZu5CnEjRiBh/HjdofhdVkkJVHs7mt98S3co2umugWcDaHTZ57rtrVkAikSkyWg6b3Sp4RMRRSzV2Qnb+vVImzIFIqI7HL9LOvJIJB11FCyrVkX9YDbdCdzk6YAxUM1rSqlaAEsAVAMoh4fmcxEpFZFqEaluaGjw5VJERCGnddMm2K3WsFo+1VummTPR/u23aPviC92haKU7gVtgjDx34rrtFRGpALBWKTUNwDQApc5N6j2MQW6FSqnCnJycwVySiChkWM1VQGwsUk89VXcoAZNx3nmQlBQ0RflgNt0JvBG9a+EmAFBKWbw9mdGnbjEGrkEptRbAOAyuT52IKGzYzGYkn3A8YtPTdYcSMLFpqcg49xzse/tv6LZadYejjdYEbiRai8vubABrfTxlNoC9LtewDOJ8RERho2vPHrRt3oy0KZE1fcydrJISqNZW7Hvrbd2haKO7Bg4Aq1zmfU8DUNGzISIFfc0Ld2bUuKc57zP60mv9ECcRUUizrVsHABHd/90j6dhjkXjYYVE9J1x7AldKzQJQICJFxpSvGpdR48VwmhcuIhON0eXFcIw2L3OZjjZLRMqNQWqlAGa6W62NiCjSWM1ViB0yBElHHKE7lIATEZhKStD21Vdo/eor3eFoIdE+DB8ACgsLVXV1te4wiIh8prq78d3kKUj76U+QV16uO5yg6G5uxnc/+Skyp1+MEXffrTucgBGRDUqpXmvHaq+BExHR4LVt3oxuiwWpUdD/3SM2MxMZZ5+NfW++BXtLi+5wgo4JnIgoAljNZkAEqZNP0x1KUJlmlsBus2HfO+/qDiXomMCJiCKAzVyFpKOPRlz2oJbSCDvJEyciYfz4qBzMxgRORBTmupub0bppU8Q9vGQgRASm4mK0fv452r79Vnc4QcUETkQU5mzr1wN2e1T1fzvLvPgiSHw8LKuj67EXTOBERGHOajYjJiMDycceozsULeKyspA+bRqa33gD9vZ23eEEDRM4EVEYU0rBZq5C6mmnQeLidIejjWlmCezNzdj//vu6QwkaJnAiojDW/u136Nq9Oyr7v52lnHQS4kePhmXlKt2hBA0TOBFRGLNVmQEAqVOiO4FLTAxMJcVoqa5Ge+0PusMJCiZwIqIwZjVXIfHQQxE/fLjuULQzTZ8OxMXBUhkdg9mYwImIwpTdZkPLhg1R8fCSgYgbOhTpp5+O5ldfhb2jQ3c4AccETkQUpmwffwJ0diJtanROH3PHNLME3U1NsP7977pDCTgmcCKiMGWrMkNSUpA8cWL/haNE6mmnIT4vLypWZmMCJyIKQ0opWP9lRurJJyMmIUF3OCFDYmORWXwJbB+uR8e2bbrDCSgmcCKiMNS5ZQs6t29n/7cbphkzgJgYWCpf1h1KQDGBExGFIau5CgDY/+1GfG4u0n7yE1heeRmqs1N3OAHDBE5EFIasVWYkjBmDhFGjdIcSkkwzZ6K7YQ+sH3ygO5SAYQInIgoz9vZ2tHz8CVJZ+/Yo7SdTETdsGJoieDAbEzgRUZhpqa6GamuL+uVT+yJxcci8ZAZs5ip01tfrDicgmMCJiMKMzVwFSUhAyqRJukMJaaZLigGlYHn5Fd2hBAQTOBFRmLFWmZFSWIiYlBTdoYS0hJH5SJ08GZZXXoHq7tYdjt+FRAIXkTIRKRaRUhEpHUB5k/GecjfHSkWkQkSKjFeFiBQEJnIiouDqrK9Hx/c17P8eIFNJCbp27ICtqkp3KH6nPYEbSbhWKVWplFoBYLyIFPdRvghAEYDxAEweis0EsAZAOYAKpVStf6MmItLDWtUzfYz93wORfvrPEDtkSEQOZtOewAGUKqWcHx2zEsAsT4WVUmuN8pY+ymQppUQpdaJSaqP/QiUi0stmrkLciBFIGD9edyhhQRISYJp+Maz//D907t6tOxy/0prARcTdAr4WOGrYRETkRHV2wrZ+PdKmTIGI6A4nbJiKi4HubjS/8qruUPxKdw08G0Cjyz7Xba8Z/eAD7lMnIgoHrZs2wW61cvlULyWMHYuUk0+GpbISym7XHY7f6E7gJk8HRMTjsX5UA1jr1Kc+zV2fupHcq0WkuqGhwcdLEREFj9VcBcTGIvXUU3WHEnZMJSXo3L4dLR99pDsUv9GdwC1w1MKduW57RSm10WXQ2qcA5rspt0IpVaiUKszJyRnMJYmIgsJmNiP5hOMRm56uO5Swkz6tCLGZmWhaFTmD2XQn8Eb0roWbAEApZfHlhMYodWe1APiwXCIKa1179qBt82akTeH0MV/EJCYi8+KLsf/vf0dX46B7akOC1gRujBC3uOzOBrDWl/MZ873XuGl+5zQyIgprtnXrAID934NgmlkCdHai+dXXdIfiF7pr4ACwyqWPehqAip4NESnoa164M6PpfJ5L7f1SOOaDExGFLau5CrFDhiDpiCN0hxK2EsePR/LEibCsXg2llO5wBk17AldKzQJQYKyaVgqgxmVeeDGc5oWLyEQRKTP2Fxkrsjk3kVca+3pWaltjDGYjIgpLqrsbtqoqpE2ZDInR/rEd1kwlJej48Ue0fPqp7lAGLU53AACglFraz7GlTtsbAWx03udSvtbTMSKicNS2eTO6LRaksv970DLOPgu7Fi+GZXUlUk86SXc4g8KvckREIc5qNgMiSJ18mu5Qwl5McjIyL7gA+997D90Wi+5wBoUJnIgoxNnMVUg6+mjEZQ9qli0ZTDNLoDo60PzGG7pDGRQmcCKiENbd3IzWTZv48BI/Sjr8cCQdc0zYD2ZjAiciCmG29esBu539335mmlmC9u++R+vnn+sOxWdM4EREIcxqNiMmIwPJxx6jO5SIknnuuYhJSYFldWX/hUMUEzgRUYhSSsFmrkLqaadB4kJi0lDEiElNRcZ552Hf3/6G7v37dYfjEyZwIqIQ1f7td+javZv93wFimlkC1daGfW+9pTsUnzCBExGFKFuVGQCQOoUJPBCSjj4aiUccgabV4fmAEyZwIqIQZTVXIfGwwxA/fLjuUCKSiMBUUoz2zV+j9d9f6Q7Ha0zgREQhyG6zoWXDBjafB1jmBRdAkpJgWbVKdyheYwInIgpBto8/ATo7OX0swGLT05Fx9tnY99ZbsNtsusPxChM4EVEIslWZISkpSJl4gu5QIp5p5kzYW1qw7513dIfiFSZwIqIQo5SC9V9mpJ5yCiQhQXc4ES/5hOORMGF82A1mYwInIgoxnVu2oHP7dvZ/B4mIIKukBG2bvkDbf/6jO5wBYwInIgoxVnMVAE4fC6aMCy+ExMfDsip8auFM4EREIcZaZUbC2LFIGDVKdyhRIy4rC+lnnYXmN9+Eva1NdzgDwgRORBRC7O3taPn4E6RO5ejzYDOVlMC+bx/2v/ee7lAGhAmciCiEtFRXQ7W1sf9bg5STJiFhzBg0hUkzOhM4EVEIsZmrIAkJSJk0SXcoUadnZbbWDRvQXlOjO5x+MYETEYUQa5UZKZMmISY5WXcoUSlz+nQgPj4sHjPKBE5EFCI66+vR8X0NUtl8rk3ckCFIP+MMNL/2GuwdHbrD6VNIPGBWRMoA1ALIBgCl1Ip+ypsAlAIYopSa5+bYTGNzvHG+g8oQEYUia5Vj+lgaB7BpZSopwf733sP+NWuQed55usPxSHsNXETKAdQqpSqNxD1eRIr7KF8EoAiO5GxyU6QcwCql1AojcRcZXxCIiEKazWxGXN4IJBQU6A4lqqWediri8/NDvhldewIHUKqUcr5LKwHM8lRYKbXWKG/xUKQQjgTfoxYAR4MQUUhTnZ2wfbgeaVOmQkR0hxPVJCYGppJitHz0ETq2btUdjkdaE7iITHSz24KDE7BXlFInunwhmAhgja/nIyIKhtbPP4fdZmP/d4jInD4DiI0N6Vq47hp4NoBGl32u2z4zms7X9tenTkSkm9VcBcTFIfWUU3SHQgDihw9D2k9/Csurr0J1duoOxy3dCdzk6YAxGM0nImISkVJj0+1kPhEpFZFqEaluaGjw9VJERH5hrTIj5fjjEZuerjsUMphmlqB7zx7s/+c/dYfilu4EboEx8tyJ67bXlFIWYxDbUgDTRKTXsjrG8UKlVGFOTs5gL0lE5LOuhga0b/6ay6eGmLSpUxGXmxuyzei6E3gjetfCTYAjCXt7MqPm7TrifA0Aj6PaiYh0s65bBwBcPjXESGwsTDNmwFZVhc66Ot3h9KI1gSulNqL3aPJsAGt9PGUhgPLBNL8TEQWbzVyF2KFDkXj44bpDIRemS2YAACwvv6w5kt5018ABYJXLvO9pACp6NkSkoK954c6UUmsBzHOpvU8DsNQfgRIR+Zvq7oZt3TqkTZ4MiQmFj2RyFp+fj9SpU2B5+RWori7d4RxE+1+LUmoWgAIRKTIGntW4TAMrhtO8cBGZaDSTF8NYpMVlOlqlsa/MWCRmDVdiI6JQ1fbVV+i2WNj/HcJMJSXo2rULVrNZdygHCYmlVI3BZn0dW+q0vRHARnioVSulaj0dIyIKNVazGRBB6uTTdIdCHqT/7GeIHToUltWVSD/9dN3hHKC9Bk5EFM1s5iokHXMM4rKydIdCHkh8PEzTp8P6f/+Hzl27dIdzgE8JXEQy/B0IEVG06bZY0PrFF0ibwtHnoc5UUgzY7Wh+5RXdoRzgdQIXkfcB/BCAWIiIoopt/XrAbufyqWEgYfRopJx6CiyrK6Hsdt3hAPCtBr4aAB+VQ0Q0SFZzFWIyM5F8zDG6Q6EByCopQWd9PWzrPtQdCgDfEngjANVXARFZ4ls4RETRQSkFm9mM1NNOhcSFxHhi6kdaURFiTSZYVvda3FMLX/5qagCUisgQAJ/CsRCL8wNIsuF4mtj8QUdHRBSh2r/9Fl0NDUibwulj4SImIQGZ06ej8cUX0bVnD+KGDtUajy8J/B/Gv40AStwczwaQ6XNERERRwGbMKU7lALawYiopRuOzz6L5tdcw5JprtMbiSxN6rVIqWyk1wcMrG8BT/g6UiCiSWM1VSDzsMMQPH6Y7FPJCYkEBkgtPRNPq1VCqz97kgPMlgV87gDLlPpyXiCgqdFttaNm4kQ8vCVNZJSXo3LIVLR9/ojUOrxO4Uuqznv8WkQwROcN4ZTiV4TQzIiIPWj75GOjsRCr7v8NS+llnISYjQ/tgNp8XchGRVXAMYFtrvJpE5D0RGePH+IiIIo7VbIakpCBl4gm6QyEfxCQlIfPCC7H//ffR1dSkLw5v3yAimQAq4XjO9nilVAyALAATAPwdjoeJcKU2IiI3lFKw/cuM1FNOgSQk6A6HfGQqKYHq7ETz669ri8HXPvASpdRTPU3lSqlmpdQPxoNHpoFTyIiI3Or48Ud01tWx/zvMJR12KJKOO9axMpumwWy+JPBmpVSzp4PGs7hrfY6IiCiC2cxVADh9LBJkzZyJjpoatH72Wf+FA8CXBD6Qrxp6x9YTEYUoa5UZCWPHImHUKN2h0CBlnHMOYlJTYVmlZzCbLwm8z2feGf3fE3wLh4goctnb2tDyyadIncrR55EgJiUFGeefj33vvovuffuCf30f3rNCRN4XkenOg9WMkenXwDGQbbHfIiQiihAt1Rug2trY/x1BTCUlUG1taH7zzaBf25d54M0ArgPwWwAWEekWkW4ATQBmAZiplAr+VxEiohBnM5shCQlImTRJdyjkJ8lHH4WkI4/UMpjNp3ngSqlapdTPAYwHMNN4TVBKTeIiLkRE7lmrqpAyaRJikpN1h0J+ZJpZgvZvvkHbv/8d1Ov6vJAL4FhxTSn1svFi4iYi8qCzrg4dNTVIZfN5xMk4/3xIcjIsq1YF9bq+LOTyPgAmayIiL1ir1gEA0jiALeLEpqUh45xz0Pz239BttQXtur7UwFcDKPB3IJ6ISJmIFItIqYiUDqC8yXgPH6hCRCHDVmVGXN4IJBQE7eOTgihrZglUSwv2/e3toF3TlwTeiH7meYvIEt/C6XWecjgeX1qplFoBYLyIFPdRvghAERx98yZ/xEBENFiqsxO2D9cjbcpUiIjucCgAko47DomHHALL6sqgXdOXBF4DoFRElojIDONJZMc7vc6AI4n6Q6lSyvlurIRjpLtbSqm1RnmLn65PRDRorZ9/DrvNxv7vCCYiMJWUoO3LL9H29ddBuWacD+/5h/FvI4ASN8ezAWT6HJFBRCa62W2B/74cEBEFhdVcBcTFIfWUU3SHQgGUeeEF2P3AA7CsXo3cRYsCfj1fauC1SqlspdQED69sAE/5IbZsOL4kOHPdJiIKedYqM1KOPx6x6em6Q6EAijWZkH72WWh+8y3YW1sDfj1fn0bWH38MIDN5OiAiHo8NlDEorlpEqhsaGgZ7OiIit7oaGtC++Wsunxolsn7xS6Sf9XPYW1oCfi2vm9CVUp+JSEZfq635aU64BY5auDPXbZ8Zg+JWAEBhYSEfvkJEAWFd1zN9jP3f0SBl4glImXhCUK4VyvPAG9G7Fm4CDjyylIgo5NnMVYgdOhSJhx+uOxSKMCE7D1wptRG9R5NnA1gb6GsTEfmD6u6Gbd06pE2eDInxaeFLIo9Ceh44gFUu876nAahwuk5BX/PCiYh0avvqK3RbLOz/poDwZRpZzzzwIQA+haOW7Dw6PBuOqV7zBxucUmqWsapaERy1/hqXeeHFcCT1SuDA1LMiYz9EpAzAWqM2T0QUVFazGRBB6uTTdIdCEUi8ffyZiPQka09TurIBZCqlYgcTWDAVFhaq6upq3WEQUYT58Re/hLLbMW7VSt2hUBgTkQ1KqULX/b7UwGvdncjlYn/y4bxERBGj22JB6xdfYOh11+kOhSJUKM8DJyIKW7b16wG7HWk/Yf83BYbXCVwp9Znzds+zwV3K8HGjRBTVrOYqxGRmIumYY3SHQhGqzyZ0ERkLx+AxExxP+GpSSj3du5hca5SZBGAvgO+VUg/6O1gionCglILNbEba5NMgsWEzHIjCTH994LVwjDqfpZRa5q6AUqoZTmufi8hqAKUAmMCJKCq1f/stuhoakDqFzecUOP0lcAuAaUqpHwd6QqVUidNIdSKiqGMzmwEAqVMma46EIll/feBrvUnezu/z4T1ERBHBaq5C4uGHI37YMN2hUATrL4EfVJMWkRNEZK6IfC8i3SKyUkSu6e990aRr7154O7eeiCJHt9WGlo0b+fASCrj+ErjFeUMp9ZnRFz4TwGdKqUvdDGrr9b5o0VlXh9rzL0DjM8/qDoWINGn55GOgs5P93xRw/SVwt1VJY2nSvpYui8oqaFxeHlImTcLuhx5Cy8bP+n8DEUUcq9mMmJQUpJxwvO5QKML1l8BNfRzrK0n39b6IJSIYcf99iM/LQ90tt6CrqUl3SEQURKqzE9YPPkDKqadCEhJ0h0MRrr9R6AUicjoA8fJYn0utRrLY9HTkL38YW37xS9SXzcOoij/xMYJEUaLh8cfRVb8Dpjvv1B0KRYH+Evg0OJ7u5S5J9xx3Jyqb0HskH3UUhs2/HbvuuRd7n3oaQ2eV6g6JiAKsZcMG7F3xFDJnzED6GWfoDoeiQH8JfCOAEi/PKQBW+RZO5Mj65S/RWl2Nhj/+ESkTT0DKpEm6QyKiAOnevx/1c8sQn5+P4XfcoTscihL9JfC1vqxrLiJRPw9cRJB7zz1o+2oz6m65FeNeexVxQ4boDouIAmDXffejc+dOjPnLS4hNS9UdDkWJPjtnlVK3+3JSX98XaWLT0pD/x+Xo3rcP9XPLoLq7dYdERH6275130Pz66xh63XVIOeEE3eFQFOHoqgBLOvxwDF9wB2wffog9FRW6wyEiP+rcuRM77robSccei6G/5XO/KbiYwIPAVFKCjAsuwJ7HHofto491h0NEfqDsdtTfPh+qqwv5S8sh8fG6Q6IowwQeBCKCEXffhYSxY1F3223oamjQHRIRDVLjc8+j5aOPMHz+7UgYO1Z3OBSFmMCDJCY1FfnLH4bdakXdbXPZH04Uxtq++QYNDz+MtKIzYSou1h0ORSkm8CBKOvRQ5C5ciJaPP8aex5/QHQ4R+cDe1ob6uXMRY8rEiHvvhYinZTKIAqu/aWRBISJlAGoBZAOAUmrFYMobxy3GpkkptdTPIfvMdMkMtHz6KfY8+SSST5yItMl8XjBRONn90ENo/+57jHpqBeKysnSHQ1FMew1cRMoB1CqlKo1EPF5EPLZJ9VdeRMqUUkuVUiuM42uNhB4ychctRML4AtTPLUPnrt26wyGiAbJWrUPTCy8i69e/RtpUPm2M9NKewAGUKqUqnbZXApg1iPKXOhc2npwWUsugxaSkYOTy5bC3tqLu1lugurp0hxTS7K2tsK5bB2W36w6FolhXUxN2zJ+PhAnjMey2W3WHQ6Q3gYvIRDe7LXCsv+5r+UYRWe30nlI4knxISZwwASPuvgut1RvQ8MijusMJWd1WK7Zeey22XX0Ndt79eyZx0kIphZ2L7kKXxYL8ZcsQk5SkOyQi7TXwbACNLvtct70tPwtAkYg0GU3njS419pCRedFFMJUUY++KFbD+61+6wwk53RYLtv7marR+vgnp04pgWbUKOxYu5Ah+CrrmV17B/jVrMOzmm5B0xBG6wyECoD+BmzwdEBF3x/otr5SqBbAEQDWAcnhoPheRUhGpFpHqBo3zsocvWIDEww5Dfdk8dO7YoS2OUNPV2IgtV16F9q+/xshH/oj8Rx7B0Nmz0fzyK9hxxx1M4hQ0HVu3Yuf9i5Fy0knIvvJK3eEQHaA7gVtgjCR34rrtVXkRqYDjISzT4Hjcaalzk3oPY5BboVKqMCcnx9u4/SYmKQn5yx+G6uhA3S23QnV2aoslVHTu3o0tl12Ojh9/xMgnn0T6GWdARJDzuxsx9Hc3ovn1N1A/73aOHaCAU11dqJ9bBomNRV75HyCxsbpDIjpAdwJvRO9atQkAlFIWb8sbfeQWY+AalFJrAYyDhz71UJE4bhxy770HrZ99ht3Ll+sOR6vO+npsuewydO7YgVErKpA25eBpdjmzZyPnlluw7623UDd3Lr/wUEDt+VMFWjdtQu7ddyF+xAjd4RAdROs8cKXURhGxuOzOBuD2caQDKJ8NYK/Leyzh8HjTzPPOQ8unn6Lxz88gpbAQ6aefrjukoOvYuhVbrrwS9v1WjHnmz0g+/ni35YaWXguJi8PupUtR19WN/AcfgCQkBDdYinitn3+OPU8+iYwLL0DmeefpDoeoF901cABY5TLvexqAA4/tEpECl+Meyxs17mnOJzf6xmv9HXQgDJ8/H4lHHoH62+ejs65OdzhB1V5Tgy2/+jVUSytGP/esx+TdY8hvrsLwO+Zj/5o12H7zHNg7OoITKEWFbqsNdWXzEDd8GHIXLtQdDpFb2hO4UmoWgAIRKTKmfNW4jBovhtM87wGUnyUi5cYgtVIAM5VS84LxswxWTGIiRj78MNDVhe233AIVJUmp7ZtvsOWyy6GUwugXnkfyUUcN6H3Zl1+O4QvvhPUf/8D2G2+Evb09wJFStNj1hyXo3LYN+eXliE1P1x0OkVuilNIdg3aFhYWqurpadxgH7Hv3PdTdfDOyr7gCw+ffrjucgGr98ktsveZaxCQnY/SzzyBx3Divz9G0chV23nUXUqdMwcjHHuUcXRqUfWvWoO7G32FIaSmG3TJHdzhEEJENSqlC1/3aa+DUW8bZZyHrV79C4/PPY9+aNbrDCZiWDRuw9cqrEJuejjEvvehT8gaArEtnYsT998G2bh22z54Ne2urnyOlaNG5azd2LlyEpCOPRM4N1+sOh6hPTOAhati8MiQdfTR23LEAHdu26Q7H72wffYSt11yLuJwcjHnpRSSMHDmo85kuuQQjliyG7aOPsW3WdbDbbH6KlKKFstux4447YG9rQ94DyzgwkkIeE3iIiklIQP7yhwEAdRE2SMv6wQfYVjoLCSNHYsxLLyI+N9cv5zVdfDHyysvRUl2NraWz0G1lEqeBa3rpL7CtW4fh88qQWFCgOxyifjGBh7CEkSMxYvH9aPvqK+wuD5knog7Kvvffx7YbbkTihAkY/cLziBs61K/nz7zgfOQ/+ABaP/8c2665Bt379/v1/BSZ2r/7DrsfeABpP/0pTL/4he5wiAaECTzEZUybhuwrLkfTX/6Cfe++qzucQWl+8y3UzbkFyUcdhdHPPRuwZylnnHMO8h96CK3//je2Xn0NuvftC8h1KDLYOzpQN7cMMWlpGHH/fRAR3SERDQgTeBgYduutSDruWOxYcCc6tmzRHY5PLC+/jPqyMqSceCJG//lpxGZkBPR6GWf9HCP/uBxtX3+NrVf9Bt0WS0CvR+GrYfkf0f7NNxhx/31+bxEiCiQm8DAgCQkY+dBDQFycY9GSMJvv3PiXv2DHgjuROnkyRlX8CTGpqUG5bvqZZ2Lko4+g/dtvseWq36CrqSko16XwYfvoIzQ++yxMv7g0Klc/pPDGBB4m4vPzkfeHJWj/+mvsWrJEdzgDtvfPf8aue+9D2plnYuQTjyMmOTmo10//2c8w8okn0FFbi61XXImuvXv7fxNFhe7mZtTfPh8JY8ZgeFmZ7nCIvMYEHkbSTz8d2Vf/Bpa/rkTzW2/rDqdPSik0PPY4di97ABnnnoORyx9GjKZpOWlTp2DUk0841lq/4gp0aXx8LIUGpRR23H03uvbsQd6yZYhJSdEdEpHXmMDDzLCbb0byCSdg56JFaK/9QXc4biml0PDQQ9jz2GPInD4decuWQeLjtcaUetppGFVRgc66emy5/Ap07tqtNR7Sa9+bb2L/O+8i54YbkHzM0brDIfIJE3iYkfh45D/8ECQhAXVz5sDe1qY7pIMoux277l+MvU89DdMvf+EY1Rsiz1BOPfkkjH5qBbp27cLWyy9H586dukMiDTq212HnPfci+cQTMeTaa3SHQ+QzJvAwFJ+bi7yl5Wj/z3+w6/77dYdzgOruxs677kLTSy8h+8orkbtoESQmtP7EUgoLMerpp9G1Zw+2XHY5OuvrdYdEQaS6u1E/bx6gFPLKy0PmyyWRL0Lr05UGLO0nP8GQ0lJYVlei+fXXdYcD1dWF+tvnw7K6EkN+ex2GzSsL2fm0KRNPwOhnn0G3xYItl12Oju3R9ejWaLb3qafRumEDchctRMLIfN3hEA0KE3gYy/ndjUgpLMSOu3+P9u+/1xaH6uhA3S23Yt+bbyLn5psx7KabQjZ590g+9liMfvZZdFut2HLZZejYulV3SBRgrV/+Gw2PPYaMc89BxoUX6g6HaNCYwMOYxMUh78EHEZOcjO033wx7S0vQY7C3t2P7jb/D/vffx/D5t2PodbP6f1OISD76KIx59hmo1lZsuexytP8QmoMCafDsLS2onzsXcUOHIveuu0L+CybRQDCBh7n44cOQt2wpOmpqsfOee4N6bXtLC7Zddx2s//oXcu++G9lXXBHU6/tD0pFHYvTzz0F1dGDr5VegvbZWd0gUALuWLkXHli3I+8MSxGZm6g6HyC+YwCNA2uTJGPrb69D82muwvPxKUK7ZbbVi67WlaPn4E4xYshhZv7g0KNcNhKTDDsOYF56HUgpbLr8C7d99pzsk8qP9//wnLH9dieyrrkLqKafoDofIb5jAI8TQ669HysknY+e996Lt228Deq1uiwVbr/oNWjdtQv5DD8J08cUBvV4wJB5yCMa88DxEBFuuuBJt//mP7pDID7r27MGOBXci8fDDkXPzTbrDIfIrJvAIIbGxyH9gGWLS0hzPD7cF5lnYXXv3YsuVV6H9m28w8pFHkHH22QG5jg6JBQUY8+ILkPh4bL3iSrR9/bXukGgQlFLYseBO2K1W5C9bqm0lQKJAYQKPIHE5Och/4AF0/Pgjdtz9eyil/Hr+zl27seXyK9Dx448Y+acnkX5G5D38IWHsWEcST07GliuvQuu/v9IdEvnIsnIlrB98gGG33YbEQw7RHQ6R3zGBR5jUU07G0Buux74334Rl9Wq/nbezrg5bLrsMXTt2YNSKCqRNnuy3c4eahNGjMebFFxCbloatV12F1i++0B0Seam9tha7/lCO1MmTkfXrX+kOhyggQiKBi0iZiBSLSKmIlA6mvLGvQkSKjFeFiBQELvrQM3TWLKSedhp23Xc/2r75ZtDn69iyBT9edhm6m5ow+pk/I/Wkk/wQZWhLGDnSkcRNJmz9zdVo+ewz3SHRAKmODtTfNhcxSUkYsXhxyK0GSOQv2v+yRaQcQK1SqlIptQLAeBEpHmT5mQDWACgHUKGUiqq5QRIbi7xlSxFrMqHuppvRbbX6fK72mhps+fVlUC2tGP3cs0g+/nj/BRri4vPyMObFFxA3ZAi2XX0NWqqrdYdEA9Dw2ONo27wZuffeg/jhw3SHQxQw2hM4gFKlVKXT9koAfa0G0m95pVSWUkqUUicqpTb6MdawETdkCPIffAAd27Zhx8KFPvWHt33zDbZcdjmUUhjz4gtIPuqoAEQa2uJzczH6hRcQl5uLrdeWwvbxJ7pDoj60VFdj71NPIbP4EmRMm6Y7HKKA0prARWSim90WAEX+KB/tUiZNQs5NN2H/O++i6X//16v3tn75JbZccSUkIQFjXnwhqgcBxQ8fhjHPP4f4/DxsmzULtg8/1B0SudG9fz/qy+YhftQo5M6frzscooDTXQPPBtDoss912+vyRj/4gPvUI9mQa69B6k+mYveSPwx4RHXLhg3YeuVViE1Px5iXXkTiuHEBjjL0xeXkYMzzzyNh9Ghs++1sWM1VukMiFzvvvRedu3Yhf2k5YlJTdYdDFHC6E7jJ0wERcXdsIOWrAax16iOf5q5P3Uju1SJS3dDQ4E3MYUViYpBXXo7YIUNQN2cOuvfv77O8bf16bL3mWkfCeulFJIwcGaRIQ1/ckCEY/fxzSCgowPbZs2H94APdIZGh+e23se+NNzH0t7+NqnEaFN10J3ALHLVqZ67bXpVXSm10GbT2KYBe7WlKqRVKqUKlVGFOTs6AAw5HcVlZyH/oQXTW12PHHQs89odbP/gA22Zdh4RRozDmpRcRn5sb5EhDX1xWFsY8+wwSDz0U2264Efv/8Q/dIUW9zh07sPP39yD5uOPC6mE6RIOlO4E3onet2gQASimLL+VFxLU/vBaAu77zqJIycSKG3TIH+9esQdOLL/U6vu/997HthhuROGECRj//HOKGDtUQZXiINZkw+tlnkHTEEdj+u5uw7/33dYcUtZTdjvp5t0N1dSFv2VJIXJzukIiCRmsCN0aIW1x2ZwNY60t5Y773GjfN71E1jcyT7KuuQtrPfoZdy5YdtDhJ85tvoW7OLUg+6iiMfu5ZxGVlaYwyPMRmZGD0n59G8tFHo27OLdj3zju6Q4pKjc8+h5ZPPkHugjuQMHq07nCIgkp3DRwAVrn0UU8DUNGzISIFLsc9ljeazue51N4vhWM+eNSTmBjk/WEJ4nKGou7mOehuboalshL1ZWVIOfFEjP7z04jNyNAdZtiITU/HqKefRvLxx6Pu1tvQ/OZbukOKKm1ff43dy5cjfVoRMmfM0B0OUdCJv9fL9ikIkTIAGwEUAI7+aZdj05RS0wZYvgBAT4IfAqDG+bg7hYWFqjqKFulo3bQJP/76MiSMGY2O72uQOnUqRj76CGKSknSHFpbsNhu2/XY2WqqrkbdkMTIvukh3SBHP3taGH4qLYW/eh3FvvM5WI4poIrJBKVXYa38oJHDdoi2BA0Dj889j15I/IO3MM5H/8EN8UtMg2VtbsW32bLR89DFG3HcvTJdcojukiLbzvvvR9NJLGPX000ibErnr8hMBnhM4R3xEqazLL0fyxIlIOvxwSHy87nDCXkxyMkY9+SS233AjdixchPiRo5B6cuSvGa+D1WxG00svIevyy5i8KaqFQh84aSAiSD7mGCZvP4pJSsLIPy5HwpgxqLvtVnTt2aM7pIjT1dSE+jvuQOIhEzDsllt0h0OkFRM4kR/FpKYif/ly2PftR31ZGVR3t+6QIoZSCjsWLoTd0oy8Zcs4ZoOiHhM4kZ8lHXYochfeCduH67GnoqL/N9CANL/8Mqxr/46cOXOQdPjhusMh0o4JnCgAMi+5BBkXXoA9jz0O20cf6w4n7HX8+CN2Ll6ClFNOQfaVV+gOhygkMIETBYCIYMRddyFh7FjUzb2N/eGDYG9rQ91tcyFxccj7wxJIDD+2iAAmcKKAcfSHPwz7fiv7w32klMKOBXei7d//Rt6SxVyfn8gJEzhRACUd6tQf/qc/6Q4n7OytWIF9b7+NnDlzkH7mmbrDIQopTOBEAZY5YwYyL7rQ6A//SHc4YWPfmjVoWL4cGeefjyGl1+oOhyjkMIETBZiIIHfRIiSMG4e62+aiK4KfP+8vbd98g/p5tyPp2GMx4r57ISK6QyIKOUzgREFwoD/cakUd+8P71LV3L7bNno3Y9HSMfOxRzvcm8oAJnChIevrDW9Z/xP5wD+wdHdh+4+/Q3diEkY8/jvhhw3SHRBSymMCJgoj94Z4ppbDz7t+jdeNG5C1ZjOSjj9IdElFIYwInCiIRQe5ddyGhoID94S4an3seza+8gqGzZyPjnHN0h0MU8pjAiYIsJiUF+Q8/5OgPn8v+cACwfvABdi9bhvSf/xxDb7hedzhEYYEJnEgDR3/4QrR89BH2PBnd/eHt33+PultvQ+Jhh3GlNSIv8P8UIk0yZ0xH5kUXYc/j0dsf3tXUhG2zr4ckJWHU448hJiVFd0hEYYMJnEgTR3/4oqjtD1ednai7eQ66duzAyEcfQXxenu6QiMIKEziRRtHcH75z8WK0fPwxcu+9ByknnKA7HKKwwwROpFnSoYcid9EiR3/4E0/qDicoGv/nf2D5379iyDVXw3TxxbrDIQpLTOBEIcA0YzoyL74Ye554Arb163WHE1C29eux6/7FSPvZz5AzZ47ucIjCFhM4UYjIXbTQ0R8+tyxi+8M7tmzB9pvnILFgHPIeWAaJjdUdElHYCokELiJlIlIsIqUiUjqY8iJiMo6XicjqgZyPKBTEpKRgZM966bfNjbj+8O79+7Htt7MhIhj5xBOITUvTHRJRWNOewEWkHECtUqpSKbUCwHgRKR5E+flKqaXGqwTAPCZxCheJhxzi6A//+OOI6g9X3d2ou+VWdGzdivxH/oiEUaN0h0QU9rQncAClSqlKp+2VAGb5Ul5ETAAKXMpXAJjnhziJgiIS+8N3L3sANrMZuYsWIvWkk3SHQxQRtCZwEZnoZrcFQNEgyheJSIHLcdekThTSchctRMJ4x/zwzt27dYczKJaXX0bjc88h67LLkDVzpu5wiCKG7hp4NoBGl32u2wMur5SyKKWylFK1TsenAVjreiKj/7xaRKobInTAEIUvR3/4cthbWlAfxv3hLRs2YMfdv0fqaadh+Lwy3eEQRRTdCdzk6YDRHD6o8sa+IrhpQldKrVBKFSqlCnNycvqPlCjIEidMcPSHf/IJ9jz+hO5wvNaxvQ7bb/wdEvLzkf/wQ5C4ON0hEUUU3QncAket2pnr9mDKPwWgRCm10evIiEKAafrFyJw+HXuefBK2Dz/UHc6A2W02bJ89G6qrCyOffAKxmZm6QyKKOLoTeCN616pNgKM5fDDlRaQMQIVSqlfzOVE4yV14p6M/fG5ZWPSHK7sddWXz0F5Tg/yHH0LiuHG6QyKKSFoTuFEztrjszoabPmtvyhvTyjb2JG8RcTsojigchFt/eMMfH4H173/H8HnzkDZ5su5wiCKW7ho4AKxymcc9DY6pXwAAESlwOd5f+SI4knq1sahLAQB3o9eJwsbB/eGP6w7Ho+Y338LeigqYSkqQddmvdYdDFNG0J3Cl1CwABSJSZCy4UuMyz7sYTvPC+ypvDFpbA0dCbzJeNQAmBeWHIQog0/SLkTljBvY8+SdY163THU4vrV98gR0LFiClsBC5C++EiOgOiSiiiVJKdwzaFRYWqurqat1hEPXL3tqKH2fORNfeRox79VXEDx+mOyQAQOfOnfihpAQxCYkYW7kacVlZukMiihgiskEpVei6X3sNnIgGLiY5GfkPPwx7ayvqb7sNqqtLd0iwt7Zi+/U3QNlaMPLJJ5i8iYKECZwozCROmIDcuxah5dNPsecJvfPDlVKov+MOtG3ejLwHHkDSoYdqjYcomjCBE4Uh08Wh0R++58knsf+ddzHs1luQfsbp2uIgikZM4ERhKnfhnUicMB71c8vQuSv488P3vfc+9jzyKDIvuhDZV18d9OsTRTsmcKIwFZOcjPzly7X0h7dt3oz6229H8nHHIfeeezjinEgDJnCiMJY4fvyB/vCGIM0P72powLbrb0BsZiZGPvYoYhITg3JdIjoYEzhRmDNdfDEyL5mBvX+qgLUqsP3h9vZ2bL/hRnRbLBj1xOOI44OAiLRhAieKALl3Gv3hZYHrD1dKYeeiu9C6aRPylixB0pFHBuQ6RDQwTOBEESAY/eGNzzyD5tdfx9Abb0DG2Wf5/fxE5B0mcKIIkTh+PEbcfVdA+sP3//Of2P3Ag0g/52wMnT3br+cmIt8wgRNFkMyLLkJm8SV+7Q9v+/Zb1N96G5KOOAJ5ixdzxDlRiGACJ4owuQsWIHHCBNTPnYvOXbsGda6upiZsn309JDUFI594HDHJyX6KkogGiwmcKMLEJCcj/4/LYW9vR/2tvveHq44O1P3uJnTt3o1Rjz2G+NxcP0dKRIPBBE4UgRILChz94dXVaHjsMa/fr5TCznvvQ8unn2LE/fch+bjjAhAlEQ0GEzhRhMq88EJHf3jFCljNVV69t+mlv8CyejWGlJYi84ILAhQhEQ0GEzhRBDvQH15WNuD+cGvVOuxasgRpZ56JnJtvCnCEROQrJnCiCObcH15366399oe31/6AujlzkDhhAvLKyyEx/IggClX8v5MowiUWFGDE7+9Ga/UGNDzquT+8u7kZ22fPhsTFYeQTTyA2LTWIURKRt5jAiaJA5gUXwFRSjL0VFW77w1VXF+rm3IKOujqMfPQRJIzM1xAlEXmDCZwoSgxfsACJhx7qtj98V/lS2D78ECPuWoSUwkJNERKRN5jAiaJETFIS8pc/3Ks/vGnlKjS9+CKyr7gCpuJizVES0UDF6Q6gPyJSBqAWQDYAKKVW+LM8UTTp6Q+vn1uGhkcfQ+rk07Dz3nuROnUqhs29TXd4ROSFkK6Bi0g5gFqlVKWRiMeLiMcqgrfliaKRc3/49tnXI2H0aOQ/9CAkLuS/zxORk5BO4ABKlVKVTtsrAczyY3miqDR8wQIkHnYYEBuLUU88jtj0dN0hEZGXQvYrt4hMdLPbAqDIH+WJollMUhLG/s9fYG9pQVxOju5wiMgHIZvA4ejDbnTZ57rtc3kRKQVQCgCjR4/2JT6isBaTmoqYVM71JgpXodyEbvJ0QETcHfOqvFJqhVKqUClVmMMaCBERhZlQTuAWGCPJnbhuD6Y8ERFR2ArlBN6I3rVqEwAopSx+KE9ERBS2QjaBK6U2wlGrdpYNYK0/yhMREYWzkE3ghlUu87inAajo2RCRApfjfZYnIiKKFCGdwJVSswAUiEiRMWq8xmWedzGc5nkPoDwREVFEEKWU7hi0KywsVNXV1brDICIi6kVENiilej1lKKRr4EREROQeEzgREVEYYgInIiIKQ0zgREREYYiD2ACISAOALX485VAAe/x4PuI9DRTe18DgffW/aL6nY5RSvdb8ZgIPABGpdjdikHzHexoYvK+Bwfvqf7ynvbEJnYiIKAwxgRMREYUhJvDAWKE7gAjEexoYvK+Bwfvqf7ynLtgHTkREFIZYAyciIgpDTOBERERhKE53AOFIRMoA1MLxvHEopfrsm/G2fLQREROAUmNzEoA1vKf+JyIVxhP7+irD+zoAxt/sfAA1xq5qpdTGPsrzvg6AcZ8sxqZJKbV0AOWj9r6yBu4lESkHUKuUqjT+WMa7PIN8UOWj1Hyl1FLjVQJgnvE4WLd4T71n3LOCAZThfe2HkbxXK6XmOSWM+X2U530dABEpMz4DVhj3aa2RoD2V531VSvHlxQtAk8v2RDhqjH4pH20vACY4Pgyd95XB8Sx33lP/3OOJAMr7u0e8rwO+n6sBFDttmwAU8L4O+r5ucHeveV89v1gD94KITHSz2wKgyB/lo1iRiDjXDi3wUFvkPfVJIYA1fRXgffVKMRy1wwIRmaiUsiilat0V5H31SqOIrO7ZMFrhVroryPvqwATunWwAjS77XLcHUz7qGB9+WS4fgNMArPXwFt5TLxhNiqsGUJT3dQCcEkeh077VRrO6O7yvAzcLji/zTUbTeaNSqtJDWd5XMIF7y+TpgIf/gb0tH/WM+1IEYJ6HIqZ+3ksG435YlFKWARQ39XMecjjQMqSUqlWOgWsrATzlobzJ04l4Xw9mfIlfAqAaji6fSX0UN3k6EE33lQncOxYYox2duG4Ppjw5PghLlOcRvRbwng7UTKWUp5YMVxbwvg6Exfi32mlfLRzN6p7K874OgIhUAFirlJoGRytcqXOTugsLeF85jcxLjej9zc8EOJqC/VA+qhnNZhX9JB3e0wEwmnoHmrwB3teBqgV63RML4Kj5ublXvK8DYPy9Wnq+uCul1orIOAA/eHgL7yuYwL2ilNooIhaX3dnw8EHpbfloZvTVbuxJ3iJS5C6R854OWDYc/Yk925MAFBhfkipdB13xvg6MUqpWRCwuydoED10VvK8Dlg1gr/MOpZRFRPjZ2gc2oXtvlctcw2kAKno2jJGpxQMtT45kDcf/fNUiYjJGpE90Os576iWl1Fr137n1S+EYhW4xtmsB3tdBWAJgptP2pcY+ALyvvjC+rE9z3mf0Zdc6bfO+uuDDTHxg1GI2whjQopxW/zGOTTP6cfotH+2M/0mb3ByqVI5FXXhPB8mYjlMCx8jpJQBWGLUb3lcfuS4wopxWDON99Y3xxX0W/ru6HT9b+8EETkREFIbYhE5ERBSGmMCJiIjCEBM4ERFRGGICJyIiCkNM4ERERGGICZxokFyepEYUdPwbjE5M4ESD0PPUJN1xUNSbaCyIRFGECZwigrFK0xrjUYRB+SAzFkhZG2prLxv3oq9HXEYUT797HfdBREpFZIOIuFucKGCMx25OY008ujCBU0QwHu04DUGqDRtJ4cQ+nprm6X0FQfiCYYLjkaxR8XSmPn73Jri5D4H8HRgrgV0biHMPwBI4HsNJUYIPM6FIYwnSdcrh24dlwGtIxpeKrEBfJwRZnDf6uA+B/h1Y+i0RAMbyuLWeHgREkYc1cCLfFLg+0WuASvweCXkrkn8HFXCsJ05RgAmcyEvGE5DW+PC+IgCl/o+IBirSfwfGl8qJ/RakiMAmdIp4Rn91Kf7btGmC8UQul3IFAIqNciYAlXD0oQLAeKXUPOO/pwFY7WUMxfjv4xLniUhPLbDceMb0RABPwdG8e6bxbzaAEpenLxUZxxrheMb3GufmUuNnXQ3Hk8dKlFJrjZ+romef0z3INmK61puBeAOIob/rzTN+5lLjHAUAhjjdXxj3o9w4R8/9gPHv+J771keM7u5Df78D57ivNQaG9fzu5gOYqJQSuBCRcjieoNVo/IzVHmKaCMffU61RzuTyFLMi4z7BON4IYJLzfRmgtSIy0dvxGRSGlFJ88RUxLwAbABQ5bRfAkWCcy5jgqEGbXMrVuGw3OW+7XMPkY3w1zvG5Od4EoMyI0WRsm5xiKnIpvwFA8UCu43Ru55+l1PX+9BO/NzF4vJ6bc6wBUOrhHBVuYmhyPq+7330f92Egv4Nil30THR+Xvf6ONriJo8L5b8fYV+Tm77Cs52czfqYyNz/ngH83Luct8/Z9fIXfi03oFOkqjNcBylHbXA1HjbfHPABrncrUAuipJfZs9zCpwE0da4SjNmoxXllO1yqGy88Cz32e7uJrhKMlwflnqcZ/WxkGwpsYvLneRvy3dux6joO6K4zzrXAThzuWAZRx5a5m7+48T8ExjdC1vLvWmQq4DHpUjtp3qdFaUOR6DeO8vtSia+FopaAIxyZ0ilhGk2gR3A9aWgugQkR6knEBen9YNgI40c17Az0961MP+yvRO5H0NNsOhAWOGqPrPm94E0Nf13NtZt4Lz6PDXa8HACsBlDn9/nQohvu/j4OmsxlN5wVw37ReC0eTfTWADUYyd+7eGciXFFcWRMkUwmjHBE6RbCJwoMZ9EOXo8wQcH55r4fggNbkUy4aXfd1+YnG306nm2dPHWwBHH7Q3BjVP3ocY3F7PD0m3p9bb8/sLKiMpAwP7AtTzxaTI+JtzNg9AtXJMASuBo1ZfLiK1cDSvL3V9wwCZfHwfhREmcIpKblbnqoBTsnZKTqvcvN31vYOKw00y85hknQZibYAjcX0K75rABy0UYvCnQdbiB/KFyAIcWC3NI+N4pdNgt1kiMkkp5cu0N1+mOFKYYQKnSLYR8PgB3dPE2NOsWQvHh2fPiOLxcKy05vo+wL8LdcyEUaPtjxHbRHXwqPSgThkKhRgMPbVatyO+vTSQ34HJeUMptdGoTbvrenFVDTi6dNz0l8M4VtZT21aO0eMbASwVkRofvmCYoGkxGQouDmKjiOU0CGimm8PFOHgd81Kl1DzjtcL411MtpnGQ62v7+t4y9F79LbvnfD0D7gJMRwwmN/tmYXDr0Ls7pzPXPmR3/fPO0ww9ljVirITjb+4gIjKx5wuQ0bLhaq2bWPpTAMeYAopwTOAUaUw4+MO5BI6myAP7jP++FAePnK41niw2EGvh6Hv1xVoc3Gfs2gSbjb4/sE1u9vWUb3Qp51rW3Xt94U0MAzWkj/KXOm84NTG7Ni2b3JzD3b7+fgdr0XsUd4FxbedzXQvgUjdf5qa5ueY8OP4OXb8IFKn/zteej96y+/gi6cl4+DZ6ncKMKMe8QaKwZnwwzoNjnvFGACt7miSND9j5cDSNA44PuCWutTcRqcHBtaeeGvxBC50YNaUCXwcYiUgFjNHZyvHwC3fxr1UuC3gYiWuW8XNsNN6/1mjWBhzTrWpdzrPE+LfXvTF+jllwJMNKOAZN9TkgzMcY+rye8d5iOL4ErIJjoReLcb0a4z0m4/zZcIz8di7T63dvnP+g++DcB+3ud+B0zARHK0MN/tuXvNHpZ57Xc5+c/rZ6Zg70LOTSMz5gXk+Cdiq7t+e86r+LxZQa5Yvw3y8UBQAqvU3gIrJBKeVudDxFGCZwIhz4QK9wqg05r+A2H8A4lyS+xrkfmAKjJ4H398WCHIy/2ad8HPhGYYZN6BT1jKbzGuWy9KSxkMpSOGqFrv3otW6aQ4l0K4Vvc8cpDDGBEzlY+jhW42bfPONFFBKM2vcktlZEDyZwIscUohJ3I8uNWvY0uMwHN5rTN2iaQhVNDoxwp37NB79URhX2gROh1xPLegYR9XpilJv3lcHNk81ocIwvTj2D2w4alEi9GU8yA2vf0YUJnGiQ+lqggygY+DcYnZjAiYiIwhD7wImIiMIQEzgREVEYYgInIiIKQ0zgREREYYgJnIiIKAz9f21IGpiQrRgvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots( 1, 1, figsize=(7,5) )\n",
    "\n",
    "c1 = 'tab:red'\n",
    "c2 = 'tab:green'\n",
    "\n",
    "axs.plot( np.abs((n1-n2)/n1), color=c1 )\n",
    "\n",
    "axs.set_xlabel( \"log( train amplitudes )\", fontproperties=axislabelfont )\n",
    "axs.set_ylabel( \"Error\", fontproperties=axislabelfont )\n",
    "\n",
    "xticks = np.round( axs.get_xticks(), 2 )\n",
    "axs.set_xticklabels( xticks, fontproperties=tickfont )\n",
    "\n",
    "yticks = np.round( axs.get_yticks(), 2 )\n",
    "axs.set_yticklabels( yticks, fontproperties=tickfont )\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
